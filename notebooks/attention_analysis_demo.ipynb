{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 MMTD Attention 기반 해석가능성 분석 데모\n",
    "\n",
    "이 노트북은 MMTD 모델의 Attention 기반 해석가능성 분석 시스템을 시연합니다.\n",
    "\n",
    "## 🎯 주요 기능\n",
    "- **텍스트 Attention**: 어떤 단어가 중요한지 분석\n",
    "- **이미지 Attention**: 어떤 이미지 영역이 중요한지 분석\n",
    "- **Cross-Modal Attention**: 텍스트와 이미지 간 상호작용 분석\n",
    "- **종합 해석**: 예측 결과에 대한 완전한 설명 제공\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 커스텀 모듈 import\n",
    "from src.analysis.attention_analyzer import AttentionAnalyzer\n",
    "from src.analysis.attention_visualizer import AttentionVisualizer\n",
    "from src.models.interpretable_mmtd import InterpretableMMTD\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(\"🚀 라이브러리 로딩 완료!\")\n",
    "print(f\"🖥️ 사용 가능한 디바이스: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 모델 및 분석 도구 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = '../checkpoints/best_interpretable_mmtd.ckpt'  # 실제 모델 경로로 수정\n",
    "tokenizer_name = 'bert-base-uncased'\n",
    "\n",
    "print(f\"🔧 설정:\")\n",
    "print(f\"  - 디바이스: {device}\")\n",
    "print(f\"  - 모델 경로: {model_path}\")\n",
    "print(f\"  - 토크나이저: {tokenizer_name}\")\n",
    "\n",
    "# 모델 로딩\n",
    "try:\n",
    "    model = InterpretableMMTD.load_from_checkpoint(\n",
    "        model_path,\n",
    "        map_location=device\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"✅ 모델 로딩 성공!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 로딩 실패: {e}\")\n",
    "    print(\"💡 모델 경로를 확인하거나 사전 훈련된 모델을 사용해주세요.\")\n",
    "\n",
    "# 토크나이저 로딩\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "print(\"✅ 토크나이저 로딩 성공!\")\n",
    "\n",
    "# 분석 도구 초기화\n",
    "analyzer = AttentionAnalyzer(model, tokenizer, device)\n",
    "visualizer = AttentionVisualizer()\n",
    "print(\"✅ 분석 도구 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 예시 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 스팸 이메일 텍스트\n",
    "spam_text = \"\"\"\n",
    "URGENT! You have WON $1,000,000 in our EXCLUSIVE lottery! \n",
    "Click here NOW to claim your FREE prize! \n",
    "Limited time offer - expires TODAY!\n",
    "Call 1-800-WIN-CASH immediately!\n",
    "\"\"\"\n",
    "\n",
    "# 예시 정상 이메일 텍스트\n",
    "ham_text = \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I hope you're doing well. I wanted to follow up on our meeting yesterday \n",
    "about the project timeline. Could you please send me the updated schedule \n",
    "when you have a chance?\n",
    "\n",
    "Thanks,\n",
    "Sarah\n",
    "\"\"\"\n",
    "\n",
    "print(\"📝 예시 텍스트 준비 완료!\")\n",
    "print(f\"스팸 텍스트 길이: {len(spam_text)} 글자\")\n",
    "print(f\"정상 텍스트 길이: {len(ham_text)} 글자\")\n",
    "\n",
    "# 예시 이미지 생성 (실제로는 데이터셋에서 로딩)\n",
    "# 더미 이미지 (224x224 RGB)\n",
    "dummy_image = torch.randn(3, 224, 224)\n",
    "print(f\"🖼️ 예시 이미지 shape: {dummy_image.shape}\")\n",
    "\n",
    "print(\"\\n⚠️ 실제 사용 시에는 데이터셋에서 실제 이미지를 로딩해주세요!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 단일 샘플 Attention 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스팸 텍스트 분석\n",
    "print(\"🔍 스팸 텍스트 Attention 분석 중...\")\n",
    "\n",
    "try:\n",
    "    spam_explanation = analyzer.explain_prediction(\n",
    "        text=spam_text,\n",
    "        image=dummy_image,\n",
    "        return_attention_maps=True\n",
    "    )\n",
    "    \n",
    "    print(\"✅ 분석 완료!\")\n",
    "    \n",
    "    # 예측 결과 출력\n",
    "    pred = spam_explanation['prediction']\n",
    "    print(f\"\\n📊 예측 결과:\")\n",
    "    print(f\"  • 예측 라벨: {pred['label']}\")\n",
    "    print(f\"  • 예측 점수: {pred['score']:.4f}\")\n",
    "    print(f\"  • 신뢰도: {pred['confidence']:.4f}\")\n",
    "    \n",
    "    # 상위 중요 토큰 출력\n",
    "    important_tokens = spam_explanation['text_analysis']['important_tokens'][:5]\n",
    "    print(f\"\\n📝 가장 중요한 텍스트 토큰 (Top 5):\")\n",
    "    for i, token in enumerate(important_tokens, 1):\n",
    "        print(f\"  {i}. '{token['token']}' - 중요도: {token['combined_importance']:.4f}\")\n",
    "    \n",
    "    # 모달리티 균형\n",
    "    cross_modal = spam_explanation['cross_modal_analysis']\n",
    "    print(f\"\\n⚖️ 모달리티 균형:\")\n",
    "    print(f\"  • 텍스트→이미지: {cross_modal['text_to_image_strength']:.4f}\")\n",
    "    print(f\"  • 이미지→텍스트: {cross_modal['image_to_text_strength']:.4f}\")\n",
    "    print(f\"  • 균형도: {cross_modal['modality_balance']:.4f} (0=텍스트 중심, 1=이미지 중심)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 분석 실패: {e}\")\n",
    "    spam_explanation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 텍스트 Attention 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spam_explanation is not None:\n",
    "    # 텍스트 attention 시각화\n",
    "    text_fig = visualizer.visualize_text_attention(\n",
    "        tokens=spam_explanation['text_analysis']['tokens'],\n",
    "        token_importance=spam_explanation['text_analysis']['important_tokens'],\n",
    "        title=\"스팸 텍스트 Attention 분석\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"📊 텍스트 attention 시각화 완료!\")\nelse:\n",
    "    print(\"❌ 분석 결과가 없어 시각화를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🖼️ 이미지 Attention 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spam_explanation is not None:\n",
    "    # 이미지 attention 시각화\n",
    "    image_fig = visualizer.visualize_image_attention(\n",
    "        image=dummy_image,\n",
    "        patch_importance=spam_explanation['image_analysis']['important_patches'],\n",
    "        title=\"스팸 이미지 Attention 분석\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"🖼️ 이미지 attention 시각화 완료!\")\nelse:\n",
    "    print(\"❌ 분석 결과가 없어 시각화를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Cross-Modal Attention 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spam_explanation is not None and 'attention_maps' in spam_explanation:\n",
    "    # Cross-modal attention 시각화\n",
    "    cross_modal_fig = visualizer.visualize_cross_modal_attention(\n",
    "        cross_modal_attention=spam_explanation['attention_maps']['cross_modal_attention'],\n",
    "        tokens=spam_explanation['text_analysis']['tokens'],\n",
    "        title=\"스팸 Cross-Modal Attention 분석\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"🔄 Cross-modal attention 시각화 완료!\")\nelse:\n",
    "    print(\"❌ Cross-modal attention 데이터가 없어 시각화를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 종합 분석 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spam_explanation is not None:\n",
    "    # 종합 분석 시각화\n",
    "    comprehensive_fig = visualizer.visualize_comprehensive_explanation(\n",
    "        explanation=spam_explanation,\n",
    "        image=dummy_image,\n",
    "        title=\"스팸 이메일 종합 Attention 분석\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"🎯 종합 분석 시각화 완료!\")\nelse:\n",
    "    print(\"❌ 분석 결과가 없어 시각화를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 정상 이메일 비교 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상 이메일 분석\n",
    "print(\"🔍 정상 이메일 Attention 분석 중...\")\n",
    "\n",
    "try:\n",
    "    ham_explanation = analyzer.explain_prediction(\n",
    "        text=ham_text,\n",
    "        image=dummy_image,\n",
    "        return_attention_maps=True\n",
    "    )\n",
    "    \n",
    "    print(\"✅ 정상 이메일 분석 완료!\")\n",
    "    \n",
    "    # 스팸 vs 정상 비교\n",
    "    if spam_explanation is not None:\n",
    "        print(\"\\n📊 스팸 vs 정상 이메일 비교:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"스팸 이메일:\")\n",
    "        print(f\"  • 예측: {spam_explanation['prediction']['label']} ({spam_explanation['prediction']['score']:.4f})\")\n",
    "        print(f\"  • 모달리티 균형: {spam_explanation['cross_modal_analysis']['modality_balance']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n정상 이메일:\")\n",
    "        print(f\"  • 예측: {ham_explanation['prediction']['label']} ({ham_explanation['prediction']['score']:.4f})\")\n",
    "        print(f\"  • 모달리티 균형: {ham_explanation['cross_modal_analysis']['modality_balance']:.4f}\")\n",
    "        \n",
    "        # 중요 토큰 비교\n",
    "        spam_tokens = [t['token'] for t in spam_explanation['text_analysis']['important_tokens'][:3]]\n",
    "        ham_tokens = [t['token'] for t in ham_explanation['text_analysis']['important_tokens'][:3]]\n",
    "        \n",
    "        print(f\"\\n📝 중요 토큰 비교:\")\n",
    "        print(f\"스팸: {spam_tokens}\")\n",
    "        print(f\"정상: {ham_tokens}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 정상 이메일 분석 실패: {e}\")\n",
    "    ham_explanation = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "output_dir = '../outputs/demo_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if spam_explanation is not None:\n",
    "    # 스팸 분석 결과 저장\n",
    "    analyzer.save_explanation(\n",
    "        spam_explanation,\n",
    "        f'{output_dir}/spam_explanation.json',\n",
    "        include_attention_maps=False\n",
    "    )\n",
    "    print(\"💾 스팸 분석 결과 저장 완료!\")\n",
    "\n",
    "if ham_explanation is not None:\n",
    "    # 정상 분석 결과 저장\n",
    "    analyzer.save_explanation(\n",
    "        ham_explanation,\n",
    "        f'{output_dir}/ham_explanation.json',\n",
    "        include_attention_maps=False\n",
    "    )\n",
    "    print(\"💾 정상 분석 결과 저장 완료!\")\n",
    "\n",
    "print(f\"\\n📁 결과 저장 위치: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 데모 완료!\n",
    "\n",
    "### 🔍 **분석된 내용**\n",
    "1. **텍스트 Attention**: 어떤 단어가 스팸/정상 판단에 중요한지\n",
    "2. **이미지 Attention**: 어떤 이미지 영역이 중요한지\n",
    "3. **Cross-Modal Attention**: 텍스트와 이미지가 어떻게 상호작용하는지\n",
    "4. **모달리티 균형**: 텍스트 vs 이미지 기여도\n",
    "\n",
    "### 🚀 **다음 단계**\n",
    "- 실제 데이터셋으로 배치 분석 실행: `scripts/attention_analysis_experiment.py`\n",
    "- 더 많은 샘플로 패턴 분석\n",
    "- 오류 사례 심층 분석\n",
    "- 모델 개선점 도출\n",
    "\n",
    "### 📊 **핵심 장점**\n",
    "- ✅ **완전한 투명성**: 모든 예측에 대한 명확한 근거 제공\n",
    "- ✅ **다중모달 해석**: 텍스트와 이미지 모두 분석\n",
    "- ✅ **직관적 시각화**: 비전문가도 이해 가능\n",
    "- ✅ **실용적 활용**: 실제 스팸 필터링 시스템에 적용 가능\n",
    "\n",
    "---\n",
    "*🔬 이것이 바로 \"진짜 해석가능한\" AI입니다!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}