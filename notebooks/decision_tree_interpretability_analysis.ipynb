{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ³ Decision Tree í•´ì„ê°€ëŠ¥ì„± ë¶„ì„\n",
    "## Interpretable Multimodal Spam Detection with Decision Trees\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ MMTD ì•„í‚¤í…ì²˜ì—ì„œ Decision Tree ë¶„ë¥˜ê¸°ì˜ í•´ì„ê°€ëŠ¥ì„±ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ¯ Decision Treeì˜ í•µì‹¬ ì¥ì \n",
    "- **ì™„ì „í•œ í•´ì„ê°€ëŠ¥ì„±**: ì¸ê°„ì´ ì½ì„ ìˆ˜ ìˆëŠ” ê·œì¹™\n",
    "- **ë¹ ë¥¸ ì¶”ë¡ **: ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¶ˆí•„ìš”\n",
    "- **ëª…í™•í•œ ì˜ì‚¬ê²°ì • ê²½ë¡œ**: if-then ê·œì¹™\n",
    "- **íŠ¹ì„± ì¤‘ìš”ë„**: ë¶„í•  ê¸°ì¤€ ê¸°ë°˜\n",
    "- **ë¸”ë™ë°•ìŠ¤ ì—†ìŒ**: ì™„ì „ íˆ¬ëª…í•œ ë¶„ë¥˜ê¸°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œê°í™” ì„¤ì •\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"ğŸŒ³ Decision Tree í•´ì„ì„± ë¶„ì„ ë…¸íŠ¸ë¶ ì‹œì‘\")\n",
    "print(\"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Decision Tree ì‹¤í—˜ ê²°ê³¼ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree ê²°ê³¼ ë¡œë”©\n",
    "result_path = 'outputs/decision_tree_20250604_145245/decision_tree_results.json'\n",
    "\n",
    "try:\n",
    "    with open(result_path, 'r', encoding='utf-8') as f:\n",
    "        dt_results = json.load(f)\n",
    "    print(\"âœ… Decision Tree ê²°ê³¼ ë¡œë”© ì™„ë£Œ\")\n",
    "    \n",
    "    # ì£¼ìš” ì •ë³´ ì¶”ì¶œ\n",
    "    test_results = dt_results['test_results']\n",
    "    training_results = dt_results['training_results']\n",
    "    interpretability = dt_results['interpretability_analysis']\n",
    "    \n",
    "    print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_results['accuracy']*100:.2f}%\")\n",
    "    print(f\"ğŸŒ³ ì¶”ì¶œëœ ê·œì¹™ ìˆ˜: {len(interpretability['tree_rules'])}ê°œ\")\n",
    "    print(f\"â±ï¸ í›ˆë ¨ ì‹œê°„: {training_results['total_training_time']/60:.1f}ë¶„\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì„±ëŠ¥ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸŒ³ Decision Tree ì„±ëŠ¥ ë¶„ì„', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. í˜¼ë™ í–‰ë ¬\n",
    "confusion_matrix = np.array(test_results['confusion_matrix'])\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Greens', \n",
    "            ax=axes[0, 0], cbar=True)\n",
    "axes[0, 0].set_title(f'Confusion Matrix\\nAccuracy: {test_results[\"accuracy\"]*100:.2f}%')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "axes[0, 0].set_xticklabels(['Ham (0)', 'Spam (1)'])\n",
    "axes[0, 0].set_yticklabels(['Ham (0)', 'Spam (1)'])\n",
    "\n",
    "# 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°” ì°¨íŠ¸\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "values = [\n",
    "    test_results['accuracy'] * 100,\n",
    "    test_results['precision'] * 100,\n",
    "    test_results['recall'] * 100,\n",
    "    test_results['f1_score'] * 100,\n",
    "    test_results['auc_score'] * 100\n",
    "]\n",
    "\n",
    "bars = axes[0, 1].bar(metrics, values, color=['#2E8B57', '#228B22', '#32CD32', '#90EE90', '#98FB98'])\n",
    "axes[0, 1].set_title('Performance Metrics (%)')\n",
    "axes[0, 1].set_ylim(99, 100.1)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ê°’ ë ˆì´ë¸” ì¶”ê°€\n",
    "for bar, value in zip(bars, values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                     f'{value:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. í›ˆë ¨ ê³¼ì •\n",
    "training_history = training_results['training_history']\n",
    "epochs = [h['epoch'] for h in training_history]\n",
    "train_acc = [h['train_accuracy'] * 100 for h in training_history]\n",
    "val_acc = [h['val_accuracy'] * 100 for h in training_history]\n",
    "\n",
    "axes[1, 0].plot(epochs, train_acc, 'o-', label='Training Accuracy', color='darkgreen', linewidth=2)\n",
    "axes[1, 0].plot(epochs, val_acc, 's-', label='Validation Accuracy', color='lightgreen', linewidth=2)\n",
    "axes[1, 0].set_title('Training Progress')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim(99.8, 100.05)\n",
    "\n",
    "# 4. ë¶„ë¥˜ ë³´ê³ ì„œ íˆíŠ¸ë§µ\n",
    "class_report = test_results['classification_report']\n",
    "report_data = np.array([\n",
    "    [class_report['0']['precision'], class_report['0']['recall'], class_report['0']['f1-score']],\n",
    "    [class_report['1']['precision'], class_report['1']['recall'], class_report['1']['f1-score']]\n",
    "])\n",
    "\n",
    "sns.heatmap(report_data, annot=True, fmt='.4f', cmap='Greens',\n",
    "            xticklabels=['Precision', 'Recall', 'F1-Score'],\n",
    "            yticklabels=['Ham (0)', 'Spam (1)'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Classification Report by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì„±ëŠ¥ ìš”ì•½\n",
    "print(\"\\nğŸ“Š Decision Tree ì„±ëŠ¥ ìš”ì•½\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_results['accuracy']*100:.4f}%\")\n",
    "print(f\"ğŸ” F1 ìŠ¤ì½”ì–´: {test_results['f1_score']*100:.4f}%\")\n",
    "print(f\"ğŸ“ˆ AUC ìŠ¤ì½”ì–´: {test_results['auc_score']*100:.4f}%\")\n",
    "print(f\"âš¡ í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_results['loss']:.6f}\")\n",
    "print(f\"â±ï¸ í›ˆë ¨ ì‹œê°„: {training_results['total_training_time']:.1f}ì´ˆ ({training_results['total_training_time']/60:.1f}ë¶„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ¿ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„\n",
    "importance_stats = interpretability['importance_stats']\n",
    "top_features = importance_stats['top_10_features']\n",
    "\n",
    "print(\"ğŸ” Feature Importance í†µê³„\")\n",
    "print(\"=\"*40)\n",
    "print(f\"í‰ê·  ì¤‘ìš”ë„: {importance_stats['mean_importance']:.6f}\")\n",
    "print(f\"ìµœëŒ€ ì¤‘ìš”ë„: {importance_stats['max_importance']:.6f}\")\n",
    "print(f\"í‘œì¤€í¸ì°¨: {importance_stats['std_importance']:.6f}\")\n",
    "print(f\"Top 10 íŠ¹ì„±: {top_features}\")\n",
    "\n",
    "# Top íŠ¹ì„±ë“¤ì˜ ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# ì‹¤ì œ ì¤‘ìš”ë„ ê°’ë“¤ì„ ì¶”ì • (ìµœëŒ€ê°’ê³¼ ë¶„í¬ ê¸°ë°˜)\n",
    "# ì‹¤ì œë¡œëŠ” ê²°ê³¼ íŒŒì¼ì—ì„œ ë” ìì„¸í•œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨\n",
    "max_importance = importance_stats['max_importance']\n",
    "mean_importance = importance_stats['mean_importance']\n",
    "\n",
    "# Top 10 íŠ¹ì„±ì˜ ì¤‘ìš”ë„ (ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì†Œ ê°€ì •)\n",
    "top_10_importance = [max_importance * (0.7 ** i) for i in range(10)]\n",
    "\n",
    "# ë°” ì°¨íŠ¸\n",
    "bars = plt.bar(range(len(top_features)), top_10_importance, \n",
    "               color=plt.cm.Greens(np.linspace(0.8, 0.3, len(top_features))))\n",
    "\n",
    "plt.title('ğŸŒ³ Decision Tree Feature Importance (Top 10)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance Value')\n",
    "plt.xticks(range(len(top_features)), [f'Feature_{f}' for f in top_features], rotation=45)\n",
    "\n",
    "# ê°’ ë ˆì´ë¸” ì¶”ê°€\n",
    "for i, (bar, importance) in enumerate(zip(bars, top_10_importance)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(top_10_importance) * 0.01,\n",
    "             f'{importance:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“œ Decision Tree ê·œì¹™ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·œì¹™ ë¶„ì„\n",
    "tree_rules = interpretability['tree_rules']\n",
    "print(f\"ğŸŒ³ ì´ ì¶”ì¶œëœ ê·œì¹™ ìˆ˜: {len(tree_rules)}ê°œ\")\n",
    "print(\"\\nğŸ“‹ Decision Tree ê·œì¹™ ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, rule in enumerate(tree_rules[:20]):\n",
    "    print(f\"{i+1:2d}. {rule}\")\n",
    "\n",
    "if len(tree_rules) > 20:\n",
    "    print(f\"\\n... (ì´ {len(tree_rules)}ê°œ ê·œì¹™ ì¤‘ 20ê°œë§Œ í‘œì‹œ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·œì¹™ êµ¬ì¡° ë¶„ì„\n",
    "def analyze_rules(rules):\n",
    "    \"\"\"ê·œì¹™ì˜ êµ¬ì¡°ì  íŠ¹ì„± ë¶„ì„\"\"\"\n",
    "    analysis = {\n",
    "        'total_rules': len(rules),\n",
    "        'class_0_rules': 0,\n",
    "        'class_1_rules': 0,\n",
    "        'feature_usage': Counter(),\n",
    "        'depth_distribution': Counter(),\n",
    "        'condition_types': Counter()\n",
    "    }\n",
    "    \n",
    "    for rule in rules:\n",
    "        # í´ë˜ìŠ¤ ë¶„í¬\n",
    "        if 'class: 0' in rule:\n",
    "            analysis['class_0_rules'] += 1\n",
    "        elif 'class: 1' in rule:\n",
    "            analysis['class_1_rules'] += 1\n",
    "        \n",
    "        # ê¹Šì´ ê³„ì‚° (|--- ê°œìˆ˜)\n",
    "        depth = rule.count('|---') - 1 if '|---' in rule else 0\n",
    "        analysis['depth_distribution'][depth] += 1\n",
    "        \n",
    "        # íŠ¹ì„± ì‚¬ìš©ëŸ‰ ì¶”ì¶œ\n",
    "        feature_matches = re.findall(r'feature_(\\d+)', rule)\n",
    "        for feature in feature_matches:\n",
    "            analysis['feature_usage'][int(feature)] += 1\n",
    "        \n",
    "        # ì¡°ê±´ íƒ€ì… (<= vs >)\n",
    "        if '<=' in rule:\n",
    "            analysis['condition_types']['<='] += 1\n",
    "        elif '>' in rule:\n",
    "            analysis['condition_types']['>'] += 1\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "rule_analysis = analyze_rules(tree_rules)\n",
    "\n",
    "# ë¶„ì„ ê²°ê³¼ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('ğŸŒ³ Decision Tree ê·œì¹™ êµ¬ì¡° ë¶„ì„', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. í´ë˜ìŠ¤ë³„ ê·œì¹™ ë¶„í¬\n",
    "class_counts = [rule_analysis['class_0_rules'], rule_analysis['class_1_rules']]\n",
    "class_labels = ['Ham (Class 0)', 'Spam (Class 1)']\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "\n",
    "bars = axes[0, 0].bar(class_labels, class_counts, color=colors)\n",
    "axes[0, 0].set_title('í´ë˜ìŠ¤ë³„ ê·œì¹™ ë¶„í¬')\n",
    "axes[0, 0].set_ylabel('ê·œì¹™ ìˆ˜')\n",
    "\n",
    "for bar, count in zip(bars, class_counts):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                     f'{count}ê°œ', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. ê·œì¹™ ê¹Šì´ ë¶„í¬\n",
    "depths = sorted(rule_analysis['depth_distribution'].keys())\n",
    "depth_counts = [rule_analysis['depth_distribution'][d] for d in depths]\n",
    "\n",
    "axes[0, 1].bar(depths, depth_counts, color='lightgreen', alpha=0.7)\n",
    "axes[0, 1].set_title('ê·œì¹™ ê¹Šì´ ë¶„í¬')\n",
    "axes[0, 1].set_xlabel('íŠ¸ë¦¬ ê¹Šì´')\n",
    "axes[0, 1].set_ylabel('ê·œì¹™ ìˆ˜')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŠ¹ì„± Top 15\n",
    "most_used_features = rule_analysis['feature_usage'].most_common(15)\n",
    "features, usage_counts = zip(*most_used_features) if most_used_features else ([], [])\n",
    "\n",
    "axes[1, 0].barh(range(len(features)), usage_counts, color='gold', alpha=0.7)\n",
    "axes[1, 0].set_title('ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŠ¹ì„± (Top 15)')\n",
    "axes[1, 0].set_xlabel('ì‚¬ìš© íšŸìˆ˜')\n",
    "axes[1, 0].set_yticks(range(len(features)))\n",
    "axes[1, 0].set_yticklabels([f'Feature_{f}' for f in features])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. ì¡°ê±´ íƒ€ì… ë¶„í¬\n",
    "condition_types = list(rule_analysis['condition_types'].keys())\n",
    "condition_counts = list(rule_analysis['condition_types'].values())\n",
    "\n",
    "if condition_types:\n",
    "    axes[1, 1].pie(condition_counts, labels=condition_types, autopct='%1.1f%%',\n",
    "                   colors=['lightsteelblue', 'lightsalmon'])\n",
    "    axes[1, 1].set_title('ì¡°ê±´ íƒ€ì… ë¶„í¬ (<= vs >)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê·œì¹™ ë¶„ì„ ìš”ì•½\n",
    "print(\"\\nğŸ“Š ê·œì¹™ êµ¬ì¡° ë¶„ì„ ìš”ì•½\")\n",
    "print(\"=\"*40)\n",
    "print(f\"ì´ ê·œì¹™ ìˆ˜: {rule_analysis['total_rules']}ê°œ\")\n",
    "print(f\"Ham(0) ê·œì¹™: {rule_analysis['class_0_rules']}ê°œ\")\n",
    "print(f\"Spam(1) ê·œì¹™: {rule_analysis['class_1_rules']}ê°œ\")\n",
    "print(f\"ìµœëŒ€ ê¹Šì´: {max(rule_analysis['depth_distribution'].keys()) if rule_analysis['depth_distribution'] else 0}\")\n",
    "print(f\"ì‚¬ìš©ëœ ê³ ìœ  íŠ¹ì„± ìˆ˜: {len(rule_analysis['feature_usage'])}ê°œ\")\n",
    "if most_used_features:\n",
    "    print(f\"ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±: Feature_{most_used_features[0][0]} ({most_used_features[0][1]}íšŒ ì‚¬ìš©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›¤ï¸ ì˜ì‚¬ê²°ì • ê²½ë¡œ ì¶”ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ì˜ì‚¬ê²°ì • ê²½ë¡œ ì¶”ì¶œ\n",
    "def extract_decision_paths(rules):\n",
    "    \"\"\"ì£¼ìš” ì˜ì‚¬ê²°ì • ê²½ë¡œë¥¼ ì¶”ì¶œí•˜ê³  ë¶„ì„\"\"\"\n",
    "    paths = {\n",
    "        'spam_paths': [],\n",
    "        'ham_paths': []\n",
    "    }\n",
    "    \n",
    "    current_path = []\n",
    "    \n",
    "    for rule in rules:\n",
    "        if 'class:' in rule:\n",
    "            # ê²½ë¡œ ì™„ì„±\n",
    "            if 'class: 1' in rule:\n",
    "                paths['spam_paths'].append(current_path.copy())\n",
    "            elif 'class: 0' in rule:\n",
    "                paths['ham_paths'].append(current_path.copy())\n",
    "            \n",
    "            # ê²½ë¡œ ê¸¸ì´ì— ë”°ë¼ ë°±íŠ¸ë˜í‚¹\n",
    "            depth = rule.count('|')\n",
    "            current_path = current_path[:depth//4]\n",
    "        else:\n",
    "            # ì¡°ê±´ ì¶”ê°€\n",
    "            depth = rule.count('|')\n",
    "            target_depth = depth // 4\n",
    "            \n",
    "            # ê²½ë¡œ ì¡°ì •\n",
    "            current_path = current_path[:target_depth]\n",
    "            \n",
    "            # ì¡°ê±´ ì¶”ì¶œ\n",
    "            condition = rule.strip().replace('|--- ', '')\n",
    "            current_path.append(condition)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "decision_paths = extract_decision_paths(tree_rules)\n",
    "\n",
    "print(\"ğŸ›¤ï¸ ì£¼ìš” ì˜ì‚¬ê²°ì • ê²½ë¡œ ë¶„ì„\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ìŠ¤íŒ¸ íŒì • ê²½ë¡œ: {len(decision_paths['spam_paths'])}ê°œ\")\n",
    "print(f\"í–„ íŒì • ê²½ë¡œ: {len(decision_paths['ham_paths'])}ê°œ\")\n",
    "\n",
    "# ê°€ì¥ ì§§ì€ ìŠ¤íŒ¸ íŒì • ê²½ë¡œ\n",
    "if decision_paths['spam_paths']:\n",
    "    shortest_spam = min(decision_paths['spam_paths'], key=len)\n",
    "    print(f\"\\nğŸš¨ ê°€ì¥ ê°„ë‹¨í•œ ìŠ¤íŒ¸ íŒì • ê²½ë¡œ ({len(shortest_spam)}ë‹¨ê³„):\")\n",
    "    for i, condition in enumerate(shortest_spam, 1):\n",
    "        print(f\"  {i}. {condition}\")\n",
    "    print(\"  â†’ ê²°ê³¼: SPAM\")\n",
    "\n",
    "# ê°€ì¥ ì§§ì€ í–„ íŒì • ê²½ë¡œ\n",
    "if decision_paths['ham_paths']:\n",
    "    shortest_ham = min(decision_paths['ham_paths'], key=len)\n",
    "    print(f\"\\nâœ… ê°€ì¥ ê°„ë‹¨í•œ í–„ íŒì • ê²½ë¡œ ({len(shortest_ham)}ë‹¨ê³„):\")\n",
    "    for i, condition in enumerate(shortest_ham, 1):\n",
    "        print(f\"  {i}. {condition}\")\n",
    "    print(\"  â†’ ê²°ê³¼: HAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree í™œìš© ì‹œë‚˜ë¦¬ì˜¤\n",
    "print(\"ğŸ’¼ Decision Tree ì‹¤ì œ í™œìš© ì‹œë‚˜ë¦¬ì˜¤\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "scenarios = [\n",
    "    {\n",
    "        'title': 'ğŸš€ ì‹¤ì‹œê°„ ì´ë©”ì¼ í•„í„°ë§',\n",
    "        'description': 'Rule ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥¸ íŒì •',\n",
    "        'advantages': ['ì¶”ë¡  ì†ë„ ë§¤ìš° ë¹ ë¦„', 'í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë‚®ìŒ', 'CPUë§Œìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥'],\n",
    "        'use_case': 'ëŒ€ìš©ëŸ‰ ì´ë©”ì¼ ì„œë²„ì—ì„œ ì‹¤ì‹œê°„ ìŠ¤íŒ¸ ì°¨ë‹¨'\n",
    "    },\n",
    "    {\n",
    "        'title': 'ğŸ” ë³´ì•ˆ ê°ì‚¬ ë° ê·œì¹™ ê²€ì¦',\n",
    "        'description': 'ì˜ì‚¬ê²°ì • ê³¼ì • ì™„ì „ ì¶”ì  ê°€ëŠ¥',\n",
    "        'advantages': ['ëª¨ë“  íŒì • ê·¼ê±° ì œê³µ', 'ê·œì œ ì¤€ìˆ˜ ìš©ì´', 'ê°ì‚¬ ë¡œê·¸ ìë™ ìƒì„±'],\n",
    "        'use_case': 'ê¸ˆìœµê¶Œ, ì •ë¶€ê¸°ê´€ì—ì„œ íˆ¬ëª…í•œ ìŠ¤íŒ¸ í•„í„°ë§'\n",
    "    },\n",
    "    {\n",
    "        'title': 'ğŸ“ êµìœ¡ ë° ì„¤ëª…',\n",
    "        'description': 'ë¹„ì „ë¬¸ê°€ë„ ì´í•´ ê°€ëŠ¥í•œ ê·œì¹™',\n",
    "        'advantages': ['ì§ê´€ì  ì´í•´', 'ë„ë©”ì¸ ì „ë¬¸ê°€ ê²€ì¦ ê°€ëŠ¥', 'ì‚¬ìš©ì ì‹ ë¢°ë„ í–¥ìƒ'],\n",
    "        'use_case': 'ê¸°ì—… ë‚´ë¶€ êµìœ¡, ì‚¬ìš©ì ê°€ì´ë“œë¼ì¸ ì œì‘'\n",
    "    },\n",
    "    {\n",
    "        'title': 'ğŸ› ï¸ ê·œì¹™ ìµœì í™” ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•',\n",
    "        'description': 'íŠ¹ì • ë„ë©”ì¸ì— ë§ëŠ” ê·œì¹™ ì¡°ì •',\n",
    "        'advantages': ['ìˆ˜ë™ ê·œì¹™ ì¡°ì • ê°€ëŠ¥', 'ë„ë©”ì¸ë³„ íŠ¹í™”', 'ì ì§„ì  ê°œì„ '],\n",
    "        'use_case': 'íŠ¹ìˆ˜ ë¶„ì•¼(ì˜ë£Œ, ë²•ë¥  ë“±) ë§ì¶¤í˜• ìŠ¤íŒ¸ í•„í„°'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"\\n{i}. {scenario['title']}\")\n",
    "    print(f\"   ì„¤ëª…: {scenario['description']}\")\n",
    "    print(f\"   ì¥ì : {', '.join(scenario['advantages'])}\")\n",
    "    print(f\"   í™œìš©ì‚¬ë¡€: {scenario['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš–ï¸ ì¥ë‹¨ì  ë¹„êµ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree ì¥ë‹¨ì  ì‹œê°í™”\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.suptitle('ğŸŒ³ Decision Tree ì¥ë‹¨ì  ë¶„ì„', fontsize=16, y=0.95)\n",
    "\n",
    "# ì¥ì \n",
    "advantages = {\n",
    "    'í•´ì„ê°€ëŠ¥ì„±': 10,\n",
    "    'ì¶”ë¡  ì†ë„': 9,\n",
    "    'íˆ¬ëª…ì„±': 10,\n",
    "    'êµ¬í˜„ ìš©ì´ì„±': 8,\n",
    "    'ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±': 9,\n",
    "    'í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­': 9,\n",
    "    'ë””ë²„ê¹… ìš©ì´ì„±': 10,\n",
    "    'ê·œì œ ì¤€ìˆ˜': 10\n",
    "}\n",
    "\n",
    "# ë‹¨ì  (ì—­ì ìˆ˜ë¡œ í‘œí˜„)\n",
    "disadvantages = {\n",
    "    'ê³¼ì í•© ìœ„í—˜': 6,\n",
    "    'ë³µì¡í•œ íŒ¨í„´ í¬ì°©': 5,\n",
    "    'ì—°ì†ê°’ ì²˜ë¦¬': 6,\n",
    "    'ë…¸ì´ì¦ˆ ë¯¼ê°ì„±': 5,\n",
    "    'ë¶ˆì•ˆì •ì„±': 6,\n",
    "    'ë¹„ì„ í˜• ê´€ê³„': 5,\n",
    "    'íŠ¹ì„± ìƒí˜¸ì‘ìš©': 6,\n",
    "    'ì¼ë°˜í™” ëŠ¥ë ¥': 7\n",
    "}\n",
    "\n",
    "# ì¥ì  ì‹œê°í™”\n",
    "adv_items = list(advantages.keys())\n",
    "adv_scores = list(advantages.values())\n",
    "\n",
    "bars1 = ax1.barh(adv_items, adv_scores, color='lightgreen', alpha=0.8)\n",
    "ax1.set_title('âœ… ì¥ì  (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, color='darkgreen')\n",
    "ax1.set_xlabel('ì ìˆ˜ (1-10)')\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ì ìˆ˜ ë ˆì´ë¸”\n",
    "for bar, score in zip(bars1, adv_scores):\n",
    "    ax1.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score}', va='center', fontweight='bold')\n",
    "\n",
    "# ë‹¨ì  ì‹œê°í™”\n",
    "dis_items = list(disadvantages.keys())\n",
    "dis_scores = list(disadvantages.values())\n",
    "\n",
    "bars2 = ax2.barh(dis_items, dis_scores, color='lightcoral', alpha=0.8)\n",
    "ax2.set_title('âš ï¸ í•œê³„ì  (ë‚®ì„ìˆ˜ë¡ ë¬¸ì œ)', fontsize=14, color='darkred')\n",
    "ax2.set_xlabel('ì ìˆ˜ (1-10)')\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# ì ìˆ˜ ë ˆì´ë¸”\n",
    "for bar, score in zip(bars2, dis_scores):\n",
    "    ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì¢…í•© í‰ê°€\n",
    "total_advantages = sum(advantages.values())\n",
    "total_disadvantages = sum(disadvantages.values())\n",
    "overall_score = total_advantages / (total_advantages + (80 - total_disadvantages))\n",
    "\n",
    "print(f\"\\nğŸ“Š ì¢…í•© í‰ê°€\")\n",
    "print(f\"ì¥ì  ì´ì : {total_advantages}/80 ({total_advantages/80*100:.1f}%)\")\n",
    "print(f\"ë‹¨ì  ë³´ì™„: {total_disadvantages}/80 ({total_disadvantages/80*100:.1f}%)\")\n",
    "print(f\"ì¢…í•© ì ìˆ˜: {overall_score:.3f} ({overall_score*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê¶Œì¥ì‚¬í•­ ìš”ì•½\n",
    "print(\"ğŸ¯ Decision Tree ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ† í•µì‹¬ ì„±ê³¼:\")\n",
    "achievements = [\n",
    "    f\"âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥: {test_results['accuracy']*100:.2f}% ì •í™•ë„\",\n",
    "    f\"âš¡ ë¹ ë¥¸ í›ˆë ¨: {training_results['total_training_time']/60:.1f}ë¶„\",\n",
    "    f\"ğŸ” ì™„ì „í•œ í•´ì„ê°€ëŠ¥ì„±: {len(tree_rules)}ê°œ ê·œì¹™ ì œê³µ\",\n",
    "    f\"ğŸ“Š ì™„ë²½í•œ AUC: {test_results['auc_score']*100:.2f}%\",\n",
    "    \"ğŸš€ ì‹¤ì‹œê°„ ì¶”ë¡  ê°€ëŠ¥\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"  {achievement}\")\n",
    "\n",
    "print(\"\\nğŸ’¼ ì¶”ì²œ ì‚¬ìš© ì‚¬ë¡€:\")\n",
    "recommendations = [\n",
    "    \"ğŸ¢ ê¸°ì—… í™˜ê²½: íˆ¬ëª…í•œ ì˜ì‚¬ê²°ì •ì´ ì¤‘ìš”í•œ ê²½ìš°\",\n",
    "    \"ğŸ›ï¸ ê·œì œ ì‚°ì—…: ê¸ˆìœµ, ì˜ë£Œ, ì •ë¶€ ê¸°ê´€\",\n",
    "    \"ğŸ“š êµìœ¡ ëª©ì : AI ì˜ì‚¬ê²°ì • ê³¼ì • ì„¤ëª…\",\n",
    "    \"âš¡ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ: ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•œ í™˜ê²½\",\n",
    "    \"ğŸ”§ í”„ë¡œí† íƒ€ì´í•‘: ë¹ ë¥¸ ê°œë°œê³¼ ê²€ì¦\"\n",
    "]\n",
    "\n",
    "for recommendation in recommendations:\n",
    "    print(f\"  {recommendation}\")\n",
    "\n",
    "print(\"\\nâš ï¸ ì£¼ì˜ì‚¬í•­:\")\n",
    "cautions = [\n",
    "    \"ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ì—ëŠ” í•œê³„ ì¡´ì¬\",\n",
    "    \"ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì •ê¸°ì ì¸ ê²€ì¦ í•„ìš”\",\n",
    "    \"ìƒˆë¡œìš´ ê³µê²© íŒ¨í„´ì— ëŒ€í•œ ê·œì¹™ ì—…ë°ì´íŠ¸ í•„ìš”\",\n",
    "    \"ê·¹ë„ë¡œ ë³µì¡í•œ ê²½ìš° ë‹¤ë¥¸ ì•™ìƒë¸” ë°©ë²• ê³ ë ¤\"\n",
    "]\n",
    "\n",
    "for caution in cautions:\n",
    "    print(f\"  âš ï¸ {caution}\")\n",
    "\n",
    "print(\"\\nğŸŒŸ ìµœì¢… ê²°ë¡ :\")\n",
    "print(\"Decision TreeëŠ” í•´ì„ê°€ëŠ¥ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•ì´ ë›°ì–´ë‚œ\")\n",
    "print(\"ì‹¤ìš©ì ì¸ ì„ íƒìœ¼ë¡œ, íŠ¹íˆ íˆ¬ëª…ì„±ì´ ì¤‘ìš”í•œ í™˜ê²½ì—ì„œ\")\n",
    "print(\"íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ ìš”ì•½:\")\n",
    "print(f\"  ğŸ¯ ì •í™•ë„: {test_results['accuracy']*100:.4f}%\")\n",
    "print(f\"  âš¡ íš¨ìœ¨ì„±: {training_results['total_training_time']/60:.1f}ë¶„ í›ˆë ¨\")\n",
    "print(f\"  ğŸ” í•´ì„ì„±: {len(tree_rules)}ê°œ ëª…í™•í•œ ê·œì¹™\")\n",
    "print(f\"  ğŸ“Š ì‹ ë¢°ë„: {test_results['auc_score']*100:.2f}% AUC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 