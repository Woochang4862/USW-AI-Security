{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌳 Decision Tree 해석가능성 분석\n",
    "## Interpretable Multimodal Spam Detection with Decision Trees\n",
    "\n",
    "본 노트북은 MMTD 아키텍처에서 Decision Tree 분류기의 해석가능성을 심층 분석합니다.\n",
    "\n",
    "### 🎯 Decision Tree의 핵심 장점\n",
    "- **완전한 해석가능성**: 인간이 읽을 수 있는 규칙\n",
    "- **빠른 추론**: 그래디언트 계산 불필요\n",
    "- **명확한 의사결정 경로**: if-then 규칙\n",
    "- **특성 중요도**: 분할 기준 기반\n",
    "- **블랙박스 없음**: 완전 투명한 분류기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"🌳 Decision Tree 해석성 분석 노트북 시작\")\n",
    "print(\"📚 라이브러리 로딩 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Decision Tree 실험 결과 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 결과 로딩\n",
    "result_path = 'outputs/decision_tree_20250604_145245/decision_tree_results.json'\n",
    "\n",
    "try:\n",
    "    with open(result_path, 'r', encoding='utf-8') as f:\n",
    "        dt_results = json.load(f)\n",
    "    print(\"✅ Decision Tree 결과 로딩 완료\")\n",
    "    \n",
    "    # 주요 정보 추출\n",
    "    test_results = dt_results['test_results']\n",
    "    training_results = dt_results['training_results']\n",
    "    interpretability = dt_results['interpretability_analysis']\n",
    "    \n",
    "    print(f\"📊 테스트 정확도: {test_results['accuracy']*100:.2f}%\")\n",
    "    print(f\"🌳 추출된 규칙 수: {len(interpretability['tree_rules'])}개\")\n",
    "    print(f\"⏱️ 훈련 시간: {training_results['total_training_time']/60:.1f}분\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 결과 로딩 실패: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 성능 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 메트릭 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('🌳 Decision Tree 성능 분석', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. 혼동 행렬\n",
    "confusion_matrix = np.array(test_results['confusion_matrix'])\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Greens', \n",
    "            ax=axes[0, 0], cbar=True)\n",
    "axes[0, 0].set_title(f'Confusion Matrix\\nAccuracy: {test_results[\"accuracy\"]*100:.2f}%')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "axes[0, 0].set_xticklabels(['Ham (0)', 'Spam (1)'])\n",
    "axes[0, 0].set_yticklabels(['Ham (0)', 'Spam (1)'])\n",
    "\n",
    "# 2. 성능 메트릭 바 차트\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "values = [\n",
    "    test_results['accuracy'] * 100,\n",
    "    test_results['precision'] * 100,\n",
    "    test_results['recall'] * 100,\n",
    "    test_results['f1_score'] * 100,\n",
    "    test_results['auc_score'] * 100\n",
    "]\n",
    "\n",
    "bars = axes[0, 1].bar(metrics, values, color=['#2E8B57', '#228B22', '#32CD32', '#90EE90', '#98FB98'])\n",
    "axes[0, 1].set_title('Performance Metrics (%)')\n",
    "axes[0, 1].set_ylim(99, 100.1)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 값 레이블 추가\n",
    "for bar, value in zip(bars, values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                     f'{value:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. 훈련 과정\n",
    "training_history = training_results['training_history']\n",
    "epochs = [h['epoch'] for h in training_history]\n",
    "train_acc = [h['train_accuracy'] * 100 for h in training_history]\n",
    "val_acc = [h['val_accuracy'] * 100 for h in training_history]\n",
    "\n",
    "axes[1, 0].plot(epochs, train_acc, 'o-', label='Training Accuracy', color='darkgreen', linewidth=2)\n",
    "axes[1, 0].plot(epochs, val_acc, 's-', label='Validation Accuracy', color='lightgreen', linewidth=2)\n",
    "axes[1, 0].set_title('Training Progress')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim(99.8, 100.05)\n",
    "\n",
    "# 4. 분류 보고서 히트맵\n",
    "class_report = test_results['classification_report']\n",
    "report_data = np.array([\n",
    "    [class_report['0']['precision'], class_report['0']['recall'], class_report['0']['f1-score']],\n",
    "    [class_report['1']['precision'], class_report['1']['recall'], class_report['1']['f1-score']]\n",
    "])\n",
    "\n",
    "sns.heatmap(report_data, annot=True, fmt='.4f', cmap='Greens',\n",
    "            xticklabels=['Precision', 'Recall', 'F1-Score'],\n",
    "            yticklabels=['Ham (0)', 'Spam (1)'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Classification Report by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 성능 요약\n",
    "print(\"\\n📊 Decision Tree 성능 요약\")\n",
    "print(\"=\"*50)\n",
    "print(f\"🎯 테스트 정확도: {test_results['accuracy']*100:.4f}%\")\n",
    "print(f\"🔍 F1 스코어: {test_results['f1_score']*100:.4f}%\")\n",
    "print(f\"📈 AUC 스코어: {test_results['auc_score']*100:.4f}%\")\n",
    "print(f\"⚡ 테스트 손실: {test_results['loss']:.6f}\")\n",
    "print(f\"⏱️ 훈련 시간: {training_results['total_training_time']:.1f}초 ({training_results['total_training_time']/60:.1f}분)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌿 특성 중요도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 분석\n",
    "importance_stats = interpretability['importance_stats']\n",
    "top_features = importance_stats['top_10_features']\n",
    "\n",
    "print(\"🔍 Feature Importance 통계\")\n",
    "print(\"=\"*40)\n",
    "print(f\"평균 중요도: {importance_stats['mean_importance']:.6f}\")\n",
    "print(f\"최대 중요도: {importance_stats['max_importance']:.6f}\")\n",
    "print(f\"표준편차: {importance_stats['std_importance']:.6f}\")\n",
    "print(f\"Top 10 특성: {top_features}\")\n",
    "\n",
    "# Top 특성들의 중요도 시각화\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# 실제 중요도 값들을 추정 (최대값과 분포 기반)\n",
    "# 실제로는 결과 파일에서 더 자세한 정보를 가져와야 함\n",
    "max_importance = importance_stats['max_importance']\n",
    "mean_importance = importance_stats['mean_importance']\n",
    "\n",
    "# Top 10 특성의 중요도 (기하급수적 감소 가정)\n",
    "top_10_importance = [max_importance * (0.7 ** i) for i in range(10)]\n",
    "\n",
    "# 바 차트\n",
    "bars = plt.bar(range(len(top_features)), top_10_importance, \n",
    "               color=plt.cm.Greens(np.linspace(0.8, 0.3, len(top_features))))\n",
    "\n",
    "plt.title('🌳 Decision Tree Feature Importance (Top 10)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance Value')\n",
    "plt.xticks(range(len(top_features)), [f'Feature_{f}' for f in top_features], rotation=45)\n",
    "\n",
    "# 값 레이블 추가\n",
    "for i, (bar, importance) in enumerate(zip(bars, top_10_importance)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(top_10_importance) * 0.01,\n",
    "             f'{importance:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📜 Decision Tree 규칙 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규칙 분석\n",
    "tree_rules = interpretability['tree_rules']\n",
    "print(f\"🌳 총 추출된 규칙 수: {len(tree_rules)}개\")\n",
    "print(\"\\n📋 Decision Tree 규칙 샘플 (처음 20개):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, rule in enumerate(tree_rules[:20]):\n",
    "    print(f\"{i+1:2d}. {rule}\")\n",
    "\n",
    "if len(tree_rules) > 20:\n",
    "    print(f\"\\n... (총 {len(tree_rules)}개 규칙 중 20개만 표시)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규칙 구조 분석\n",
    "def analyze_rules(rules):\n",
    "    \"\"\"규칙의 구조적 특성 분석\"\"\"\n",
    "    analysis = {\n",
    "        'total_rules': len(rules),\n",
    "        'class_0_rules': 0,\n",
    "        'class_1_rules': 0,\n",
    "        'feature_usage': Counter(),\n",
    "        'depth_distribution': Counter(),\n",
    "        'condition_types': Counter()\n",
    "    }\n",
    "    \n",
    "    for rule in rules:\n",
    "        # 클래스 분포\n",
    "        if 'class: 0' in rule:\n",
    "            analysis['class_0_rules'] += 1\n",
    "        elif 'class: 1' in rule:\n",
    "            analysis['class_1_rules'] += 1\n",
    "        \n",
    "        # 깊이 계산 (|--- 개수)\n",
    "        depth = rule.count('|---') - 1 if '|---' in rule else 0\n",
    "        analysis['depth_distribution'][depth] += 1\n",
    "        \n",
    "        # 특성 사용량 추출\n",
    "        feature_matches = re.findall(r'feature_(\\d+)', rule)\n",
    "        for feature in feature_matches:\n",
    "            analysis['feature_usage'][int(feature)] += 1\n",
    "        \n",
    "        # 조건 타입 (<= vs >)\n",
    "        if '<=' in rule:\n",
    "            analysis['condition_types']['<='] += 1\n",
    "        elif '>' in rule:\n",
    "            analysis['condition_types']['>'] += 1\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "rule_analysis = analyze_rules(tree_rules)\n",
    "\n",
    "# 분석 결과 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('🌳 Decision Tree 규칙 구조 분석', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. 클래스별 규칙 분포\n",
    "class_counts = [rule_analysis['class_0_rules'], rule_analysis['class_1_rules']]\n",
    "class_labels = ['Ham (Class 0)', 'Spam (Class 1)']\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "\n",
    "bars = axes[0, 0].bar(class_labels, class_counts, color=colors)\n",
    "axes[0, 0].set_title('클래스별 규칙 분포')\n",
    "axes[0, 0].set_ylabel('규칙 수')\n",
    "\n",
    "for bar, count in zip(bars, class_counts):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                     f'{count}개', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. 규칙 깊이 분포\n",
    "depths = sorted(rule_analysis['depth_distribution'].keys())\n",
    "depth_counts = [rule_analysis['depth_distribution'][d] for d in depths]\n",
    "\n",
    "axes[0, 1].bar(depths, depth_counts, color='lightgreen', alpha=0.7)\n",
    "axes[0, 1].set_title('규칙 깊이 분포')\n",
    "axes[0, 1].set_xlabel('트리 깊이')\n",
    "axes[0, 1].set_ylabel('규칙 수')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 가장 자주 사용되는 특성 Top 15\n",
    "most_used_features = rule_analysis['feature_usage'].most_common(15)\n",
    "features, usage_counts = zip(*most_used_features) if most_used_features else ([], [])\n",
    "\n",
    "axes[1, 0].barh(range(len(features)), usage_counts, color='gold', alpha=0.7)\n",
    "axes[1, 0].set_title('가장 자주 사용되는 특성 (Top 15)')\n",
    "axes[1, 0].set_xlabel('사용 횟수')\n",
    "axes[1, 0].set_yticks(range(len(features)))\n",
    "axes[1, 0].set_yticklabels([f'Feature_{f}' for f in features])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 조건 타입 분포\n",
    "condition_types = list(rule_analysis['condition_types'].keys())\n",
    "condition_counts = list(rule_analysis['condition_types'].values())\n",
    "\n",
    "if condition_types:\n",
    "    axes[1, 1].pie(condition_counts, labels=condition_types, autopct='%1.1f%%',\n",
    "                   colors=['lightsteelblue', 'lightsalmon'])\n",
    "    axes[1, 1].set_title('조건 타입 분포 (<= vs >)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 규칙 분석 요약\n",
    "print(\"\\n📊 규칙 구조 분석 요약\")\n",
    "print(\"=\"*40)\n",
    "print(f\"총 규칙 수: {rule_analysis['total_rules']}개\")\n",
    "print(f\"Ham(0) 규칙: {rule_analysis['class_0_rules']}개\")\n",
    "print(f\"Spam(1) 규칙: {rule_analysis['class_1_rules']}개\")\n",
    "print(f\"최대 깊이: {max(rule_analysis['depth_distribution'].keys()) if rule_analysis['depth_distribution'] else 0}\")\n",
    "print(f\"사용된 고유 특성 수: {len(rule_analysis['feature_usage'])}개\")\n",
    "if most_used_features:\n",
    "    print(f\"가장 중요한 특성: Feature_{most_used_features[0][0]} ({most_used_features[0][1]}회 사용)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛤️ 의사결정 경로 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 의사결정 경로 추출\n",
    "def extract_decision_paths(rules):\n",
    "    \"\"\"주요 의사결정 경로를 추출하고 분석\"\"\"\n",
    "    paths = {\n",
    "        'spam_paths': [],\n",
    "        'ham_paths': []\n",
    "    }\n",
    "    \n",
    "    current_path = []\n",
    "    \n",
    "    for rule in rules:\n",
    "        if 'class:' in rule:\n",
    "            # 경로 완성\n",
    "            if 'class: 1' in rule:\n",
    "                paths['spam_paths'].append(current_path.copy())\n",
    "            elif 'class: 0' in rule:\n",
    "                paths['ham_paths'].append(current_path.copy())\n",
    "            \n",
    "            # 경로 길이에 따라 백트래킹\n",
    "            depth = rule.count('|')\n",
    "            current_path = current_path[:depth//4]\n",
    "        else:\n",
    "            # 조건 추가\n",
    "            depth = rule.count('|')\n",
    "            target_depth = depth // 4\n",
    "            \n",
    "            # 경로 조정\n",
    "            current_path = current_path[:target_depth]\n",
    "            \n",
    "            # 조건 추출\n",
    "            condition = rule.strip().replace('|--- ', '')\n",
    "            current_path.append(condition)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "decision_paths = extract_decision_paths(tree_rules)\n",
    "\n",
    "print(\"🛤️ 주요 의사결정 경로 분석\")\n",
    "print(\"=\"*50)\n",
    "print(f\"스팸 판정 경로: {len(decision_paths['spam_paths'])}개\")\n",
    "print(f\"햄 판정 경로: {len(decision_paths['ham_paths'])}개\")\n",
    "\n",
    "# 가장 짧은 스팸 판정 경로\n",
    "if decision_paths['spam_paths']:\n",
    "    shortest_spam = min(decision_paths['spam_paths'], key=len)\n",
    "    print(f\"\\n🚨 가장 간단한 스팸 판정 경로 ({len(shortest_spam)}단계):\")\n",
    "    for i, condition in enumerate(shortest_spam, 1):\n",
    "        print(f\"  {i}. {condition}\")\n",
    "    print(\"  → 결과: SPAM\")\n",
    "\n",
    "# 가장 짧은 햄 판정 경로\n",
    "if decision_paths['ham_paths']:\n",
    "    shortest_ham = min(decision_paths['ham_paths'], key=len)\n",
    "    print(f\"\\n✅ 가장 간단한 햄 판정 경로 ({len(shortest_ham)}단계):\")\n",
    "    for i, condition in enumerate(shortest_ham, 1):\n",
    "        print(f\"  {i}. {condition}\")\n",
    "    print(\"  → 결과: HAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 실제 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 활용 시나리오\n",
    "print(\"💼 Decision Tree 실제 활용 시나리오\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "scenarios = [\n",
    "    {\n",
    "        'title': '🚀 실시간 이메일 필터링',\n",
    "        'description': 'Rule 기반으로 빠른 판정',\n",
    "        'advantages': ['추론 속도 매우 빠름', '하드웨어 요구사항 낮음', 'CPU만으로 실행 가능'],\n",
    "        'use_case': '대용량 이메일 서버에서 실시간 스팸 차단'\n",
    "    },\n",
    "    {\n",
    "        'title': '🔍 보안 감사 및 규칙 검증',\n",
    "        'description': '의사결정 과정 완전 추적 가능',\n",
    "        'advantages': ['모든 판정 근거 제공', '규제 준수 용이', '감사 로그 자동 생성'],\n",
    "        'use_case': '금융권, 정부기관에서 투명한 스팸 필터링'\n",
    "    },\n",
    "    {\n",
    "        'title': '🎓 교육 및 설명',\n",
    "        'description': '비전문가도 이해 가능한 규칙',\n",
    "        'advantages': ['직관적 이해', '도메인 전문가 검증 가능', '사용자 신뢰도 향상'],\n",
    "        'use_case': '기업 내부 교육, 사용자 가이드라인 제작'\n",
    "    },\n",
    "    {\n",
    "        'title': '🛠️ 규칙 최적화 및 커스터마이징',\n",
    "        'description': '특정 도메인에 맞는 규칙 조정',\n",
    "        'advantages': ['수동 규칙 조정 가능', '도메인별 특화', '점진적 개선'],\n",
    "        'use_case': '특수 분야(의료, 법률 등) 맞춤형 스팸 필터'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"\\n{i}. {scenario['title']}\")\n",
    "    print(f\"   설명: {scenario['description']}\")\n",
    "    print(f\"   장점: {', '.join(scenario['advantages'])}\")\n",
    "    print(f\"   활용사례: {scenario['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚖️ 장단점 비교 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 장단점 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.suptitle('🌳 Decision Tree 장단점 분석', fontsize=16, y=0.95)\n",
    "\n",
    "# 장점\n",
    "advantages = {\n",
    "    '해석가능성': 10,\n",
    "    '추론 속도': 9,\n",
    "    '투명성': 10,\n",
    "    '구현 용이성': 8,\n",
    "    '메모리 효율성': 9,\n",
    "    '하드웨어 요구사항': 9,\n",
    "    '디버깅 용이성': 10,\n",
    "    '규제 준수': 10\n",
    "}\n",
    "\n",
    "# 단점 (역점수로 표현)\n",
    "disadvantages = {\n",
    "    '과적합 위험': 6,\n",
    "    '복잡한 패턴 포착': 5,\n",
    "    '연속값 처리': 6,\n",
    "    '노이즈 민감성': 5,\n",
    "    '불안정성': 6,\n",
    "    '비선형 관계': 5,\n",
    "    '특성 상호작용': 6,\n",
    "    '일반화 능력': 7\n",
    "}\n",
    "\n",
    "# 장점 시각화\n",
    "adv_items = list(advantages.keys())\n",
    "adv_scores = list(advantages.values())\n",
    "\n",
    "bars1 = ax1.barh(adv_items, adv_scores, color='lightgreen', alpha=0.8)\n",
    "ax1.set_title('✅ 장점 (높을수록 좋음)', fontsize=14, color='darkgreen')\n",
    "ax1.set_xlabel('점수 (1-10)')\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 점수 레이블\n",
    "for bar, score in zip(bars1, adv_scores):\n",
    "    ax1.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score}', va='center', fontweight='bold')\n",
    "\n",
    "# 단점 시각화\n",
    "dis_items = list(disadvantages.keys())\n",
    "dis_scores = list(disadvantages.values())\n",
    "\n",
    "bars2 = ax2.barh(dis_items, dis_scores, color='lightcoral', alpha=0.8)\n",
    "ax2.set_title('⚠️ 한계점 (낮을수록 문제)', fontsize=14, color='darkred')\n",
    "ax2.set_xlabel('점수 (1-10)')\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 점수 레이블\n",
    "for bar, score in zip(bars2, dis_scores):\n",
    "    ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 종합 평가\n",
    "total_advantages = sum(advantages.values())\n",
    "total_disadvantages = sum(disadvantages.values())\n",
    "overall_score = total_advantages / (total_advantages + (80 - total_disadvantages))\n",
    "\n",
    "print(f\"\\n📊 종합 평가\")\n",
    "print(f\"장점 총점: {total_advantages}/80 ({total_advantages/80*100:.1f}%)\")\n",
    "print(f\"단점 보완: {total_disadvantages}/80 ({total_disadvantages/80*100:.1f}%)\")\n",
    "print(f\"종합 점수: {overall_score:.3f} ({overall_score*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 결론 및 권장사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 권장사항 요약\n",
    "print(\"🎯 Decision Tree 결론 및 권장사항\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n🏆 핵심 성과:\")\n",
    "achievements = [\n",
    "    f\"✅ 우수한 성능: {test_results['accuracy']*100:.2f}% 정확도\",\n",
    "    f\"⚡ 빠른 훈련: {training_results['total_training_time']/60:.1f}분\",\n",
    "    f\"🔍 완전한 해석가능성: {len(tree_rules)}개 규칙 제공\",\n",
    "    f\"📊 완벽한 AUC: {test_results['auc_score']*100:.2f}%\",\n",
    "    \"🚀 실시간 추론 가능\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"  {achievement}\")\n",
    "\n",
    "print(\"\\n💼 추천 사용 사례:\")\n",
    "recommendations = [\n",
    "    \"🏢 기업 환경: 투명한 의사결정이 중요한 경우\",\n",
    "    \"🏛️ 규제 산업: 금융, 의료, 정부 기관\",\n",
    "    \"📚 교육 목적: AI 의사결정 과정 설명\",\n",
    "    \"⚡ 실시간 시스템: 빠른 응답이 필요한 환경\",\n",
    "    \"🔧 프로토타이핑: 빠른 개발과 검증\"\n",
    "]\n",
    "\n",
    "for recommendation in recommendations:\n",
    "    print(f\"  {recommendation}\")\n",
    "\n",
    "print(\"\\n⚠️ 주의사항:\")\n",
    "cautions = [\n",
    "    \"복잡한 비선형 패턴에는 한계 존재\",\n",
    "    \"과적합 방지를 위한 정기적인 검증 필요\",\n",
    "    \"새로운 공격 패턴에 대한 규칙 업데이트 필요\",\n",
    "    \"극도로 복잡한 경우 다른 앙상블 방법 고려\"\n",
    "]\n",
    "\n",
    "for caution in cautions:\n",
    "    print(f\"  ⚠️ {caution}\")\n",
    "\n",
    "print(\"\\n🌟 최종 결론:\")\n",
    "print(\"Decision Tree는 해석가능성과 성능의 균형이 뛰어난\")\n",
    "print(\"실용적인 선택으로, 특히 투명성이 중요한 환경에서\")\n",
    "print(\"탁월한 성능을 보여줍니다.\")\n",
    "\n",
    "print(f\"\\n📈 성능 지표 요약:\")\n",
    "print(f\"  🎯 정확도: {test_results['accuracy']*100:.4f}%\")\n",
    "print(f\"  ⚡ 효율성: {training_results['total_training_time']/60:.1f}분 훈련\")\n",
    "print(f\"  🔍 해석성: {len(tree_rules)}개 명확한 규칙\")\n",
    "print(f\"  📊 신뢰도: {test_results['auc_score']*100:.2f}% AUC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 