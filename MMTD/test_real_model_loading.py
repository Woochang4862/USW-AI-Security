import torch
import sys
import os
from pathlib import Path

# ν„μ¬ λ””λ ‰ν„°λ¦¬λ¥Ό Python pathμ— μ¶”κ°€
sys.path.append('.')

try:
    from models import MMTD
    print("β… MMTD λ¨λΈ ν΄λμ¤ import μ„±κ³µ")
except ImportError as e:
    print(f"β MMTD λ¨λΈ import μ‹¤ν¨: {e}")
    sys.exit(1)

class RealModelTester:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else 
                                  "mps" if torch.backends.mps.is_available() else "cpu")
        print(f"π”§ λ””λ°”μ΄μ¤: {self.device}")
        
    def test_model_creation(self):
        """κΈ°λ³Έ MMTD λ¨λΈ μƒμ„± ν…μ¤νΈ"""
        print("\nπ—οΈ MMTD λ¨λΈ μƒμ„± ν…μ¤νΈ...")
        
        try:
            # κΈ°λ³Έ λ¨λΈ μƒμ„± μ‹λ„
            model = MMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            print("β… κΈ°λ³Έ MMTD λ¨λΈ μƒμ„± μ„±κ³µ")
            print(f"   λ¨λΈ νλΌλ―Έν„° μ: {sum(p.numel() for p in model.parameters()):,}")
            
            # λ¨λΈμ„ ν‰κ°€ λ¨λ“λ΅ μ„¤μ •
            model.eval()
            model.to(self.device)
            print(f"β… λ¨λΈμ„ {self.device}μ— λ΅λ”© μ™„λ£")
            
            return model
            
        except Exception as e:
            print(f"β λ¨λΈ μƒμ„± μ‹¤ν¨: {e}")
            return None
    
    def test_checkpoint_loading(self, model):
        """μ²΄ν¬ν¬μΈνΈ λ΅λ”© ν…μ¤νΈ"""
        print("\nπ’Ύ μ²΄ν¬ν¬μΈνΈ λ΅λ”© ν…μ¤νΈ...")
        
        checkpoint_path = "checkpoints/fold1/checkpoint-939/pytorch_model.bin"
        
        if not os.path.exists(checkpoint_path):
            print(f"β μ²΄ν¬ν¬μΈνΈ νμΌ μ—†μ: {checkpoint_path}")
            return False
            
        try:
            print(f"π“ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹λ„: {checkpoint_path}")
            
            # μ²΄ν¬ν¬μΈνΈ λ΅λ“
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            print(f"β… μ²΄ν¬ν¬μΈνΈ νμΌ λ΅λ”© μ„±κ³µ")
            print(f"   μ²΄ν¬ν¬μΈνΈ ν‚¤ μ: {len(checkpoint.keys())}")
            
            # λ‡ κ° ν‚¤ ν™•μΈ
            print("   μƒμ„ 5κ° ν‚¤:")
            for i, key in enumerate(list(checkpoint.keys())[:5]):
                shape = checkpoint[key].shape if hasattr(checkpoint[key], 'shape') else 'scalar'
                print(f"     {i+1}. {key}: {shape}")
            
            # λ¨λΈμ— λ΅λ”© μ‹λ„
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint, strict=False)
            
            print(f"β… λ¨λΈμ— μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ™„λ£")
            print(f"   Missing keys: {len(missing_keys)}")
            print(f"   Unexpected keys: {len(unexpected_keys)}")
            
            if missing_keys:
                print("   μΌλ¶€ missing keys:")
                for key in missing_keys[:3]:
                    print(f"     - {key}")
                    
            if unexpected_keys:
                print("   μΌλ¶€ unexpected keys:")
                for key in unexpected_keys[:3]:
                    print(f"     - {key}")
            
            return True
            
        except Exception as e:
            print(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨: {e}")
            return False
    
    def test_model_forward(self, model):
        """λ¨λΈ forward pass ν…μ¤νΈ"""
        print("\nπ”„ λ¨λΈ Forward Pass ν…μ¤νΈ...")
        
        try:
            # λ”λ―Έ μ…λ ¥ λ°μ΄ν„° μƒμ„±
            batch_size = 1
            seq_length = 64
            image_size = 224
            
            dummy_input = {
                'input_ids': torch.randint(0, 1000, (batch_size, seq_length), dtype=torch.long),
                'attention_mask': torch.ones(batch_size, seq_length, dtype=torch.long),
                'token_type_ids': torch.zeros(batch_size, seq_length, dtype=torch.long),
                'pixel_values': torch.randn(batch_size, 3, image_size, image_size, dtype=torch.float32)
            }
            
            # λ””λ°”μ΄μ¤λ΅ μ΄λ™
            for key in dummy_input:
                dummy_input[key] = dummy_input[key].to(self.device)
            
            print(f"π“ μ…λ ¥ λ°μ΄ν„° μƒμ„± μ™„λ£:")
            for key, tensor in dummy_input.items():
                print(f"   {key}: {tensor.shape} on {tensor.device}")
            
            # Forward pass
            with torch.no_grad():
                outputs = model(**dummy_input)
                
            print(f"β… Forward pass μ„±κ³µ!")
            print(f"   μ¶λ ¥ ν•νƒ: {outputs.logits.shape}")
            print(f"   μμΈ΅ ν™•λ¥ : {torch.softmax(outputs.logits, dim=-1)}")
            
            return True
            
        except Exception as e:
            print(f"β Forward pass μ‹¤ν¨: {e}")
            import traceback
            print(f"   μƒμ„Έ μ¤λ¥: {traceback.format_exc()}")
            return False
    
    def run_full_test(self):
        """μ „μ²΄ ν…μ¤νΈ μ‹¤ν–‰"""
        print("π€ μ‹¤μ  MMTD λ¨λΈ λ΅λ”© λ° λ™μ‘ ν…μ¤νΈ μ‹μ‘")
        print("="*60)
        
        # 1. λ¨λΈ μƒμ„±
        model = self.test_model_creation()
        if model is None:
            print("β λ¨λΈ μƒμ„± μ‹¤ν¨λ΅ ν…μ¤νΈ μ¤‘λ‹¨")
            return False
        
        # 2. μ²΄ν¬ν¬μΈνΈ λ΅λ”©
        checkpoint_loaded = self.test_checkpoint_loading(model)
        if not checkpoint_loaded:
            print("β οΈ μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ‹¤ν¨, κΈ°λ³Έ λ¨λΈλ΅ κ³„μ†")
        
        # 3. Forward pass ν…μ¤νΈ
        forward_success = self.test_model_forward(model)
        
        # κ²°κ³Ό μ”μ•½
        print("\nπ“‹ ν…μ¤νΈ κ²°κ³Ό μ”μ•½:")
        print("-" * 40)
        print(f"λ¨λΈ μƒμ„±: β… μ„±κ³µ")
        print(f"μ²΄ν¬ν¬μΈνΈ λ΅λ”©: {'β… μ„±κ³µ' if checkpoint_loaded else 'β μ‹¤ν¨'}")
        print(f"Forward pass: {'β… μ„±κ³µ' if forward_success else 'β μ‹¤ν¨'}")
        
        if checkpoint_loaded and forward_success:
            print("\nπ‰ μ‹¤μ  MMTD λ¨λΈ λ΅λ”© λ° λ™μ‘ μ™„μ „ μ„±κ³µ!")
            print("   μ΄μ  μ‹¤μ  attention λ¶„μ„μ„ μ‹μ‘ν•  μ μμµλ‹λ‹¤.")
            return True
        else:
            print("\nβ οΈ μΌλ¶€ λ¬Έμ κ°€ μμ§€λ§ μ§„λ‹¨ μ •λ³΄λ¥Ό μ–»μ—μµλ‹λ‹¤.")
            return False


if __name__ == "__main__":
    tester = RealModelTester()
    success = tester.run_full_test()
    
    if success:
        print("\nβ… λ‹¤μ λ‹¨κ³„: μ‹¤μ  attention κ°€μ¤‘μΉ μ¶”μ¶ κµ¬ν„")
    else:
        print("\nπ”§ λ‹¤μ λ‹¨κ³„: μ‹λ³„λ λ¬Έμ λ“¤ ν•΄κ²° ν•„μ”") 