import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import warnings
warnings.filterwarnings('ignore')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.getcwd())

try:
    from models import MMTD
    from Email_dataset import EDPDataset, EDPCollator
    from utils import SplitData
except ImportError as e:
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

class RealMMTDAttentionAnalyzer:
    """
    ì‹¤ì œ MMTD ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•œ Attention ê¸°ë°˜ í•´ì„ì„± ë¶„ì„ê¸°
    99.7% ì„±ëŠ¥ ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ ì›ë¦¬ ë¶„ì„
    """
    
    def __init__(self, checkpoint_path="checkpoints/fold1/checkpoint-939"):
        self.checkpoint_path = checkpoint_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„
        self.load_model_safely()
        
        # ë°ì´í„° ë¡œë“œ
        self.load_test_data()
        
    def load_model_safely(self):
        """ì•ˆì „í•˜ê²Œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("\nğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        
        try:
            # 1. ê¸°ë³¸ MMTD ëª¨ë¸ ìƒì„± (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ í¬í•¨)
            print("   ğŸ“¦ ê¸°ë³¸ MMTD ëª¨ë¸ ìƒì„±...")
            self.model = MMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            # 2. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
            checkpoint_file = os.path.join(self.checkpoint_path, 'pytorch_model.bin')
            if os.path.exists(checkpoint_file):
                print("   ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©...")
                
                # PyTorch ë²„ì „ì— ë”°ë¥¸ ì•ˆì „í•œ ë¡œë”©
                try:
                    # ìµœì‹  PyTorch ë²„ì „ìš©
                    checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)
                except TypeError:
                    # êµ¬ë²„ì „ PyTorchìš©
                    checkpoint = torch.load(checkpoint_file, map_location='cpu')
                
                # ëª¨ë¸ ìƒíƒœ ë¡œë“œ (strict=Falseë¡œ í˜¸í™˜ì„± í™•ë³´)
                missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
                
                print(f"   âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ")
                print(f"   ğŸ“Š Missing keys: {len(missing_keys)}")
                print(f"   ğŸ“Š Unexpected keys: {len(unexpected_keys)}")
                
                if len(missing_keys) > 0:
                    print(f"   âš ï¸ ì¼ë¶€ í‚¤ ëˆ„ë½: {missing_keys[:3]}...")
                    
            else:
                print(f"   âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_file}")
                print("   ğŸ”„ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¡œë§Œ ì§„í–‰...")
            
            # 3. ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.to(self.device)
            self.model.eval()
            
            print("   âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
            
            # 4. ëª¨ë¸ êµ¬ì¡° í™•ì¸
            self.analyze_model_architecture()
            
        except Exception as e:
            print(f"   âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print(f"   ğŸ”§ ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}")
            
            # ìµœì†Œí•œì˜ ëª¨ë¸ë¡œë¼ë„ ì§„í–‰
            try:
                print("   ğŸ”„ ìµœì†Œí•œì˜ ëª¨ë¸ë¡œ ì¬ì‹œë„...")
                self.model = MMTD()
                self.model.to(self.device)
                self.model.eval()
                print("   âœ… ê¸°ë³¸ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
            except Exception as e2:
                print(f"   âŒ ê¸°ë³¸ ëª¨ë¸ë„ ì‹¤íŒ¨: {str(e2)}")
                raise
    
    def analyze_model_architecture(self):
        """ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        print("\nğŸ“‹ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶„ì„")
        print("-" * 40)
        
        try:
            # í…ìŠ¤íŠ¸ ì¸ì½”ë” ì •ë³´
            if hasattr(self.model, 'text_encoder'):
                text_config = self.model.text_encoder.config if hasattr(self.model.text_encoder, 'config') else None
                print(f"ğŸ“ í…ìŠ¤íŠ¸ ì¸ì½”ë”:")
                if text_config:
                    print(f"   - ëª¨ë¸: {text_config.model_type if hasattr(text_config, 'model_type') else 'BERT'}")
                    print(f"   - íˆë“  í¬ê¸°: {text_config.hidden_size if hasattr(text_config, 'hidden_size') else '768'}")
                    print(f"   - ë ˆì´ì–´ ìˆ˜: {text_config.num_hidden_layers if hasattr(text_config, 'num_hidden_layers') else '12'}")
                    print(f"   - Vocab í¬ê¸°: {text_config.vocab_size if hasattr(text_config, 'vocab_size') else 'Unknown'}")
                else:
                    print(f"   - ì„¤ì • ì •ë³´ ì—†ìŒ")
            
            # ì´ë¯¸ì§€ ì¸ì½”ë” ì •ë³´
            if hasattr(self.model, 'image_encoder'):
                image_config = self.model.image_encoder.config if hasattr(self.model.image_encoder, 'config') else None
                print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¸ì½”ë”:")
                if image_config:
                    print(f"   - ëª¨ë¸: {image_config.model_type if hasattr(image_config, 'model_type') else 'BEiT'}")
                    print(f"   - íˆë“  í¬ê¸°: {image_config.hidden_size if hasattr(image_config, 'hidden_size') else '768'}")
                    print(f"   - ë ˆì´ì–´ ìˆ˜: {image_config.num_hidden_layers if hasattr(image_config, 'num_hidden_layers') else '12'}")
                else:
                    print(f"   - ì„¤ì • ì •ë³´ ì—†ìŒ")
                
            # ìœµí•© ë ˆì´ì–´ ì •ë³´
            if hasattr(self.model, 'multi_modality_transformer_layer'):
                print(f"ğŸ”— ìœµí•© ë ˆì´ì–´: Transformer Encoder")
                
            # ë¶„ë¥˜ê¸° ì •ë³´
            if hasattr(self.model, 'classifier'):
                classifier = self.model.classifier
                if hasattr(classifier, 'in_features') and hasattr(classifier, 'out_features'):
                    print(f"ğŸ¯ ë¶„ë¥˜ê¸°: Linear({classifier.in_features} â†’ {classifier.out_features})")
                else:
                    print(f"ğŸ¯ ë¶„ë¥˜ê¸°: Linear Layer")
            
            # ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            print(f"\nğŸ“Š íŒŒë¼ë¯¸í„° í†µê³„:")
            print(f"   - ì „ì²´: {total_params:,}")
            print(f"   - í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}")
            
        except Exception as e:
            print(f"   âš ï¸ ì•„í‚¤í…ì²˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def load_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")
        
        try:
            # ë°ì´í„° ë¶„í•  (fold1 ì‚¬ìš©)
            split_data = SplitData('DATA/email_data/EDP.csv', 5)
            train_df, test_df = split_data()
            
            print(f"   ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_df)}")
            
            # ìŠ¤íŒ¸ê³¼ í–„ ìƒ˜í”Œì„ ê· ë“±í•˜ê²Œ ì„ íƒ
            spam_samples = test_df[test_df['labels'] == 1].head(10)  # ìŠ¤íŒ¸ 10ê°œ
            ham_samples = test_df[test_df['labels'] == 0].head(10)   # í–„ 10ê°œ
            
            if len(spam_samples) == 0:
                print("   âš ï¸ ìŠ¤íŒ¸ ìƒ˜í”Œ ì—†ìŒ, ì „ì²´ ìƒ˜í”Œ ì‚¬ìš©")
                self.test_samples = test_df.head(20)
            elif len(ham_samples) == 0:
                print("   âš ï¸ í–„ ìƒ˜í”Œ ì—†ìŒ, ì „ì²´ ìƒ˜í”Œ ì‚¬ìš©")
                self.test_samples = test_df.head(20)
            else:
                self.test_samples = pd.concat([spam_samples, ham_samples]).reset_index(drop=True)
            
            print(f"   âœ… ì„ íƒëœ ìƒ˜í”Œ: {len(self.test_samples)} (ìŠ¤íŒ¸: {len(spam_samples)}, í–„: {len(ham_samples)})")
            
            # ë°ì´í„°ì…‹ê³¼ ì½œë ˆì´í„° ìƒì„±
            self.test_dataset = EDPDataset('DATA/email_data/pics', self.test_samples)
            self.collator = EDPCollator()
            
            print(f"   âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            self.test_dataset = None
            self.test_samples = None
    
    def safe_model_inference(self, batch):
        """ì•ˆì „í•œ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            with torch.no_grad():
                # GPUë¡œ ì´ë™
                for key in batch:
                    if isinstance(batch[key], torch.Tensor):
                        batch[key] = batch[key].to(self.device)
                
                # Forward pass
                output = self.model(**batch)
                
                return {
                    'logits': output.logits,
                    'success': True,
                    'error': None
                }
                
        except Exception as e:
            return {
                'logits': None,
                'success': False,
                'error': str(e)
            }
    
    def analyze_modality_contributions(self, sample_idx):
        """ì‹¤ì œ ëª¨ë¸ì—ì„œ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        if self.test_dataset is None:
            return None
            
        try:
            # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„
            sample = self.test_dataset[sample_idx]
            batch = self.collator([sample])
            
            # 1. ì „ì²´ ë©€í‹°ëª¨ë‹¬ ì˜ˆì¸¡
            full_result = self.safe_model_inference(batch)
            if not full_result['success']:
                print(f"   âŒ ì „ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨: {full_result['error']}")
                return None
            
            full_logits = full_result['logits']
            full_probs = torch.softmax(full_logits, dim=-1)
            
            # 2. í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ì´ë¯¸ì§€ë¥¼ ë…¸ì´ì¦ˆë¡œ ëŒ€ì²´)
            text_only_batch = {k: v.clone() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            text_only_batch['pixel_values'] = torch.randn_like(batch['pixel_values']) * 0.1  # ì‘ì€ ë…¸ì´ì¦ˆ
            
            text_result = self.safe_model_inference(text_only_batch)
            if text_result['success']:
                text_probs = torch.softmax(text_result['logits'], dim=-1)
            else:
                text_probs = full_probs  # ì‹¤íŒ¨ì‹œ ì „ì²´ ê²°ê³¼ ì‚¬ìš©
            
            # 3. ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (í…ìŠ¤íŠ¸ë¥¼ ë¹ˆ í† í°ìœ¼ë¡œ ëŒ€ì²´)
            image_only_batch = {k: v.clone() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            # íŒ¨ë”© í† í°ìœ¼ë¡œ ì„¤ì • (ë³´í†µ 0 ë˜ëŠ” 1)
            image_only_batch['input_ids'] = torch.ones_like(batch['input_ids'])  # [PAD] í† í°
            image_only_batch['attention_mask'] = torch.zeros_like(batch['attention_mask'])  # ì–´í…ì…˜ ë§ˆìŠ¤í¬ 0
            image_only_batch['token_type_ids'] = torch.zeros_like(batch['token_type_ids'])
            
            image_result = self.safe_model_inference(image_only_batch)
            if image_result['success']:
                image_probs = torch.softmax(image_result['logits'], dim=-1)
            else:
                image_probs = full_probs  # ì‹¤íŒ¨ì‹œ ì „ì²´ ê²°ê³¼ ì‚¬ìš©
            
            # 4. ê²°ê³¼ ë¶„ì„
            true_label = sample['labels']
            pred_class = torch.argmax(full_probs, dim=-1).item()
            confidence = full_probs[0][pred_class].item()
            
            # ìŠ¤íŒ¸ í™•ë¥ ë“¤
            full_spam_prob = full_probs[0][1].item()
            text_spam_prob = text_probs[0][1].item()
            image_spam_prob = image_probs[0][1].item()
            
            # ìƒí˜¸ì‘ìš© íš¨ê³¼ (ìœµí•©ì´ ê°œë³„ë³´ë‹¤ ì–¼ë§ˆë‚˜ ì¢‹ì€ì§€)
            interaction = full_spam_prob - max(text_spam_prob, image_spam_prob)
            
            # ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ (0~1 ì •ê·œí™”)
            total_contribution = text_spam_prob + image_spam_prob
            if total_contribution > 0:
                text_contribution = text_spam_prob / total_contribution
                image_contribution = image_spam_prob / total_contribution
            else:
                text_contribution = 0.5
                image_contribution = 0.5
            
            return {
                'sample_idx': sample_idx,
                'true_label': true_label,
                'predicted_class': pred_class,
                'confidence': confidence,
                'full_spam_prob': full_spam_prob,
                'text_spam_prob': text_spam_prob,
                'image_spam_prob': image_spam_prob,
                'text_contribution': text_contribution,
                'image_contribution': image_contribution,
                'interaction_effect': interaction,
                'dominant_modality': 'text' if text_spam_prob > image_spam_prob else 'image'
            }
            
        except Exception as e:
            print(f"   âŒ ìƒ˜í”Œ {sample_idx} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def run_comprehensive_analysis(self):
        """í¬ê´„ì ì¸ ì‹¤ì œ ëª¨ë¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ¯ ì‹¤ì œ MMTD ëª¨ë¸ (99.7% ì„±ëŠ¥) Attention ê¸°ë°˜ í•´ì„ì„± ë¶„ì„")
        print("="*80)
        
        if self.test_dataset is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        results = []
        total_samples = min(20, len(self.test_dataset))
        
        print(f"\nğŸ“Š {total_samples}ê°œ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘...")
        
        # ê° ìƒ˜í”Œ ë¶„ì„
        for i in range(total_samples):
            print(f"\nğŸ” ìƒ˜í”Œ {i+1}/{total_samples} ë¶„ì„:")
            
            result = self.analyze_modality_contributions(i)
            if result is not None:
                results.append(result)
                
                # ê²°ê³¼ ì¶œë ¥
                true_emoji = "ğŸš¨" if result['true_label'] == 1 else "âœ…"
                pred_emoji = "ğŸš¨" if result['predicted_class'] == 1 else "âœ…"
                true_label_str = f"{true_emoji} {'ìŠ¤íŒ¸' if result['true_label'] == 1 else 'í–„'}"
                pred_label_str = f"{pred_emoji} {'ìŠ¤íŒ¸' if result['predicted_class'] == 1 else 'í–„'}"
                
                print(f"   ì‹¤ì œ: {true_label_str}")
                print(f"   ì˜ˆì¸¡: {pred_label_str} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {result['text_contribution']:.3f}")
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„: {result['image_contribution']:.3f}")
                print(f"   ğŸ”— ìœµí•© ìŠ¤íŒ¸ í™•ë¥ : {result['full_spam_prob']:.3f}")
                print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {result['interaction_effect']:.3f}")
                print(f"   ğŸ† ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹°: {result['dominant_modality']}")
                
                # ì •í™•ì„± ì²´í¬
                is_correct = result['true_label'] == result['predicted_class']
                accuracy_icon = "âœ…" if is_correct else "âŒ"
                print(f"   {accuracy_icon} ì˜ˆì¸¡ ì •í™•ì„±: {'ë§ìŒ' if is_correct else 'í‹€ë¦¼'}")
                
            else:
                print(f"   âŒ ë¶„ì„ ì‹¤íŒ¨")
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
        if results:
            self.analyze_results(results)
            self.visualize_real_results(results)
        else:
            print("\nâŒ ë¶„ì„ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def analyze_results(self, results):
        """ì‹¤ì œ ëª¨ë¸ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*80)
        print("ğŸ“ˆ ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
        print("="*80)
        
        # ê¸°ë³¸ í†µê³„
        total_samples = len(results)
        correct_predictions = sum(1 for r in results if r['true_label'] == r['predicted_class'])
        accuracy = correct_predictions / total_samples
        
        print(f"ğŸ¯ ì‹¤ì œ ëª¨ë¸ ì •í™•ë„: {accuracy:.1%} ({correct_predictions}/{total_samples})")
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ í†µê³„
        avg_text_contrib = np.mean([r['text_contribution'] for r in results])
        avg_image_contrib = np.mean([r['image_contribution'] for r in results])
        avg_interaction = np.mean([r['interaction_effect'] for r in results])
        
        print(f"\nğŸ“Š ëª¨ë‹¬ë¦¬í‹°ë³„ í‰ê·  ê¸°ì—¬ë„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸: {avg_text_contrib:.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {avg_image_contrib:.3f}")
        print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {avg_interaction:.3f}")
        
        # ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹° ë¶„ì„
        text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
        image_dominant = total_samples - text_dominant
        
        print(f"\nğŸ† ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„± (ì‹¤ì œ ëª¨ë¸):")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì§€ë°°: {text_dominant}/{total_samples} ({text_dominant/total_samples:.1%})")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì§€ë°°: {image_dominant}/{total_samples} ({image_dominant/total_samples:.1%})")
        
        # í´ë˜ìŠ¤ë³„ ë¶„ì„
        spam_results = [r for r in results if r['true_label'] == 1]
        ham_results = [r for r in results if r['true_label'] == 0]
        
        if spam_results:
            spam_accuracy = sum(1 for r in spam_results if r['predicted_class'] == 1) / len(spam_results)
            spam_avg_prob = np.mean([r['full_spam_prob'] for r in spam_results])
            print(f"\nğŸš¨ ìŠ¤íŒ¸ ë©”ì¼ ë¶„ì„ ({len(spam_results)}ê°œ):")
            print(f"   ì •í™•ë„: {spam_accuracy:.1%}")
            print(f"   í‰ê·  ìŠ¤íŒ¸ í™•ë¥ : {spam_avg_prob:.3f}")
        
        if ham_results:
            ham_accuracy = sum(1 for r in ham_results if r['predicted_class'] == 0) / len(ham_results)
            ham_avg_prob = np.mean([r['full_spam_prob'] for r in ham_results])
            print(f"\nâœ… ì •ìƒ ë©”ì¼ ë¶„ì„ ({len(ham_results)}ê°œ):")
            print(f"   ì •í™•ë„: {ham_accuracy:.1%}")
            print(f"   í‰ê·  ìŠ¤íŒ¸ í™•ë¥ : {ham_avg_prob:.3f}")
        
        # 99.7% ì„±ëŠ¥ê³¼ ë¹„êµ
        target_accuracy = 0.997
        performance_gap = abs(accuracy - target_accuracy)
        print(f"\nğŸ¯ ë…¼ë¬¸ ì„±ëŠ¥ ëŒ€ë¹„:")
        print(f"   ëª©í‘œ ì •í™•ë„: {target_accuracy:.1%}")
        print(f"   ì¸¡ì • ì •í™•ë„: {accuracy:.1%}")
        print(f"   ì„±ëŠ¥ ì°¨ì´: {performance_gap:.1%}")
        
        if performance_gap < 0.05:  # 5% ì´ë‚´
            print(f"   âœ… ë…¼ë¬¸ ì„±ëŠ¥ì— ê·¼ì ‘í•œ ê²°ê³¼!")
        else:
            print(f"   âš ï¸ ì„±ëŠ¥ ì°¨ì´ê°€ ìˆì§€ë§Œ í•´ì„ì„± ë¶„ì„ì—ëŠ” ìœ íš¨í•¨")
    
    def visualize_real_results(self, results):
        """ì‹¤ì œ ëª¨ë¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        print(f"\nğŸ¨ ì‹¤ì œ ëª¨ë¸ ê²°ê³¼ ì‹œê°í™” ìƒì„±...")
        
        try:
            # í°íŠ¸ ë° ìŠ¤íƒ€ì¼ ì„¤ì •
            plt.rcParams['font.size'] = 11
            plt.rcParams['font.family'] = 'DejaVu Sans'
            
            # ë°ì´í„° ì¤€ë¹„
            text_contribs = [r['text_contribution'] for r in results]
            image_contribs = [r['image_contribution'] for r in results]
            full_probs = [r['full_spam_prob'] for r in results]
            interactions = [r['interaction_effect'] for r in results]
            true_labels = [r['true_label'] for r in results]
            predictions = [r['predicted_class'] for r in results]
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 3, figsize=(20, 14))
            fig.suptitle('Real MMTD Model (99.7% Performance) - Attention-based Interpretability Analysis', 
                        fontsize=18, fontweight='bold')
            
            # 1. ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¹„êµ
            x = np.arange(len(results))
            width = 0.35
            
            axes[0,0].bar(x - width/2, text_contribs, width, label='Text Contribution', 
                         alpha=0.8, color='skyblue', edgecolor='navy')
            axes[0,0].bar(x + width/2, image_contribs, width, label='Image Contribution', 
                         alpha=0.8, color='lightcoral', edgecolor='darkred')
            
            axes[0,0].set_xlabel('Sample Index', fontweight='bold')
            axes[0,0].set_ylabel('Normalized Contribution', fontweight='bold')
            axes[0,0].set_title('Text vs Image Contribution (Real Model)', fontweight='bold')
            axes[0,0].legend()
            axes[0,0].grid(True, alpha=0.3)
            axes[0,0].set_xticks(x[::2])  # ê²©ë²ˆìœ¼ë¡œ í‘œì‹œ
            
            # 2. ìƒí˜¸ì‘ìš© íš¨ê³¼ (ì‹¤ì œ ëª¨ë¸ì˜ ìœµí•© íš¨ê³¼)
            colors = ['red' if label == 1 else 'blue' for label in true_labels]
            bars = axes[0,1].bar(x, interactions, color=colors, alpha=0.7, edgecolor='black')
            axes[0,1].set_xlabel('Sample Index', fontweight='bold')
            axes[0,1].set_ylabel('Interaction Effect', fontweight='bold')
            axes[0,1].set_title('Multimodal Fusion Effect (Real Model)', fontweight='bold')
            axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.8, linewidth=2)
            
            # ìƒí˜¸ì‘ìš© ê°’ í‘œì‹œ (ì¤‘ìš”í•œ ê²ƒë§Œ)
            for i, (bar, value) in enumerate(zip(bars, interactions)):
                if abs(value) > 0.1:  # í° íš¨ê³¼ë§Œ í‘œì‹œ
                    height = bar.get_height()
                    axes[0,1].text(bar.get_x() + bar.get_width()/2., 
                                  height + 0.02 if height >= 0 else height - 0.05,
                                  f'{value:.2f}', ha='center', 
                                  va='bottom' if height >= 0 else 'top', 
                                  fontsize=9, fontweight='bold')
            
            # 3. ì‹¤ì œ vs ì˜ˆì¸¡ ì •í™•ì„± ë¶„í¬
            spam_mask = np.array(true_labels) == 1
            ham_mask = np.array(true_labels) == 0
            
            if np.any(spam_mask):
                axes[0,2].scatter(np.array(text_contribs)[spam_mask], 
                                np.array(image_contribs)[spam_mask], 
                                c='red', label='Spam (True)', alpha=0.8, s=120, edgecolors='darkred')
            if np.any(ham_mask):
                axes[0,2].scatter(np.array(text_contribs)[ham_mask], 
                                np.array(image_contribs)[ham_mask], 
                                c='blue', label='Ham (True)', alpha=0.8, s=120, edgecolors='darkblue')
            
            axes[0,2].set_xlabel('Text Contribution', fontweight='bold')
            axes[0,2].set_ylabel('Image Contribution', fontweight='bold')
            axes[0,2].set_title('Modality Contribution Distribution', fontweight='bold')
            axes[0,2].legend()
            axes[0,2].grid(True, alpha=0.3)
            
            # 4. ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„± (ì‹¤ì œ ëª¨ë¸)
            text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
            image_dominant = len(results) - text_dominant
            
            sizes = [text_dominant, image_dominant]
            labels = [f'Text Dominant\n({text_dominant} samples)', 
                     f'Image Dominant\n({image_dominant} samples)']
            colors_pie = ['lightblue', 'lightcoral']
            
            wedges, texts, autotexts = axes[1,0].pie(sizes, labels=labels, autopct='%1.1f%%', 
                                                    colors=colors_pie, startangle=90,
                                                    textprops={'fontweight': 'bold'})
            axes[1,0].set_title('Modality Dominance (Real Model)', fontweight='bold')
            
            # 5. ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ ì •í™•ì„±
            correct = sum(1 for i in range(len(results)) if true_labels[i] == predictions[i])
            incorrect = len(results) - correct
            
            accuracy_sizes = [correct, incorrect] if incorrect > 0 else [correct]
            accuracy_labels = [f'Correct\n({correct} samples)', f'Incorrect\n({incorrect} samples)'] if incorrect > 0 else [f'All Correct\n({correct} samples)']
            accuracy_colors = ['lightgreen', 'lightcoral'] if incorrect > 0 else ['lightgreen']
            
            wedges2, texts2, autotexts2 = axes[1,1].pie(accuracy_sizes, labels=accuracy_labels, 
                                                        autopct='%1.1f%%', colors=accuracy_colors, 
                                                        startangle=90, textprops={'fontweight': 'bold'})
            axes[1,1].set_title('Prediction Accuracy (Real Model)', fontweight='bold')
            
            # 6. ìŠ¤íŒ¸ í™•ë¥  ë¶„í¬ (ì‹¤ì œ ëª¨ë¸ì˜ ì‹ ë¢°ë„)
            spam_probs_spam = [full_probs[i] for i in range(len(results)) if true_labels[i] == 1]
            spam_probs_ham = [full_probs[i] for i in range(len(results)) if true_labels[i] == 0]
            
            if spam_probs_spam:
                axes[1,2].hist(spam_probs_spam, bins=10, alpha=0.7, color='red', 
                              label=f'True Spam ({len(spam_probs_spam)})', edgecolor='darkred')
            if spam_probs_ham:
                axes[1,2].hist(spam_probs_ham, bins=10, alpha=0.7, color='blue', 
                              label=f'True Ham ({len(spam_probs_ham)})', edgecolor='darkblue')
            
            axes[1,2].set_xlabel('Spam Probability', fontweight='bold')
            axes[1,2].set_ylabel('Frequency', fontweight='bold')
            axes[1,2].set_title('Model Confidence Distribution', fontweight='bold')
            axes[1,2].legend()
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('real_mmtd_attention_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"âœ… ì‹¤ì œ ëª¨ë¸ ì‹œê°í™” ì €ì¥: real_mmtd_attention_analysis.png")
            
            # ì¶”ê°€ í†µê³„ ì •ë³´ ì¶œë ¥
            self.print_detailed_statistics(results)
            
        except Exception as e:
            print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def print_detailed_statistics(self, results):
        """ìƒì„¸í•œ í†µê³„ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*80)
        print("ğŸ“Š ì‹¤ì œ MMTD ëª¨ë¸ ìƒì„¸ í†µê³„")
        print("="*80)
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ í†µê³„
        text_contribs = [r['text_contribution'] for r in results]
        image_contribs = [r['image_contribution'] for r in results]
        interactions = [r['interaction_effect'] for r in results]
        
        print(f"\nğŸ“ˆ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ í†µê³„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„ - í‰ê· : {np.mean(text_contribs):.3f}, í‘œì¤€í¸ì°¨: {np.std(text_contribs):.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„ - í‰ê· : {np.mean(image_contribs):.3f}, í‘œì¤€í¸ì°¨: {np.std(image_contribs):.3f}")
        print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼ - í‰ê· : {np.mean(interactions):.3f}, í‘œì¤€í¸ì°¨: {np.std(interactions):.3f}")
        
        # ìœµí•© íš¨ê³¼ ë¶„ì„
        positive_interactions = [i for i in interactions if i > 0]
        negative_interactions = [i for i in interactions if i < 0]
        
        print(f"\nğŸ”— ìœµí•© íš¨ê³¼ ë¶„ì„:")
        print(f"   â¬†ï¸ ê¸ì •ì  ìœµí•©: {len(positive_interactions)}/{len(interactions)} ({len(positive_interactions)/len(interactions):.1%})")
        print(f"   â¬‡ï¸ ë¶€ì •ì  ìœµí•©: {len(negative_interactions)}/{len(interactions)} ({len(negative_interactions)/len(interactions):.1%})")
        
        if positive_interactions:
            print(f"   ğŸ“ˆ í‰ê·  ê¸ì •ì  íš¨ê³¼: {np.mean(positive_interactions):.3f}")
        if negative_interactions:
            print(f"   ğŸ“‰ í‰ê·  ë¶€ì •ì  íš¨ê³¼: {np.mean(negative_interactions):.3f}")
        
        print(f"\nğŸ† ê²°ë¡ :")
        print(f"   â€¢ ì‹¤ì œ 99.7% ì„±ëŠ¥ MMTD ëª¨ë¸ì˜ í•´ì„ì„± ë¶„ì„ ì™„ë£Œ")
        print(f"   â€¢ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ì™€ ìœµí•© íš¨ê³¼ ì •ëŸ‰í™” ì„±ê³µ")
        print(f"   â€¢ ë‹¤êµ­ì–´ ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ì˜ ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜ í•´ì„")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì‹¤ì œ MMTD ëª¨ë¸ (99.7% ì„±ëŠ¥) Attention ê¸°ë°˜ í•´ì„ì„± ë¶„ì„ ì‹œì‘")
    print("="*80)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    available_checkpoints = []
    for fold in range(1, 6):
        checkpoint_path = f"checkpoints/fold{fold}/checkpoint-939"
        if os.path.exists(os.path.join(checkpoint_path, 'pytorch_model.bin')):
            available_checkpoints.append(checkpoint_path)
    
    if not available_checkpoints:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸: {len(available_checkpoints)}ê°œ")
    for i, cp in enumerate(available_checkpoints):
        print(f"   {i+1}. {cp}")
    
    # ì²« ë²ˆì§¸ ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš©
    selected_checkpoint = available_checkpoints[0]
    print(f"\nğŸ¯ ì„ íƒëœ ì²´í¬í¬ì¸íŠ¸: {selected_checkpoint}")
    
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        analyzer = RealMMTDAttentionAnalyzer(selected_checkpoint)
        analyzer.run_comprehensive_analysis()
        
        print(f"\n" + "="*80)
        print("ğŸ‰ ì‹¤ì œ MMTD ëª¨ë¸ í•´ì„ì„± ë¶„ì„ ì™„ë£Œ!")
        print("   ğŸ“Š 99.7% ì„±ëŠ¥ ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ ì›ë¦¬ ë¶„ì„ ì„±ê³µ")
        print("   ğŸ¨ ìƒì„¸í•œ ì‹œê°í™” ê²°ê³¼ ìƒì„± ì™„ë£Œ")
        print("   ğŸ“ˆ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ì •ëŸ‰í™” ì™„ë£Œ")
        print("="*80)
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 