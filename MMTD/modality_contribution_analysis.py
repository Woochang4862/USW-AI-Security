import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import sys
sys.path.append('.')
from PIL import Image
import pandas as pd
import os
import random

from models import MMTD
from transformers import AutoTokenizer
import warnings
warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class ModalityContributionAnalysis:
    """
    ì‹¤ì œ MMTD ëª¨ë¸ì„ ì‚¬ìš©í•œ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¶„ì„
    - í…ìŠ¤íŠ¸ vs ì´ë¯¸ì§€ ê¸°ì—¬ë„ ë¶„ì„
    - Ablation Study (ê° ëª¨ë‹¬ë¦¬í‹° ì œê±° ì‹¤í—˜)
    - Attention ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê¸°ì—¬ë„
    - íŠ¹ì§• ë²¡í„° ì¤‘ìš”ë„ ë¶„ì„
    """
    
    def __init__(self, 
                 checkpoint_path: str = "checkpoints/fold1/checkpoint-939/pytorch_model.bin",
                 data_csv_path: str = "DATA/email_data/EDP_sample.csv",
                 image_dir: str = "DATA/email_data/pics"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else 
                                  "mps" if torch.backends.mps.is_available() else "cpu")
        self.checkpoint_path = checkpoint_path
        self.data_csv_path = data_csv_path
        self.image_dir = image_dir
        
        # ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.model = None
        self.tokenizer = None
        self.dataset = None
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.contribution_results = []
        
        print(f"ğŸ”§ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ê¸° ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def load_model_and_data(self):
        """ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë”©"""
        print("\nğŸ“‚ MMTD ëª¨ë¸ ë° ë°ì´í„° ë¡œë”©...")
        
        try:
            # ëª¨ë¸ ìƒì„±
            self.model = MMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            # output_attentions=True ì„¤ì •
            self.model.text_encoder.config.output_attentions = True
            self.model.image_encoder.config.output_attentions = True
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(self.checkpoint_path, map_location='cpu')
            self.model.load_state_dict(checkpoint, strict=False)
            self.model.eval()
            self.model.to(self.device)
            
            # í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹ ë¡œë”©
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
            self.dataset = pd.read_csv(self.data_csv_path)
            
            print(f"âœ… ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def load_real_email_image(self, image_filename: str):
        """ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€ ë¡œë”©"""
        try:
            image_path = os.path.join(self.image_dir, image_filename)
            if not os.path.exists(image_path):
                return None, None
            
            image = Image.open(image_path).convert('RGB').resize((224, 224))
            image_array = np.array(image)
            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).float() / 255.0
            return image_tensor.unsqueeze(0), image_array
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
            return None, None
    
    def create_inputs(self, text: str, image_filename: str):
        """ì…ë ¥ ë°ì´í„° ìƒì„±"""
        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        text_inputs = self.tokenizer(
            text, return_tensors="pt", padding=True, 
            truncation=True, max_length=128
        )
        
        # ì´ë¯¸ì§€ ë¡œë”©
        image_tensor, image_display = self.load_real_email_image(image_filename)
        if image_tensor is None:
            return None, None
        
        # ì…ë ¥ êµ¬ì„±
        inputs = {
            'input_ids': text_inputs['input_ids'].to(self.device),
            'attention_mask': text_inputs['attention_mask'].to(self.device),
            'token_type_ids': torch.zeros_like(text_inputs['input_ids']).to(self.device),
            'pixel_values': image_tensor.to(self.device)
        }
        
        return inputs, image_display
    
    def get_multimodal_prediction(self, inputs: Dict[str, torch.Tensor]):
        """ì „ì²´ ë©€í‹°ëª¨ë‹¬ ì˜ˆì¸¡"""
        with torch.no_grad():
            outputs = self.model(**inputs)
            prediction = torch.softmax(outputs.logits, dim=-1)
            return prediction.cpu().numpy()[0]
    
    def get_text_only_prediction(self, inputs: Dict[str, torch.Tensor]):
        """í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡ (ì´ë¯¸ì§€ë¥¼ ë…¸ì´ì¦ˆë¡œ ëŒ€ì²´)"""
        with torch.no_grad():
            # ì´ë¯¸ì§€ë¥¼ ëœë¤ ë…¸ì´ì¦ˆë¡œ ëŒ€ì²´
            noisy_inputs = inputs.copy()
            noisy_inputs['pixel_values'] = torch.randn_like(inputs['pixel_values'])
            
            outputs = self.model(**noisy_inputs)
            prediction = torch.softmax(outputs.logits, dim=-1)
            return prediction.cpu().numpy()[0]
    
    def get_image_only_prediction(self, inputs: Dict[str, torch.Tensor]):
        """ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡ (í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”©ìœ¼ë¡œ ëŒ€ì²´)"""
        with torch.no_grad():
            # í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”© í† í°ìœ¼ë¡œ ëŒ€ì²´
            text_only_inputs = inputs.copy()
            text_only_inputs['input_ids'] = torch.zeros_like(inputs['input_ids'])
            text_only_inputs['attention_mask'] = torch.zeros_like(inputs['attention_mask'])
            
            outputs = self.model(**text_only_inputs)
            prediction = torch.softmax(outputs.logits, dim=-1)
            return prediction.cpu().numpy()[0]
    
    def extract_feature_representations(self, inputs: Dict[str, torch.Tensor]):
        """ê° ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì§• í‘œí˜„ ì¶”ì¶œ"""
        with torch.no_grad():
            # í…ìŠ¤íŠ¸ íŠ¹ì§•
            text_inputs = {k: v for k, v in inputs.items() if k != 'pixel_values'}
            text_outputs = self.model.text_encoder(**text_inputs)
            text_features = text_outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´
            
            # ì´ë¯¸ì§€ íŠ¹ì§•
            image_outputs = self.model.image_encoder(pixel_values=inputs['pixel_values'])
            image_features = image_outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´
            
            return {
                'text_features': text_features.cpu(),
                'image_features': image_features.cpu(),
                'text_attentions': [att.cpu() for att in text_outputs.attentions],
                'image_attentions': [att.cpu() for att in image_outputs.attentions]
            }
    
    def calculate_attention_statistics(self, attentions: List[torch.Tensor]):
        """Attention í†µê³„ ê³„ì‚°"""
        if not attentions:
            return {}
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ attention ì‚¬ìš©
        attention = attentions[-1][0]  # [heads, seq, seq]
        
        # í†µê³„ ê³„ì‚°
        mean_attention = attention.mean().item()
        max_attention = attention.max().item()
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë¶ˆí™•ì‹¤ì„± ì¸¡ì •)
        attention_probs = attention + 1e-12  # ìˆ˜ì¹˜ ì•ˆì •ì„±
        entropy = -torch.sum(attention_probs * torch.log(attention_probs), dim=-1).mean().item()
        
        # ì§‘ì¤‘ë„ (ìµœëŒ€ê°’ë“¤ì˜ í‰ê· )
        max_per_row = attention.max(dim=-1)[0].mean().item()
        
        return {
            'mean': mean_attention,
            'max': max_attention,
            'entropy': entropy,
            'concentration': max_per_row
        }
    
    def analyze_single_sample(self, sample_data: Dict, sample_id: int):
        """ë‹¨ì¼ ìƒ˜í”Œì˜ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„"""
        print(f"\nğŸ“Š ìƒ˜í”Œ {sample_id} ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„")
        print(f"   íƒ€ì…: {sample_data['type'].upper()}")
        print(f"   ì´ë¯¸ì§€: {sample_data['image_filename']}")
        print(f"   í…ìŠ¤íŠ¸: {sample_data['text'][:50]}...")
        
        # ì…ë ¥ ìƒì„±
        inputs, image_display = self.create_inputs(
            sample_data['text'], sample_data['image_filename']
        )
        
        if inputs is None:
            print(f"   âš ï¸ ìƒ˜í”Œ {sample_id} ìŠ¤í‚µ (ì…ë ¥ ìƒì„± ì‹¤íŒ¨)")
            return None
        
        # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ìˆ˜í–‰
        multimodal_pred = self.get_multimodal_prediction(inputs)
        text_only_pred = self.get_text_only_prediction(inputs)
        image_only_pred = self.get_image_only_prediction(inputs)
        
        # íŠ¹ì§• í‘œí˜„ ì¶”ì¶œ
        features = self.extract_feature_representations(inputs)
        
        # Attention í†µê³„
        text_attention_stats = self.calculate_attention_statistics(features['text_attentions'])
        image_attention_stats = self.calculate_attention_statistics(features['image_attentions'])
        
        # íŠ¹ì§• ë²¡í„° í¬ê¸° ë¶„ì„
        text_feature_norm = torch.norm(features['text_features']).item()
        image_feature_norm = torch.norm(features['image_features']).item()
        
        # ê¸°ì—¬ë„ ê³„ì‚°
        spam_prob_full = multimodal_pred[1]
        spam_prob_text = text_only_pred[1]
        spam_prob_image = image_only_pred[1]
        
        # ì˜ˆì¸¡ í´ë˜ìŠ¤ ê³„ì‚°
        predicted_class = 1 if spam_prob_full > 0.5 else 0
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ (ì „ì²´ - ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹°)
        text_contribution = abs(spam_prob_full - image_only_pred[1])
        image_contribution = abs(spam_prob_full - text_only_pred[1])
        
        # ì •ê·œí™”ëœ ê¸°ì—¬ë„
        total_contribution = text_contribution + image_contribution
        if total_contribution > 0:
            text_contribution_norm = text_contribution / total_contribution
            image_contribution_norm = image_contribution / total_contribution
        else:
            text_contribution_norm = 0.5
            image_contribution_norm = 0.5
        
        result = {
            'sample_id': sample_id,
            'text': sample_data['text'],
            'image_filename': sample_data['image_filename'],
            'true_label': sample_data['label'],
            'type': sample_data['type'],
            'image_display': image_display,
            'predicted_class': predicted_class,
            
            # ì˜ˆì¸¡ ê²°ê³¼
            'multimodal_pred': multimodal_pred,
            'text_only_pred': text_only_pred,
            'image_only_pred': image_only_pred,
            
            # ê¸°ì—¬ë„
            'text_contribution': text_contribution,
            'image_contribution': image_contribution,
            'text_contribution_norm': text_contribution_norm,
            'image_contribution_norm': image_contribution_norm,
            
            # íŠ¹ì§• ë¶„ì„
            'text_feature_norm': text_feature_norm,
            'image_feature_norm': image_feature_norm,
            'text_attention_stats': text_attention_stats,
            'image_attention_stats': image_attention_stats
        }
        
        self.contribution_results.append(result)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"   ğŸ¯ ì˜ˆì¸¡: ë©€í‹°ëª¨ë‹¬ {spam_prob_full:.3f}, í…ìŠ¤íŠ¸ {spam_prob_text:.3f}, ì´ë¯¸ì§€ {spam_prob_image:.3f}")
        print(f"   ğŸ“Š ê¸°ì—¬ë„: í…ìŠ¤íŠ¸ {text_contribution_norm:.1%}, ì´ë¯¸ì§€ {image_contribution_norm:.1%}")
        
        return result
    
    def visualize_modality_contributions(self, results: List[Dict]):
        """ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ì‹œê°í™”"""
        if not results:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        # ë°ì´í„° ì¤€ë¹„
        sample_ids = [r['sample_id'] for r in results]
        text_contributions = [r['text_contribution_norm'] * 100 for r in results]
        image_contributions = [r['image_contribution_norm'] * 100 for r in results]
        sample_types = [r['type'] for r in results]
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ìƒ˜í”Œë³„ ê¸°ì—¬ë„ ìŠ¤íƒ ë°” ì°¨íŠ¸
        width = 0.8
        x = np.arange(len(sample_ids))
        
        bars1 = axes[0, 0].bar(x, text_contributions, width, label='í…ìŠ¤íŠ¸', color='skyblue', alpha=0.8)
        bars2 = axes[0, 0].bar(x, image_contributions, width, bottom=text_contributions, 
                              label='ì´ë¯¸ì§€', color='lightcoral', alpha=0.8)
        
        axes[0, 0].set_xlabel('ìƒ˜í”Œ ID')
        axes[0, 0].set_ylabel('ê¸°ì—¬ë„ (%)')
        axes[0, 0].set_title('ìƒ˜í”Œë³„ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels([f'#{i}' for i in sample_ids])
        axes[0, 0].legend()
        axes[0, 0].set_ylim(0, 100)
        
        # ìƒ˜í”Œ íƒ€ì…ë³„ ìƒ‰ìƒ í‘œì‹œ
        for i, (bar1, bar2, stype) in enumerate(zip(bars1, bars2, sample_types)):
            if stype == 'spam':
                bar1.set_edgecolor('red')
                bar2.set_edgecolor('red')
                bar1.set_linewidth(2)
                bar2.set_linewidth(2)
        
        # 2. íƒ€ì…ë³„ í‰ê·  ê¸°ì—¬ë„
        spam_results = [r for r in results if r['type'] == 'spam']
        ham_results = [r for r in results if r['type'] == 'ham']
        
        categories = []
        text_means = []
        image_means = []
        
        if spam_results:
            categories.append('ìŠ¤íŒ¸')
            text_means.append(np.mean([r['text_contribution_norm'] * 100 for r in spam_results]))
            image_means.append(np.mean([r['image_contribution_norm'] * 100 for r in spam_results]))
        
        if ham_results:
            categories.append('ì •ìƒ')
            text_means.append(np.mean([r['text_contribution_norm'] * 100 for r in ham_results]))
            image_means.append(np.mean([r['image_contribution_norm'] * 100 for r in ham_results]))
        
        x_cat = np.arange(len(categories))
        axes[0, 1].bar(x_cat, text_means, width, label='í…ìŠ¤íŠ¸', color='skyblue', alpha=0.8)
        axes[0, 1].bar(x_cat, image_means, width, bottom=text_means, 
                      label='ì´ë¯¸ì§€', color='lightcoral', alpha=0.8)
        
        axes[0, 1].set_xlabel('ì´ë©”ì¼ íƒ€ì…')
        axes[0, 1].set_ylabel('í‰ê·  ê¸°ì—¬ë„ (%)')
        axes[0, 1].set_title('íƒ€ì…ë³„ í‰ê·  ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„')
        axes[0, 1].set_xticks(x_cat)
        axes[0, 1].set_xticklabels(categories)
        axes[0, 1].legend()
        axes[0, 1].set_ylim(0, 100)
        
        # 3. íŠ¹ì§• ë²¡í„° í¬ê¸° ë¹„êµ
        text_norms = [r['text_feature_norm'] for r in results]
        image_norms = [r['image_feature_norm'] for r in results]
        
        axes[1, 0].scatter(text_norms, image_norms, 
                          c=['red' if r['type'] == 'spam' else 'blue' for r in results],
                          alpha=0.7, s=100)
        axes[1, 0].set_xlabel('í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„° í¬ê¸°')
        axes[1, 0].set_ylabel('ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„° í¬ê¸°')
        axes[1, 0].set_title('íŠ¹ì§• ë²¡í„° í¬ê¸° ë¶„í¬')
        
        # ìƒ˜í”Œ ë²ˆí˜¸ í‘œì‹œ
        for i, result in enumerate(results):
            axes[1, 0].annotate(f'{result["sample_id"]}', 
                               (text_norms[i], image_norms[i]),
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        # 4. Attention ì§‘ì¤‘ë„ ë¹„êµ
        text_concentrations = [r['text_attention_stats'].get('concentration', 0) for r in results]
        image_concentrations = [r['image_attention_stats'].get('concentration', 0) for r in results]
        
        axes[1, 1].scatter(text_concentrations, image_concentrations,
                          c=['red' if r['type'] == 'spam' else 'blue' for r in results],
                          alpha=0.7, s=100)
        axes[1, 1].set_xlabel('í…ìŠ¤íŠ¸ Attention ì§‘ì¤‘ë„')
        axes[1, 1].set_ylabel('ì´ë¯¸ì§€ Attention ì§‘ì¤‘ë„')
        axes[1, 1].set_title('Attention ì§‘ì¤‘ë„ ë¶„í¬')
        
        # ë²”ë¡€ ì¶”ê°€
        spam_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', 
                               markersize=8, label='ìŠ¤íŒ¸')
        ham_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', 
                              markersize=8, label='ì •ìƒ')
        axes[1, 1].legend(handles=[spam_patch, ham_patch])
        
        plt.tight_layout()
        filename = 'modality_contribution_analysis.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ì‹œê°í™” ì €ì¥: {filename}")
    
    def generate_contribution_summary(self):
        """ê¸°ì—¬ë„ ë¶„ì„ ìš”ì•½ ìƒì„±"""
        if not self.contribution_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        print("\nğŸ“ˆ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ìš”ì•½")
        print("="*60)
        
        # ì „ì²´ í‰ê· 
        avg_text_contrib = np.mean([r['text_contribution_norm'] for r in self.contribution_results])
        avg_image_contrib = np.mean([r['image_contribution_norm'] for r in self.contribution_results])
        
        print(f"   ì „ì²´ í‰ê·  ê¸°ì—¬ë„:")
        print(f"     í…ìŠ¤íŠ¸: {avg_text_contrib:.1%}")
        print(f"     ì´ë¯¸ì§€: {avg_image_contrib:.1%}")
        
        # íƒ€ì…ë³„ ë¶„ì„
        spam_results = [r for r in self.contribution_results if r['type'] == 'spam']
        ham_results = [r for r in self.contribution_results if r['type'] == 'ham']
        
        if spam_results:
            spam_text_avg = np.mean([r['text_contribution_norm'] for r in spam_results])
            spam_image_avg = np.mean([r['image_contribution_norm'] for r in spam_results])
            print(f"\n   ìŠ¤íŒ¸ ì´ë©”ì¼ ê¸°ì—¬ë„:")
            print(f"     í…ìŠ¤íŠ¸: {spam_text_avg:.1%}")
            print(f"     ì´ë¯¸ì§€: {spam_image_avg:.1%}")
        
        if ham_results:
            ham_text_avg = np.mean([r['text_contribution_norm'] for r in ham_results])
            ham_image_avg = np.mean([r['image_contribution_norm'] for r in ham_results])
            print(f"\n   ì •ìƒ ì´ë©”ì¼ ê¸°ì—¬ë„:")
            print(f"     í…ìŠ¤íŠ¸: {ham_text_avg:.1%}")
            print(f"     ì´ë¯¸ì§€: {ham_image_avg:.1%}")
        
        # ê°œë³„ ìƒ˜í”Œ ê²°ê³¼
        print(f"\n   ê°œë³„ ìƒ˜í”Œ ê¸°ì—¬ë„:")
        for result in self.contribution_results:
            print(f"     ìƒ˜í”Œ {result['sample_id']} ({result['type']}): "
                  f"í…ìŠ¤íŠ¸ {result['text_contribution_norm']:.1%}, "
                  f"ì´ë¯¸ì§€ {result['image_contribution_norm']:.1%}")
    
    def run_modality_contribution_analysis(self, num_samples: int = 8):
        """ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ì‹œì‘")
        print("="*80)
        
        # ëª¨ë¸ ë° ë°ì´í„° ë¡œë”©
        if not self.load_model_and_data():
            return False
        
        # ìƒ˜í”Œ ì„ íƒ (ì´ì „ ë¶„ì„ê³¼ ë™ì¼í•œ ìƒ˜í”Œ ì‚¬ìš©)
        spam_samples = self.dataset[self.dataset['labels'] == 1].sample(n=num_samples//2, random_state=42)
        ham_samples = self.dataset[self.dataset['labels'] == 0].sample(n=num_samples//2, random_state=42)
        
        samples = []
        for idx, row in spam_samples.iterrows():
            samples.append({
                'text': row['texts'][:200] + "..." if len(str(row['texts'])) > 200 else str(row['texts']),
                'image_filename': row['pics'],
                'label': int(row['labels']),
                'type': 'spam'
            })
        
        for idx, row in ham_samples.iterrows():
            samples.append({
                'text': row['texts'][:200] + "..." if len(str(row['texts'])) > 200 else str(row['texts']),
                'image_filename': row['pics'],
                'label': int(row['labels']),
                'type': 'ham'
            })
        
        print(f"\nğŸ“Š {len(samples)}ê°œ ìƒ˜í”Œ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„...")
        
        # ê° ìƒ˜í”Œ ë¶„ì„
        for i, sample_data in enumerate(samples, 1):
            result = self.analyze_single_sample(sample_data, i)
        
        # ë‹¤ì–‘í•œ ì‹œê°í™” ì‹¤í–‰
        print("\nğŸ“Š ìƒ˜í”Œë³„ ìƒì„¸ ë¶„ì„ ì‹œê°í™” ìƒì„± ì¤‘...")
        self.visualize_sample_details(self.contribution_results)
        
        print("\nğŸ“Š ìƒì„¸ ëª¨ë‹¬ë¦¬í‹° ë¹„êµ ì°¨íŠ¸ ìƒì„± ì¤‘...")
        self.visualize_modality_comparison_chart(self.contribution_results)
        
        print("\nğŸ“Š ê¸°ë³¸ ê¸°ì—¬ë„ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì¤‘...")
        self.visualize_modality_contributions(self.contribution_results)
        
        # ìš”ì•½ ë¦¬í¬íŠ¸
        self.generate_contribution_summary()
        
        print("\nğŸ‰ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ì™„ë£Œ!")
        return True

    def visualize_sample_details(self, results: List[Dict]):
        """ê° ìƒ˜í”Œì˜ ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ê¸°ì—¬ë„ë¥¼ ìƒì„¸íˆ ì‹œê°í™”"""
        if not results:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        # 4ê°œì”© 2í–‰ìœ¼ë¡œ ë°°ì¹˜
        fig, axes = plt.subplots(2, 4, figsize=(20, 12))
        axes = axes.flatten()
        
        for i, result in enumerate(results):
            if i >= 8:  # ìµœëŒ€ 8ê°œë§Œ í‘œì‹œ
                break
                
            ax = axes[i]
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            if result['image_display'] is not None:
                ax.imshow(result['image_display'])
            else:
                # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°•ìŠ¤
                ax.imshow(np.ones((224, 224, 3)) * 0.9)
                ax.text(112, 112, 'ì´ë¯¸ì§€ ì—†ìŒ', ha='center', va='center', fontsize=12)
            
            ax.axis('off')
            
            # ì œëª©: ìƒ˜í”Œ ë²ˆí˜¸, íƒ€ì…, ì •í™•ë„
            correct = "âœ…" if (result['predicted_class'] == 1) == (result['true_label'] == 1) else "âŒ"
            title = f"ìƒ˜í”Œ {result['sample_id']} {correct}\n{result['type'].upper()}"
            ax.set_title(title, fontsize=11, fontweight='bold')
            
            # í…ìŠ¤íŠ¸ ë‚´ìš© (í•˜ë‹¨ì— í‘œì‹œ)
            text_content = result['text']
            if isinstance(text_content, str) and text_content.lower() != 'nan':
                # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆíˆ ì¤„ë°”ê¿ˆ
                if len(text_content) > 60:
                    text_display = text_content[:60] + "..."
                else:
                    text_display = text_content
            else:
                text_display = "(í…ìŠ¤íŠ¸ ì—†ìŒ)"
            
            # ê¸°ì—¬ë„ ì •ë³´
            text_contrib = result['text_contribution_norm'] * 100
            image_contrib = result['image_contribution_norm'] * 100
            
            # ì˜ˆì¸¡ ì •ë³´
            spam_prob = result['multimodal_pred'][1] * 100
            
            # ì •ë³´ ë°•ìŠ¤ ìƒì„±
            info_text = f"ì˜ˆì¸¡: {'ìŠ¤íŒ¸' if result['predicted_class'] == 1 else 'ì •ìƒ'} ({spam_prob:.1f}%)\n"
            info_text += f"ê¸°ì—¬ë„ - í…ìŠ¤íŠ¸: {text_contrib:.1f}%, ì´ë¯¸ì§€: {image_contrib:.1f}%\n"
            info_text += f"í…ìŠ¤íŠ¸: {text_display}"
            
            # í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ í•˜ë‹¨ì— ë°°ì¹˜
            ax.text(0.5, -0.15, info_text, transform=ax.transAxes, 
                   fontsize=8, ha='center', va='top',
                   bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgray', alpha=0.8),
                   wrap=True)
        
        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
        for i in range(len(results), 8):
            axes[i].axis('off')
        
        plt.suptitle('ì‹¤ì œ ì´ë©”ì¼ ìƒ˜í”Œë³„ ìƒì„¸ ë¶„ì„\n(ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ + ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„)', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.subplots_adjust(top=0.9, bottom=0.2)  # í…ìŠ¤íŠ¸ ê³µê°„ í™•ë³´
        
        filename = 'sample_details_analysis.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ìƒ˜í”Œë³„ ìƒì„¸ ë¶„ì„ ì‹œê°í™” ì €ì¥: {filename}")
    
    def visualize_modality_comparison_chart(self, results: List[Dict]):
        """ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¹„êµ ì°¨íŠ¸ (ë” ìƒì„¸í•œ ë²„ì „)"""
        if not results:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        # 2x3 ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë” ìƒì„¸í•œ ë¶„ì„
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # ë°ì´í„° ì¤€ë¹„
        sample_ids = [r['sample_id'] for r in results]
        text_contributions = [r['text_contribution_norm'] * 100 for r in results]
        image_contributions = [r['image_contribution_norm'] * 100 for r in results]
        sample_types = [r['type'] for r in results]
        spam_probs = [r['multimodal_pred'][1] * 100 for r in results]
        text_only_probs = [r['text_only_pred'][1] * 100 for r in results]
        image_only_probs = [r['image_only_pred'][1] * 100 for r in results]
        
        # 1. ìƒ˜í”Œë³„ ê¸°ì—¬ë„ (ê°œì„ ëœ ë²„ì „)
        x = np.arange(len(sample_ids))
        width = 0.6
        
        bars1 = axes[0, 0].bar(x, text_contributions, width, label='í…ìŠ¤íŠ¸', 
                              color='skyblue', alpha=0.8)
        bars2 = axes[0, 0].bar(x, image_contributions, width, bottom=text_contributions, 
                              label='ì´ë¯¸ì§€', color='lightcoral', alpha=0.8)
        
        # ìƒ˜í”Œ íƒ€ì…ë³„ í…Œë‘ë¦¬ ìƒ‰ìƒ
        for i, (bar1, bar2, stype) in enumerate(zip(bars1, bars2, sample_types)):
            color = 'red' if stype == 'spam' else 'blue'
            bar1.set_edgecolor(color)
            bar2.set_edgecolor(color)
            bar1.set_linewidth(3)
            bar2.set_linewidth(3)
        
        axes[0, 0].set_xlabel('ìƒ˜í”Œ ID')
        axes[0, 0].set_ylabel('ê¸°ì—¬ë„ (%)')
        axes[0, 0].set_title('ìƒ˜í”Œë³„ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„\n(ë¹¨ê°„ í…Œë‘ë¦¬: ìŠ¤íŒ¸, íŒŒë€ í…Œë‘ë¦¬: ì •ìƒ)')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels([f'#{i}' for i in sample_ids])
        axes[0, 0].legend()
        axes[0, 0].set_ylim(0, 100)
        
        # 2. ì˜ˆì¸¡ í™•ë¥  ë¹„êµ
        x_pos = np.arange(len(sample_ids))
        width = 0.25
        
        axes[0, 1].bar(x_pos - width, spam_probs, width, label='ë©€í‹°ëª¨ë‹¬', color='purple', alpha=0.7)
        axes[0, 1].bar(x_pos, text_only_probs, width, label='í…ìŠ¤íŠ¸ë§Œ', color='skyblue', alpha=0.7)
        axes[0, 1].bar(x_pos + width, image_only_probs, width, label='ì´ë¯¸ì§€ë§Œ', color='lightcoral', alpha=0.7)
        
        axes[0, 1].set_xlabel('ìƒ˜í”Œ ID')
        axes[0, 1].set_ylabel('ìŠ¤íŒ¸ í™•ë¥  (%)')
        axes[0, 1].set_title('ëª¨ë‹¬ë¦¬í‹°ë³„ ìŠ¤íŒ¸ ì˜ˆì¸¡ í™•ë¥ ')
        axes[0, 1].set_xticks(x_pos)
        axes[0, 1].set_xticklabels([f'#{i}' for i in sample_ids])
        axes[0, 1].legend()
        axes[0, 1].set_ylim(0, 100)
        
        # 3. íƒ€ì…ë³„ í‰ê·  ê¸°ì—¬ë„ (íŒŒì´ ì°¨íŠ¸)
        spam_results = [r for r in results if r['type'] == 'spam']
        ham_results = [r for r in results if r['type'] == 'ham']
        
        if spam_results:
            spam_text_avg = np.mean([r['text_contribution_norm'] for r in spam_results])
            spam_image_avg = np.mean([r['image_contribution_norm'] for r in spam_results])
            
            axes[0, 2].pie([spam_text_avg, spam_image_avg], 
                          labels=['í…ìŠ¤íŠ¸', 'ì´ë¯¸ì§€'], 
                          colors=['skyblue', 'lightcoral'],
                          autopct='%1.1f%%', startangle=90)
            axes[0, 2].set_title('ìŠ¤íŒ¸ ì´ë©”ì¼ í‰ê·  ê¸°ì—¬ë„')
        
        # 4. ì •ìƒ ì´ë©”ì¼ ê¸°ì—¬ë„ (íŒŒì´ ì°¨íŠ¸)
        if ham_results:
            ham_text_avg = np.mean([r['text_contribution_norm'] for r in ham_results])
            ham_image_avg = np.mean([r['image_contribution_norm'] for r in ham_results])
            
            axes[1, 0].pie([ham_text_avg, ham_image_avg], 
                          labels=['í…ìŠ¤íŠ¸', 'ì´ë¯¸ì§€'], 
                          colors=['skyblue', 'lightcoral'],
                          autopct='%1.1f%%', startangle=90)
            axes[1, 0].set_title('ì •ìƒ ì´ë©”ì¼ í‰ê·  ê¸°ì—¬ë„')
        
        # 5. íŠ¹ì§• ë²¡í„° í¬ê¸° ë¶„ì„
        text_norms = [r['text_feature_norm'] for r in results]
        image_norms = [r['image_feature_norm'] for r in results]
        
        for i, result in enumerate(results):
            color = 'red' if result['type'] == 'spam' else 'blue'
            axes[1, 1].scatter(text_norms[i], image_norms[i], 
                             c=color, alpha=0.7, s=120, edgecolors='black')
            axes[1, 1].annotate(f'{result["sample_id"]}', 
                               (text_norms[i], image_norms[i]),
                               xytext=(5, 5), textcoords='offset points', fontsize=10)
        
        axes[1, 1].set_xlabel('í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„° í¬ê¸°')
        axes[1, 1].set_ylabel('ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„° í¬ê¸°')
        axes[1, 1].set_title('íŠ¹ì§• ë²¡í„° í¬ê¸° ë¶„í¬')
        axes[1, 1].grid(True, alpha=0.3)
        
        # ë²”ë¡€ ì¶”ê°€
        spam_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', 
                               markersize=8, label='ìŠ¤íŒ¸')
        ham_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', 
                              markersize=8, label='ì •ìƒ')
        axes[1, 1].legend(handles=[spam_patch, ham_patch])
        
        # 6. ê¸°ì—¬ë„ vs ì •í™•ë„ ì‚°ì ë„
        accuracies = [(r['predicted_class'] == 1) == (r['true_label'] == 1) for r in results]
        text_contribs = [r['text_contribution_norm'] * 100 for r in results]
        
        for i, result in enumerate(results):
            color = 'green' if accuracies[i] else 'red'
            marker = 'o' if result['type'] == 'spam' else '^'
            axes[1, 2].scatter(text_contribs[i], image_contributions[i], 
                             c=color, marker=marker, alpha=0.7, s=120, edgecolors='black')
            axes[1, 2].annotate(f'{result["sample_id"]}', 
                               (text_contribs[i], image_contributions[i]),
                               xytext=(5, 5), textcoords='offset points', fontsize=10)
        
        axes[1, 2].set_xlabel('í…ìŠ¤íŠ¸ ê¸°ì—¬ë„ (%)')
        axes[1, 2].set_ylabel('ì´ë¯¸ì§€ ê¸°ì—¬ë„ (%)')
        axes[1, 2].set_title('ê¸°ì—¬ë„ vs ì˜ˆì¸¡ ì •í™•ë„\n(ì´ˆë¡: ì •í™•, ë¹¨ê°•: ì˜¤ë¥˜, ì›: ìŠ¤íŒ¸, ì‚¼ê°: ì •ìƒ)')
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        filename = 'detailed_modality_analysis.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ìƒì„¸ ëª¨ë‹¬ë¦¬í‹° ë¶„ì„ ì‹œê°í™” ì €ì¥: {filename}")


if __name__ == "__main__":
    # ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ ì‹¤í–‰
    analyzer = ModalityContributionAnalysis()
    analyzer.run_modality_contribution_analysis(num_samples=8) 