import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import sys
sys.path.append('.')

from models import MMTD
from transformers import AutoTokenizer
import warnings
warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class RealAttentionExtractorV2:
    """
    ì‹¤ì œ MMTD ëª¨ë¸ì—ì„œ attention ê°€ì¤‘ì¹˜ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ê°œì„ ëœ í´ë˜ìŠ¤
    - output_attentions=True ì‚¬ìš©
    - BERT text encoder attention
    - BEiT image encoder attention  
    - Multi-modality fusion layer attention
    """
    
    def __init__(self, checkpoint_path: str = "checkpoints/fold1/checkpoint-939/pytorch_model.bin"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else 
                                  "mps" if torch.backends.mps.is_available() else "cpu")
        self.checkpoint_path = checkpoint_path
        
        # ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.model = None
        self.tokenizer = None
        
        print(f"ğŸ”§ ì‹¤ì œ MMTD Attention ì¶”ì¶œê¸° V2 ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def load_model_and_checkpoint(self):
        """ì‹¤ì œ MMTD ëª¨ë¸ê³¼ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
        print("\nğŸ“‚ ì‹¤ì œ MMTD ëª¨ë¸ ë¡œë”©...")
        
        try:
            # ëª¨ë¸ ìƒì„±
            self.model = MMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            # â˜… í•µì‹¬: output_attentions=True ì„¤ì •
            self.model.text_encoder.config.output_attentions = True
            self.model.image_encoder.config.output_attentions = True
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(self.checkpoint_path, map_location='cpu')
            missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•˜ê³  ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model.eval()
            self.model.to(self.device)
            
            print(f"âœ… MMTD ëª¨ë¸ ë¡œë”© ì„±ê³µ ({sum(p.numel() for p in self.model.parameters()):,} íŒŒë¼ë¯¸í„°)")
            print(f"   Missing keys: {len(missing_keys)}, Unexpected keys: {len(unexpected_keys)}")
            print(f"   ğŸ¯ Attention ì¶œë ¥ í™œì„±í™”ë¨: BERT={self.model.text_encoder.config.output_attentions}, BEiT={self.model.image_encoder.config.output_attentions}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë”©
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
            
            print("âœ… í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def create_sample_input(self, text: str = "ìŠ¤íŒ¸ ì´ë©”ì¼ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ", image_size: int = 224):
        """ìƒ˜í”Œ ì…ë ¥ ë°ì´í„° ìƒì„±"""
        print(f"\nğŸ“ ìƒ˜í”Œ ì…ë ¥ ìƒì„±: '{text}'")
        
        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        text_inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        )
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œë¡œëŠ” ì´ë©”ì¼ ì´ë¯¸ì§€ ì‚¬ìš©)
        dummy_image = torch.randn(1, 3, image_size, image_size)
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        inputs = {
            'input_ids': text_inputs['input_ids'].to(self.device),
            'attention_mask': text_inputs['attention_mask'].to(self.device),
            'token_type_ids': torch.zeros_like(text_inputs['input_ids']).to(self.device),
            'pixel_values': dummy_image.to(self.device)
        }
        
        print(f"âœ… ì…ë ¥ ë°ì´í„° ìƒì„± ì™„ë£Œ:")
        for key, tensor in inputs.items():
            print(f"   {key}: {tensor.shape}")
        
        return inputs, text
    
    def extract_attention_weights_step_by_step(self, inputs: Dict[str, torch.Tensor]):
        """ë‹¨ê³„ë³„ë¡œ attention ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
        print("\nğŸ” ë‹¨ê³„ë³„ ì‹¤ì œ Attention ê°€ì¤‘ì¹˜ ì¶”ì¶œ...")
        
        attention_data = {}
        
        with torch.no_grad():
            # 1. BERT í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‹¤í–‰
            print("   1. BERT í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‹¤í–‰...")
            text_inputs = {k: v for k, v in inputs.items() if k != 'pixel_values'}
            text_outputs = self.model.text_encoder(**text_inputs)
            
            # BERT attention ì¶”ì¶œ
            if hasattr(text_outputs, 'attentions') and text_outputs.attentions is not None:
                attention_data['bert_attentions'] = [att.cpu() for att in text_outputs.attentions]
                print(f"     âœ… BERT attention ì¶”ì¶œ ì™„ë£Œ: {len(text_outputs.attentions)}ê°œ ë ˆì´ì–´")
                print(f"     ë§ˆì§€ë§‰ ë ˆì´ì–´ í˜•íƒœ: {text_outputs.attentions[-1].shape}")
            else:
                print(f"     âŒ BERT attention ì—†ìŒ")
            
            # 2. BEiT ì´ë¯¸ì§€ ì¸ì½”ë” ì‹¤í–‰
            print("   2. BEiT ì´ë¯¸ì§€ ì¸ì½”ë” ì‹¤í–‰...")
            image_outputs = self.model.image_encoder(pixel_values=inputs['pixel_values'])
            
            # BEiT attention ì¶”ì¶œ
            if hasattr(image_outputs, 'attentions') and image_outputs.attentions is not None:
                attention_data['beit_attentions'] = [att.cpu() for att in image_outputs.attentions]
                print(f"     âœ… BEiT attention ì¶”ì¶œ ì™„ë£Œ: {len(image_outputs.attentions)}ê°œ ë ˆì´ì–´")
                print(f"     ë§ˆì§€ë§‰ ë ˆì´ì–´ í˜•íƒœ: {image_outputs.attentions[-1].shape}")
            else:
                print(f"     âŒ BEiT attention ì—†ìŒ")
            
            # 3. ìœµí•© ë ˆì´ì–´ ì‹¤í–‰ (ì „ì²´ ëª¨ë¸)
            print("   3. ì „ì²´ ëª¨ë¸ ì‹¤í–‰...")
            full_outputs = self.model(**inputs)
            
            # ì˜ˆì¸¡ ê²°ê³¼
            prediction = torch.softmax(full_outputs.logits, dim=-1)
            predicted_class = torch.argmax(prediction, dim=-1).item()
            confidence = prediction.max().item()
            
            attention_data.update({
                'prediction': prediction.cpu().numpy(),
                'predicted_class': predicted_class,
                'confidence': confidence,
                'text_hidden_states': text_outputs.hidden_states,
                'image_hidden_states': image_outputs.hidden_states
            })
            
            print(f"   ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: {'ìŠ¤íŒ¸' if predicted_class == 1 else 'ì •ìƒ'} (ì‹ ë¢°ë„: {confidence:.4f})")
        
        return attention_data
    
    def visualize_bert_attention(self, text: str, attention_data: Dict, layer_idx: int = 11):
        """BERT í…ìŠ¤íŠ¸ attention ì‹œê°í™”"""
        print(f"\nğŸ“Š BERT í…ìŠ¤íŠ¸ Attention ì‹œê°í™” (ë ˆì´ì–´ {layer_idx})")
        
        if 'bert_attentions' not in attention_data:
            print("âŒ BERT attention ë°ì´í„° ì—†ìŒ")
            return
        
        # í† í° ë¶„ë¦¬
        tokens = self.tokenizer.tokenize(text)
        tokens = ['[CLS]'] + tokens + ['[SEP]']
        
        # ì§€ì •ëœ ë ˆì´ì–´ì˜ attention
        attention = attention_data['bert_attentions'][layer_idx]  # [batch, heads, seq, seq]
        
        # í‰ê·  attention (ëª¨ë“  í—¤ë“œì˜ í‰ê· )
        attention_avg = attention[0].mean(dim=0)  # [seq, seq]
        
        # ì‹œê°í™”
        plt.figure(figsize=(12, 10))
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë§ê²Œ ì¡°ì •
        seq_len = min(len(tokens), attention_avg.shape[0])
        attention_matrix = attention_avg[:seq_len, :seq_len].numpy()
        
        sns.heatmap(
            attention_matrix, 
            xticklabels=tokens[:seq_len], 
            yticklabels=tokens[:seq_len],
            cmap='Blues',
            annot=False,
            fmt='.3f',
            cbar_kws={'label': 'Attention ê°€ì¤‘ì¹˜'}
        )
        
        plt.title(f'ì‹¤ì œ BERT í…ìŠ¤íŠ¸ Attention (ë ˆì´ì–´ {layer_idx})\n'
                 f'ì˜ˆì¸¡: {"ìŠ¤íŒ¸" if attention_data["predicted_class"] == 1 else "ì •ìƒ"} '
                 f'(ì‹ ë¢°ë„: {attention_data["confidence"]:.3f})')
        plt.xlabel('To Tokens')
        plt.ylabel('From Tokens')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        filename = f'real_bert_attention_v2_layer_{layer_idx}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… BERT attention ì‹œê°í™” ì €ì¥: {filename}")
    
    def visualize_beit_attention(self, attention_data: Dict, layer_idx: int = 11):
        """BEiT ì´ë¯¸ì§€ attention ì‹œê°í™”"""
        print(f"\nğŸ–¼ï¸ BEiT ì´ë¯¸ì§€ Attention ì‹œê°í™” (ë ˆì´ì–´ {layer_idx})")
        
        if 'beit_attentions' not in attention_data:
            print("âŒ BEiT attention ë°ì´í„° ì—†ìŒ")
            return
        
        # ì§€ì •ëœ ë ˆì´ì–´ì˜ attention
        attention = attention_data['beit_attentions'][layer_idx]  # [batch, heads, patches, patches]
        
        # í‰ê·  attention (ëª¨ë“  í—¤ë“œì˜ í‰ê· )
        attention_avg = attention[0].mean(dim=0)  # [patches, patches]
        
        # CLS í† í° ì œì™¸ (ì²« ë²ˆì§¸ í† í°ì´ CLSì¸ ê²½ìš°)
        if attention_avg.shape[0] > 196:  # 14x14=196 íŒ¨ì¹˜ + CLS
            image_attention = attention_avg[1:, 1:]  # CLS ì œê±°
        else:
            image_attention = attention_avg
        
        # íŒ¨ì¹˜ attentionì„ ì´ë¯¸ì§€ í˜•íƒœë¡œ ì¬êµ¬ì„±
        num_patches = int(np.sqrt(image_attention.shape[0]))
        
        if num_patches**2 == image_attention.shape[0]:
            # ê° íŒ¨ì¹˜ì˜ self-attention (ëŒ€ê°ì„ )
            self_attention = torch.diag(image_attention)
            attention_map = self_attention.reshape(num_patches, num_patches).numpy()
        else:
            # ì „ì²´ attentionì˜ í‰ê· 
            attention_map = image_attention.mean(dim=1).reshape(num_patches, num_patches).numpy()
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(1, 2, figsize=(15, 7))
        
        # ì›ë³¸ attention íˆíŠ¸ë§µ
        im1 = axes[0].imshow(attention_map, cmap='viridis', interpolation='nearest')
        axes[0].set_title(f'BEiT ì´ë¯¸ì§€ Attention Map (ë ˆì´ì–´ {layer_idx})')
        axes[0].set_xlabel('ì´ë¯¸ì§€ íŒ¨ì¹˜ (X)')
        axes[0].set_ylabel('ì´ë¯¸ì§€ íŒ¨ì¹˜ (Y)')
        plt.colorbar(im1, ax=axes[0])
        
        # ì—…ìƒ˜í”Œë§ëœ attention ë§µ
        upsampled = torch.nn.functional.interpolate(
            torch.tensor(attention_map).unsqueeze(0).unsqueeze(0).float(), 
            size=(224, 224), 
            mode='bilinear'
        )[0, 0].numpy()
        
        im2 = axes[1].imshow(upsampled, cmap='hot', interpolation='bilinear')
        axes[1].set_title('ê³ í•´ìƒë„ Attention ì˜¤ë²„ë ˆì´')
        axes[1].set_xlabel('í”½ì…€ X')
        axes[1].set_ylabel('í”½ì…€ Y')
        plt.colorbar(im2, ax=axes[1])
        
        plt.suptitle(f'ì‹¤ì œ BEiT ì´ë¯¸ì§€ Attention ë¶„ì„\n'
                    f'ì˜ˆì¸¡: {"ìŠ¤íŒ¸" if attention_data["predicted_class"] == 1 else "ì •ìƒ"} '
                    f'(ì‹ ë¢°ë„: {attention_data["confidence"]:.3f})')
        plt.tight_layout()
        
        filename = f'real_beit_attention_v2_layer_{layer_idx}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… BEiT attention ì‹œê°í™” ì €ì¥: {filename}")
    
    def analyze_attention_patterns(self, attention_data: Dict):
        """Attention íŒ¨í„´ ë¶„ì„"""
        print(f"\nğŸ”¬ Attention íŒ¨í„´ ë¶„ì„")
        
        if 'bert_attentions' in attention_data:
            # BERT attention í†µê³„
            bert_attention = attention_data['bert_attentions'][-1][0]  # ë§ˆì§€ë§‰ ë ˆì´ì–´, ì²« ë²ˆì§¸ ìƒ˜í”Œ
            bert_entropy = -torch.sum(bert_attention * torch.log(bert_attention + 1e-12), dim=-1).mean()
            print(f"   BERT Attention ì—”íŠ¸ë¡œí”¼: {bert_entropy:.4f}")
            print(f"   BERT Attention ì§‘ì¤‘ë„ (ìµœëŒ€ê°’): {bert_attention.max():.4f}")
        
        if 'beit_attentions' in attention_data:
            # BEiT attention í†µê³„
            beit_attention = attention_data['beit_attentions'][-1][0]  # ë§ˆì§€ë§‰ ë ˆì´ì–´, ì²« ë²ˆì§¸ ìƒ˜í”Œ
            beit_entropy = -torch.sum(beit_attention * torch.log(beit_attention + 1e-12), dim=-1).mean()
            print(f"   BEiT Attention ì—”íŠ¸ë¡œí”¼: {beit_entropy:.4f}")
            print(f"   BEiT Attention ì§‘ì¤‘ë„ (ìµœëŒ€ê°’): {beit_attention.max():.4f}")
        
        # ì˜ˆì¸¡ ì‹ ë¢°ë„ì™€ attention íŒ¨í„´ ê´€ê³„
        confidence = attention_data['confidence']
        print(f"   ì˜ˆì¸¡ ì‹ ë¢°ë„: {confidence:.4f}")
        
        if confidence > 0.9:
            print("   ğŸ“Š ë†’ì€ ì‹ ë¢°ë„: ëª…í™•í•œ íŒ¨í„´ íƒì§€")
        elif confidence > 0.7:
            print("   ğŸ“Š ì¤‘ê°„ ì‹ ë¢°ë„: ëª¨í˜¸í•œ íŒ¨í„´")
        else:
            print("   ğŸ“Š ë‚®ì€ ì‹ ë¢°ë„: ë¶ˆí™•ì‹¤í•œ íŒ¨í„´")
    
    def run_real_attention_analysis(self, text: str = "ë¬´ë£Œ ìƒí’ˆ ë°›ê¸°! ì§€ê¸ˆ í´ë¦­í•˜ì„¸ìš”!"):
        """ì‹¤ì œ attention ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ì‹¤ì œ MMTD Attention ë¶„ì„ V2 ì‹œì‘")
        print("="*60)
        
        try:
            # 1. ëª¨ë¸ ë¡œë”©
            if not self.load_model_and_checkpoint():
                return False
            
            # 2. ìƒ˜í”Œ ì…ë ¥ ìƒì„±
            inputs, processed_text = self.create_sample_input(text)
            
            # 3. Attention ì¶”ì¶œ
            attention_data = self.extract_attention_weights_step_by_step(inputs)
            
            # 4. ì‹œê°í™”
            self.visualize_bert_attention(processed_text, attention_data, layer_idx=11)
            self.visualize_beit_attention(attention_data, layer_idx=11)
            
            # 5. íŒ¨í„´ ë¶„ì„
            self.analyze_attention_patterns(attention_data)
            
            print("\nğŸ‰ ì‹¤ì œ MMTD Attention ë¶„ì„ V2 ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return False


if __name__ == "__main__":
    # ì‹¤ì œ attention ë¶„ì„ ì‹¤í–‰
    extractor = RealAttentionExtractorV2()
    
    # í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë“¤
    test_samples = [
        "ë¬´ë£Œ ìƒí’ˆì„ ë°›ìœ¼ì„¸ìš”! ì§€ê¸ˆ í´ë¦­í•˜ì„¸ìš”!",  # í•œêµ­ì–´ ìŠ¤íŒ¸
        "ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ ì¼ì •ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.",     # í•œêµ­ì–´ ì •ìƒ
        "FREE MONEY! Click here NOW!!!",          # ì˜ì–´ ìŠ¤íŒ¸
    ]
    
    for i, sample_text in enumerate(test_samples):
        print(f"\n{'='*80}")
        print(f"ìƒ˜í”Œ {i+1}: {sample_text}")
        print(f"{'='*80}")
        
        success = extractor.run_real_attention_analysis(sample_text)
        if not success:
            print(f"âš ï¸ ìƒ˜í”Œ {i+1} ë¶„ì„ ì‹¤íŒ¨")
            break
    
    print("\nâœ… ëª¨ë“  ì‹¤ì œ attention ë¶„ì„ V2 ì™„ë£Œ!") 