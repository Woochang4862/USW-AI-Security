import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import sys
sys.path.append('.')
from PIL import Image
import pandas as pd
import os
import random

from models import MMTD
from transformers import AutoTokenizer
import warnings
warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class RealEmailAttentionAnalysis:
    """
    ì‹¤ì œ MMTD ëª¨ë¸ê³¼ ì‹¤ì œ ì´ë©”ì¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ í¬ê´„ì ì¸ attention ë¶„ì„
    - ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ì‚¬ìš©
    - ë©€í‹°ì–¸ì–´ ìƒ˜í”Œ ë¶„ì„
    - ì›ë³¸ ì´ë¯¸ì§€ì™€ attention ì˜¤ë²„ë ˆì´
    - ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¶„ì„
    """
    
    def __init__(self, 
                 checkpoint_path: str = "checkpoints/fold1/checkpoint-939/pytorch_model.bin",
                 data_csv_path: str = "DATA/email_data/EDP_sample.csv",
                 image_dir: str = "DATA/email_data/pics"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else 
                                  "mps" if torch.backends.mps.is_available() else "cpu")
        self.checkpoint_path = checkpoint_path
        self.data_csv_path = data_csv_path
        self.image_dir = image_dir
        
        # ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.model = None
        self.tokenizer = None
        
        # ë°ì´í„°ì…‹ ë¡œë”©
        self.dataset = None
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = []
        
        print(f"ğŸ”§ ì‹¤ì œ ì´ë©”ì¼ MMTD Attention ë¶„ì„ê¸° ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def load_model_and_checkpoint(self):
        """ì‹¤ì œ MMTD ëª¨ë¸ê³¼ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
        print("\nğŸ“‚ ì‹¤ì œ MMTD ëª¨ë¸ ë¡œë”©...")
        
        try:
            # ëª¨ë¸ ìƒì„±
            self.model = MMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            # â˜… í•µì‹¬: output_attentions=True ì„¤ì •
            self.model.text_encoder.config.output_attentions = True
            self.model.image_encoder.config.output_attentions = True
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(self.checkpoint_path, map_location='cpu')
            missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•˜ê³  ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model.eval()
            self.model.to(self.device)
            
            print(f"âœ… MMTD ëª¨ë¸ ë¡œë”© ì„±ê³µ ({sum(p.numel() for p in self.model.parameters()):,} íŒŒë¼ë¯¸í„°)")
            print(f"   Missing keys: {len(missing_keys)}, Unexpected keys: {len(unexpected_keys)}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë”©
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')
            
            print("âœ… í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def load_email_dataset(self):
        """ì‹¤ì œ ì´ë©”ì¼ ë°ì´í„°ì…‹ ë¡œë”©"""
        print(f"\nğŸ“Š ì‹¤ì œ ì´ë©”ì¼ ë°ì´í„°ì…‹ ë¡œë”©...")
        
        try:
            # CSV íŒŒì¼ ë¡œë”©
            self.dataset = pd.read_csv(self.data_csv_path)
            print(f"âœ… ë°ì´í„°ì…‹ ë¡œë”© ì„±ê³µ: {len(self.dataset)}ê°œ ìƒ˜í”Œ")
            print(f"   ì»¬ëŸ¼: {list(self.dataset.columns)}")
            
            # ë¼ë²¨ ë¶„í¬ í™•ì¸
            if 'labels' in self.dataset.columns:
                label_counts = self.dataset['labels'].value_counts()
                print(f"   ë¼ë²¨ ë¶„í¬: {dict(label_counts)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def load_real_email_image(self, image_filename: str, label: int):
        """ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€ ë¡œë”©"""
        try:
            # ì´ë¯¸ì§€ ê²½ë¡œê°€ ì´ë¯¸ ham/ ë˜ëŠ” spam/ prefixë¥¼ í¬í•¨í•˜ê³  ìˆìŒ
            image_path = os.path.join(self.image_dir, image_filename)
            
            # ì´ë¯¸ì§€ ì¡´ì¬ í™•ì¸
            if not os.path.exists(image_path):
                print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
                return None, None
            
            # ì´ë¯¸ì§€ ë¡œë”©
            image = Image.open(image_path).convert('RGB')
            
            # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            image = image.resize((224, 224))
            
            # numpy ë°°ì—´ê³¼ tensorë¡œ ë³€í™˜
            image_array = np.array(image)
            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).float() / 255.0
            
            return image_tensor.unsqueeze(0), image_array  # [1, 3, 224, 224], numpy array
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨ ({image_filename}): {e}")
            return None, None
    
    def create_sample_input(self, text: str, image_filename: str, label: int):
        """ì‹¤ì œ ì´ë©”ì¼ ë°ì´í„°ë¡œ ìƒ˜í”Œ ì…ë ¥ ìƒì„±"""
        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        text_inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        )
        
        # ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€ ë¡œë”©
        image_tensor, image_display = self.load_real_email_image(image_filename, label)
        
        if image_tensor is None:
            return None, None, None
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        inputs = {
            'input_ids': text_inputs['input_ids'].to(self.device),
            'attention_mask': text_inputs['attention_mask'].to(self.device),
            'token_type_ids': torch.zeros_like(text_inputs['input_ids']).to(self.device),
            'pixel_values': image_tensor.to(self.device)
        }
        
        return inputs, text, image_display
    
    def extract_attention_weights(self, inputs: Dict[str, torch.Tensor]):
        """ì‹¤ì œ attention ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
        attention_data = {}
        
        with torch.no_grad():
            # 1. BERT í…ìŠ¤íŠ¸ ì¸ì½”ë” ì‹¤í–‰
            text_inputs = {k: v for k, v in inputs.items() if k != 'pixel_values'}
            text_outputs = self.model.text_encoder(**text_inputs)
            
            # BERT attention ì¶”ì¶œ
            if hasattr(text_outputs, 'attentions') and text_outputs.attentions is not None:
                attention_data['bert_attentions'] = [att.cpu() for att in text_outputs.attentions]
            
            # 2. BEiT ì´ë¯¸ì§€ ì¸ì½”ë” ì‹¤í–‰
            image_outputs = self.model.image_encoder(pixel_values=inputs['pixel_values'])
            
            # BEiT attention ì¶”ì¶œ
            if hasattr(image_outputs, 'attentions') and image_outputs.attentions is not None:
                attention_data['beit_attentions'] = [att.cpu() for att in image_outputs.attentions]
            
            # 3. ì „ì²´ ëª¨ë¸ ì‹¤í–‰
            full_outputs = self.model(**inputs)
            
            # ì˜ˆì¸¡ ê²°ê³¼
            prediction = torch.softmax(full_outputs.logits, dim=-1)
            predicted_class = torch.argmax(prediction, dim=-1).item()
            confidence = prediction.max().item()
            
            attention_data.update({
                'prediction': prediction.cpu().numpy(),
                'predicted_class': predicted_class,
                'confidence': confidence,
                'text_hidden_states': text_outputs.hidden_states,
                'image_hidden_states': image_outputs.hidden_states
            })
        
        return attention_data
    
    def get_sample_by_criteria(self, num_samples: int = 8):
        """ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œ ì„ íƒ"""
        if self.dataset is None:
            print("âŒ ë°ì´í„°ì…‹ì´ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
            return []
        
        selected_samples = []
        
        # ìŠ¤íŒ¸ê³¼ ì •ìƒì„ ë°˜ë°˜ì”©
        spam_samples = self.dataset[self.dataset['labels'] == 1].sample(n=num_samples//2, random_state=42)
        ham_samples = self.dataset[self.dataset['labels'] == 0].sample(n=num_samples//2, random_state=42)
        
        # ìƒ˜í”Œ ì •ë³´ ì •ë¦¬
        for idx, row in spam_samples.iterrows():
            selected_samples.append({
                'text': row['texts'][:200] + "..." if len(str(row['texts'])) > 200 else str(row['texts']),
                'image_filename': row['pics'],
                'label': int(row['labels']),
                'type': 'spam'
            })
        
        for idx, row in ham_samples.iterrows():
            selected_samples.append({
                'text': row['texts'][:200] + "..." if len(str(row['texts'])) > 200 else str(row['texts']),
                'image_filename': row['pics'],
                'label': int(row['labels']),
                'type': 'ham'
            })
        
        return selected_samples
    
    def analyze_single_sample(self, sample_data: Dict, sample_id: int):
        """ë‹¨ì¼ ì‹¤ì œ ì´ë©”ì¼ ìƒ˜í”Œ ë¶„ì„"""
        print(f"\nğŸ“Š ìƒ˜í”Œ {sample_id} ë¶„ì„: {sample_data['type'].upper()} ({'ìŠ¤íŒ¸' if sample_data['label'] == 1 else 'ì •ìƒ'})")
        print(f"   ì´ë¯¸ì§€: {sample_data['image_filename']}")
        print(f"   í…ìŠ¤íŠ¸: {sample_data['text'][:50]}...")
        
        # ì…ë ¥ ìƒì„±
        inputs, processed_text, image_display = self.create_sample_input(
            sample_data['text'], 
            sample_data['image_filename'], 
            sample_data['label']
        )
        
        if inputs is None:
            print(f"   âš ï¸ ìƒ˜í”Œ {sample_id} ìŠ¤í‚µ (ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨)")
            return None
        
        # Attention ì¶”ì¶œ
        attention_data = self.extract_attention_weights(inputs)
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'sample_id': sample_id,
            'text': sample_data['text'],
            'image_filename': sample_data['image_filename'],
            'true_label': sample_data['label'],
            'type': sample_data['type'],
            'predicted_class': attention_data['predicted_class'],
            'confidence': attention_data['confidence'],
            'bert_attentions': attention_data.get('bert_attentions'),
            'beit_attentions': attention_data.get('beit_attentions'),
            'image_display': image_display,
            'tokens': self.tokenizer.tokenize(sample_data['text'])
        }
        
        self.analysis_results.append(result)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
        correct = "âœ…" if (attention_data['predicted_class'] == 1) == (sample_data['label'] == 1) else "âŒ"
        print(f"   {correct} ì˜ˆì¸¡: {'ìŠ¤íŒ¸' if attention_data['predicted_class'] == 1 else 'ì •ìƒ'} "
              f"(ì‹ ë¢°ë„: {attention_data['confidence']:.3f})")
        
        return result
    
    def visualize_image_attention_with_original(self, result: Dict, layer_idx: int = 11):
        """ì‹¤ì œ ì›ë³¸ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì´ë¯¸ì§€ attention ì‹œê°í™”"""
        if 'beit_attentions' not in result or result['beit_attentions'] is None:
            print("âŒ BEiT attention ë°ì´í„° ì—†ìŒ")
            return
        
        # ì§€ì •ëœ ë ˆì´ì–´ì˜ attention
        attention = result['beit_attentions'][layer_idx]  # [batch, heads, patches, patches]
        attention_avg = attention[0].mean(dim=0)  # [patches, patches]
        
        # CLS í† í° ì œì™¸
        if attention_avg.shape[0] > 196:  # 14x14=196 íŒ¨ì¹˜ + CLS
            image_attention = attention_avg[1:, 1:]  # CLS ì œê±°
        else:
            image_attention = attention_avg
        
        # íŒ¨ì¹˜ attentionì„ ì´ë¯¸ì§€ í˜•íƒœë¡œ ì¬êµ¬ì„±
        num_patches = int(np.sqrt(image_attention.shape[0]))
        
        if num_patches**2 == image_attention.shape[0]:
            self_attention = torch.diag(image_attention)
            attention_map = self_attention.reshape(num_patches, num_patches).numpy()
        else:
            attention_map = image_attention.mean(dim=1).reshape(num_patches, num_patches).numpy()
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # 1. ì‹¤ì œ ì›ë³¸ ì´ë©”ì¼ ì´ë¯¸ì§€
        axes[0].imshow(result['image_display'])
        axes[0].set_title(f'ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€\n{result["type"].upper()} (íŒŒì¼: {result["image_filename"][:20]}...)')
        axes[0].axis('off')
        
        # 2. Attention íˆíŠ¸ë§µ
        im1 = axes[1].imshow(attention_map, cmap='viridis', interpolation='nearest')
        axes[1].set_title(f'BEiT Attention Map (ë ˆì´ì–´ {layer_idx})')
        axes[1].set_xlabel('ì´ë¯¸ì§€ íŒ¨ì¹˜ (X)')
        axes[1].set_ylabel('ì´ë¯¸ì§€ íŒ¨ì¹˜ (Y)')
        plt.colorbar(im1, ax=axes[1])
        
        # 3. ì‹¤ì œ ì´ë¯¸ì§€ + Attention ì˜¤ë²„ë ˆì´
        # Attention ë§µì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì—…ìƒ˜í”Œë§
        upsampled = torch.nn.functional.interpolate(
            torch.tensor(attention_map).unsqueeze(0).unsqueeze(0).float(), 
            size=(224, 224), 
            mode='bilinear'
        )[0, 0].numpy()
        
        # ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        axes[2].imshow(result['image_display'])
        # Attention ì˜¤ë²„ë ˆì´ (íˆ¬ëª…ë„ ì ìš©)
        im2 = axes[2].imshow(upsampled, cmap='hot', alpha=0.5, interpolation='bilinear')
        axes[2].set_title('ì‹¤ì œ ì´ë¯¸ì§€ + Attention ì˜¤ë²„ë ˆì´')
        axes[2].axis('off')
        plt.colorbar(im2, ax=axes[2])
        
        # ì˜ˆì¸¡ ì •í™•ë„ í‘œì‹œ
        correct = "âœ…" if (result['predicted_class'] == 1) == (result['true_label'] == 1) else "âŒ"
        plt.suptitle(f'ì‹¤ì œ ì´ë©”ì¼ Attention ë¶„ì„ - ìƒ˜í”Œ {result["sample_id"]} {correct}\n'
                    f'ì‹¤ì œ: {"ìŠ¤íŒ¸" if result["true_label"] == 1 else "ì •ìƒ"} | '
                    f'ì˜ˆì¸¡: {"ìŠ¤íŒ¸" if result["predicted_class"] == 1 else "ì •ìƒ"} '
                    f'(ì‹ ë¢°ë„: {result["confidence"]:.3f})')
        plt.tight_layout()
        
        filename = f'real_email_image_attention_sample_{result["sample_id"]}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ì‹¤ì œ ì´ë©”ì¼ ì´ë¯¸ì§€ attention ì‹œê°í™” ì €ì¥: {filename}")
    
    def visualize_text_attention(self, result: Dict, layer_idx: int = 11):
        """ì‹¤ì œ ì´ë©”ì¼ í…ìŠ¤íŠ¸ attention ì‹œê°í™”"""
        if 'bert_attentions' not in result or result['bert_attentions'] is None:
            print("âŒ BERT attention ë°ì´í„° ì—†ìŒ")
            return
        
        # í† í° ì¤€ë¹„ (ì²˜ìŒ 15ê°œë§Œ í‘œì‹œ)
        tokens = ['[CLS]'] + result['tokens'][:13] + ['[SEP]']
        
        # ì§€ì •ëœ ë ˆì´ì–´ì˜ attention
        attention = result['bert_attentions'][layer_idx]  # [batch, heads, seq, seq]
        attention_avg = attention[0].mean(dim=0)  # [seq, seq]
        
        # ì‹œê°í™”
        plt.figure(figsize=(12, 10))
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë§ê²Œ ì¡°ì •
        seq_len = min(len(tokens), attention_avg.shape[0])
        attention_matrix = attention_avg[:seq_len, :seq_len].numpy()
        
        sns.heatmap(
            attention_matrix, 
            xticklabels=tokens[:seq_len], 
            yticklabels=tokens[:seq_len],
            cmap='Blues',
            annot=False,
            fmt='.3f',
            cbar_kws={'label': 'Attention ê°€ì¤‘ì¹˜'}
        )
        
        # ì˜ˆì¸¡ ì •í™•ë„ í‘œì‹œ
        correct = "âœ…" if (result['predicted_class'] == 1) == (result['true_label'] == 1) else "âŒ"
        plt.title(f'ì‹¤ì œ BERT í…ìŠ¤íŠ¸ Attention - ìƒ˜í”Œ {result["sample_id"]} {correct} (ë ˆì´ì–´ {layer_idx})\n'
                 f'{result["type"].upper()} | ì‹¤ì œ: {"ìŠ¤íŒ¸" if result["true_label"] == 1 else "ì •ìƒ"} | '
                 f'ì˜ˆì¸¡: {"ìŠ¤íŒ¸" if result["predicted_class"] == 1 else "ì •ìƒ"} '
                 f'(ì‹ ë¢°ë„: {result["confidence"]:.3f})')
        plt.xlabel('To Tokens')
        plt.ylabel('From Tokens')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        filename = f'real_email_text_attention_sample_{result["sample_id"]}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ì‹¤ì œ ì´ë©”ì¼ í…ìŠ¤íŠ¸ attention ì‹œê°í™” ì €ì¥: {filename}")
    
    def run_comprehensive_real_email_analysis(self, num_samples: int = 8):
        """í¬ê´„ì ì¸ ì‹¤ì œ ì´ë©”ì¼ attention ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì‹¤ì œ ì´ë©”ì¼ MMTD Attention ë¶„ì„ ì‹œì‘")
        print("="*80)
        
        # ëª¨ë¸ ë¡œë”©
        if not self.load_model_and_checkpoint():
            return False
        
        # ë°ì´í„°ì…‹ ë¡œë”©
        if not self.load_email_dataset():
            return False
        
        # ìƒ˜í”Œ ì„ íƒ
        samples = self.get_sample_by_criteria(num_samples)
        print(f"\nğŸ“Š {len(samples)}ê°œ ì‹¤ì œ ì´ë©”ì¼ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘...")
        
        # ê° ìƒ˜í”Œ ë¶„ì„
        for i, sample_data in enumerate(samples, 1):
            result = self.analyze_single_sample(sample_data, i)
            
            if result is not None:
                # ì‹œê°í™”
                self.visualize_text_attention(result, layer_idx=11)
                self.visualize_image_attention_with_original(result, layer_idx=11)
        
        # ì¢…í•© ë¶„ì„
        self.generate_comprehensive_summary()
        
        print("\nğŸ‰ ì‹¤ì œ ì´ë©”ì¼ MMTD Attention ë¶„ì„ ì™„ë£Œ!")
        return True
    
    def generate_comprehensive_summary(self):
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        print("\nğŸ“ˆ ì‹¤ì œ ì´ë©”ì¼ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        if not self.analysis_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        total_samples = len(self.analysis_results)
        correct_predictions = sum(1 for r in self.analysis_results 
                                if (r['predicted_class'] == 1) == (r['true_label'] == 1))
        accuracy = correct_predictions / total_samples
        
        print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {total_samples}")
        print(f"   ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions}")
        print(f"   ì‹¤ì œ ë°ì´í„° ì •í™•ë„: {accuracy:.1%}")
        
        # ìŠ¤íŒ¸/ì •ìƒë³„ ë¶„ì„
        spam_results = [r for r in self.analysis_results if r['true_label'] == 1]
        ham_results = [r for r in self.analysis_results if r['true_label'] == 0]
        
        if spam_results:
            spam_acc = sum(1 for r in spam_results if r['predicted_class'] == 1) / len(spam_results)
            avg_spam_conf = sum(r['confidence'] for r in spam_results) / len(spam_results)
            print(f"\n   ìŠ¤íŒ¸ ì´ë©”ì¼ ì„±ëŠ¥:")
            print(f"     íƒì§€ìœ¨: {spam_acc:.1%}")
            print(f"     í‰ê·  ì‹ ë¢°ë„: {avg_spam_conf:.3f}")
        
        if ham_results:
            ham_acc = sum(1 for r in ham_results if r['predicted_class'] == 0) / len(ham_results)
            avg_ham_conf = sum(r['confidence'] for r in ham_results) / len(ham_results)
            print(f"\n   ì •ìƒ ì´ë©”ì¼ ì„±ëŠ¥:")
            print(f"     ì •í™•í•œ ë¶„ë¥˜ìœ¨: {ham_acc:.1%}")
            print(f"     í‰ê·  ì‹ ë¢°ë„: {avg_ham_conf:.3f}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ë³„ ì„±ëŠ¥ (ìƒ˜í”Œì´ ì ìœ¼ë¯€ë¡œ ê°œë³„ í‘œì‹œ)
        print(f"\n   ê°œë³„ ìƒ˜í”Œ ê²°ê³¼:")
        for result in self.analysis_results:
            correct = "âœ…" if (result['predicted_class'] == 1) == (result['true_label'] == 1) else "âŒ"
            print(f"     ìƒ˜í”Œ {result['sample_id']}: {correct} {result['image_filename'][:30]}... "
                  f"(ì‹ ë¢°ë„: {result['confidence']:.3f})")


if __name__ == "__main__":
    # ì‹¤ì œ ì´ë©”ì¼ attention ë¶„ì„ ì‹¤í–‰
    analyzer = RealEmailAttentionAnalysis()
    analyzer.run_comprehensive_real_email_analysis(num_samples=8) 