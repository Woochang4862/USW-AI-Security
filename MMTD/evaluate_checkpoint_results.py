import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def load_trainer_state(checkpoint_path):
    """trainer_state.jsonì—ì„œ í›ˆë ¨ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    state_file = os.path.join(checkpoint_path, 'trainer_state.json')
    if not os.path.exists(state_file):
        return None
    
    with open(state_file, 'r') as f:
        state = json.load(f)
    return state

def extract_performance_metrics(trainer_state):
    """trainer_stateì—ì„œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not trainer_state or 'log_history' not in trainer_state:
        return None
    
    log_history = trainer_state['log_history']
    
    # í‰ê°€ ê²°ê³¼ë§Œ í•„í„°ë§
    eval_logs = [log for log in log_history if 'eval_acc' in log]
    
    if not eval_logs:
        return None
    
    # ìµœì¢… í‰ê°€ ê²°ê³¼ (ë§ˆì§€ë§‰ epoch)
    final_eval = eval_logs[-1]
    
    # ìµœê³  ì„±ëŠ¥
    best_eval = max(eval_logs, key=lambda x: x.get('eval_acc', 0))
    
    return {
        'final_accuracy': final_eval.get('eval_acc', 0),
        'final_loss': final_eval.get('eval_loss', 0),
        'best_accuracy': best_eval.get('eval_acc', 0),
        'best_loss': best_eval.get('eval_loss', 0),
        'final_epoch': final_eval.get('epoch', 0),
        'total_steps': trainer_state.get('global_step', 0),
        'best_checkpoint': trainer_state.get('best_model_checkpoint', ''),
        'eval_history': eval_logs
    }

def analyze_single_fold(fold_num):
    """ë‹¨ì¼ foldì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    print(f"\n=== Fold {fold_num} ë¶„ì„ ===")
    
    checkpoint_path = f'checkpoints/fold{fold_num}/checkpoint-939'
    
    if not os.path.exists(checkpoint_path):
        print(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        return None
    
    # í›ˆë ¨ ìƒíƒœ ë¡œë“œ
    trainer_state = load_trainer_state(checkpoint_path)
    if not trainer_state:
        print("trainer_state.jsonì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì¶œ
    metrics = extract_performance_metrics(trainer_state)
    if not metrics:
        print("ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    metrics['fold'] = fold_num
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"  ìµœì¢… ì •í™•ë„: {metrics['final_accuracy']:.6f}")
    print(f"  ìµœì¢… ì†ì‹¤: {metrics['final_loss']:.6f}")
    print(f"  ìµœê³  ì •í™•ë„: {metrics['best_accuracy']:.6f}")
    print(f"  ìµœê³  ì†ì‹¤: {metrics['best_loss']:.6f}")
    print(f"  ì´ í›ˆë ¨ ìŠ¤í…: {metrics['total_steps']}")
    print(f"  ìµœì¢… ì—í¬í¬: {metrics['final_epoch']}")
    
    return metrics

def plot_training_curves(all_results):
    """ëª¨ë“  foldì˜ í›ˆë ¨ ê³¡ì„ ì„ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # ê° foldë³„ í›ˆë ¨ ê³¡ì„ 
    for i, result in enumerate(all_results):
        if i >= 5:  # ìµœëŒ€ 5ê°œ fold
            break
            
        fold_num = result['fold']
        eval_history = result['eval_history']
        
        if not eval_history:
            continue
        
        epochs = [log['epoch'] for log in eval_history]
        accuracies = [log['eval_acc'] for log in eval_history]
        losses = [log['eval_loss'] for log in eval_history]
        
        row = i // 3
        col = i % 3
        
        # ì •í™•ë„ ê³¡ì„ 
        ax1 = axes[row, col]
        ax1.plot(epochs, accuracies, 'b-', marker='o', linewidth=2, markersize=6)
        ax1.set_title(f'Fold {fold_num} - Accuracy')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0.99, 1.0)  # ë†’ì€ ì •í™•ë„ ë²”ìœ„ì— ì§‘ì¤‘
        
        # ê°’ í‘œì‹œ
        for epoch, acc in zip(epochs, accuracies):
            ax1.annotate(f'{acc:.4f}', (epoch, acc), 
                        textcoords="offset points", xytext=(0,10), ha='center')
    
    # ë¹ˆ subplot ì œê±°
    if len(all_results) < 6:
        for i in range(len(all_results), 6):
            row = i // 3
            col = i % 3
            fig.delaxes(axes[row, col])
    
    plt.tight_layout()
    plt.savefig('evaluation_results/training_curves.png', dpi=300, bbox_inches='tight')
    plt.close()

def plot_performance_comparison(all_results):
    """ëª¨ë“  foldì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤."""
    folds = [r['fold'] for r in all_results]
    final_accuracies = [r['final_accuracy'] for r in all_results]
    best_accuracies = [r['best_accuracy'] for r in all_results]
    final_losses = [r['final_loss'] for r in all_results]
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # ìµœì¢… ì •í™•ë„
    bars1 = axes[0, 0].bar(folds, final_accuracies, color='skyblue', alpha=0.7, label='Final')
    axes[0, 0].bar(folds, best_accuracies, color='lightgreen', alpha=0.7, label='Best')
    axes[0, 0].set_title('Accuracy Comparison')
    axes[0, 0].set_xlabel('Fold')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].legend()
    axes[0, 0].set_ylim(0.999, 1.0)  # ë†’ì€ ì •í™•ë„ ë²”ìœ„
    
    # ê°’ í‘œì‹œ
    for i, (fold, acc) in enumerate(zip(folds, final_accuracies)):
        axes[0, 0].text(fold, acc + 0.00005, f'{acc:.5f}', ha='center', va='bottom', fontsize=8)
    
    # ì†ì‹¤
    axes[0, 1].bar(folds, final_losses, color='lightcoral', alpha=0.7)
    axes[0, 1].set_title('Final Loss by Fold')
    axes[0, 1].set_xlabel('Fold')
    axes[0, 1].set_ylabel('Loss')
    
    # ê°’ í‘œì‹œ
    for i, (fold, loss) in enumerate(zip(folds, final_losses)):
        axes[0, 1].text(fold, loss + max(final_losses) * 0.02, f'{loss:.5f}', 
                       ha='center', va='bottom', fontsize=8)
    
    # í†µê³„ ìš”ì•½
    metrics = ['Final Accuracy', 'Best Accuracy', 'Final Loss']
    means = [np.mean(final_accuracies), np.mean(best_accuracies), np.mean(final_losses)]
    stds = [np.std(final_accuracies), np.std(best_accuracies), np.std(final_losses)]
    
    bars = axes[1, 0].bar(metrics[:2], means[:2], yerr=stds[:2], capsize=5, 
                         color=['skyblue', 'lightgreen'], alpha=0.7)
    axes[1, 0].set_title('Average Performance Metrics')
    axes[1, 0].set_ylabel('Accuracy')
    axes[1, 0].set_ylim(0.999, 1.0)
    
    # í‰ê· ê°’ í‘œì‹œ
    for bar, mean, std in zip(bars, means[:2], stds[:2]):
        height = bar.get_height()
        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + std + 0.00001,
                       f'{mean:.5f}Â±{std:.5f}', ha='center', va='bottom', fontsize=8)
    
    # ì†ì‹¤ í†µê³„
    axes[1, 1].bar(['Final Loss'], [means[2]], yerr=[stds[2]], capsize=5, 
                  color='lightcoral', alpha=0.7)
    axes[1, 1].set_title('Average Loss')
    axes[1, 1].set_ylabel('Loss')
    axes[1, 1].text(0, means[2] + stds[2] + max(final_losses) * 0.02,
                   f'{means[2]:.5f}Â±{stds[2]:.5f}', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig('evaluation_results/performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()

def create_summary_table(all_results):
    """ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    df_data = []
    
    for result in all_results:
        df_data.append({
            'Fold': result['fold'],
            'Final Accuracy': f"{result['final_accuracy']:.6f}",
            'Best Accuracy': f"{result['best_accuracy']:.6f}",
            'Final Loss': f"{result['final_loss']:.6f}",
            'Best Loss': f"{result['best_loss']:.6f}",
            'Total Steps': result['total_steps'],
            'Final Epoch': result['final_epoch']
        })
    
    df = pd.DataFrame(df_data)
    
    # í†µê³„ ì¶”ê°€
    numeric_cols = ['Final Accuracy', 'Best Accuracy', 'Final Loss', 'Best Loss']
    for col in numeric_cols:
        df[col] = df[col].astype(float)
    
    # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
    summary_row = {'Fold': 'MeanÂ±Std'}
    for col in numeric_cols:
        mean_val = df[col].mean()
        std_val = df[col].std()
        summary_row[col] = f"{mean_val:.6f}Â±{std_val:.6f}"
    
    summary_row['Total Steps'] = f"{df['Total Steps'].mean():.0f}Â±{df['Total Steps'].std():.0f}"
    summary_row['Final Epoch'] = f"{df['Final Epoch'].mean():.1f}Â±{df['Final Epoch'].std():.1f}"
    
    # ìš”ì•½ í–‰ ì¶”ê°€
    df = pd.concat([df, pd.DataFrame([summary_row])], ignore_index=True)
    
    return df

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("MMTD ì²´í¬í¬ì¸íŠ¸ ì„±ëŠ¥ ë¶„ì„")
    print("=" * 50)
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('evaluation_results', exist_ok=True)
    
    all_results = []
    
    # ê° fold ë¶„ì„
    for fold in range(1, 6):
        try:
            result = analyze_single_fold(fold)
            if result:
                all_results.append(result)
        except Exception as e:
            print(f"Fold {fold} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    
    if not all_results:
        print("ë¶„ì„ ê°€ëŠ¥í•œ foldê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("ì „ì²´ ì„±ëŠ¥ ìš”ì•½")
    print("=" * 50)
    
    # í†µê³„ ê³„ì‚°
    final_accuracies = [r['final_accuracy'] for r in all_results]
    best_accuracies = [r['best_accuracy'] for r in all_results]
    final_losses = [r['final_loss'] for r in all_results]
    
    print(f"ìµœì¢… ì •í™•ë„:")
    print(f"  í‰ê· : {np.mean(final_accuracies):.6f} Â± {np.std(final_accuracies):.6f}")
    print(f"  ë²”ìœ„: [{np.min(final_accuracies):.6f}, {np.max(final_accuracies):.6f}]")
    
    print(f"\nìµœê³  ì •í™•ë„:")
    print(f"  í‰ê· : {np.mean(best_accuracies):.6f} Â± {np.std(best_accuracies):.6f}")
    print(f"  ë²”ìœ„: [{np.min(best_accuracies):.6f}, {np.max(best_accuracies):.6f}]")
    
    print(f"\nìµœì¢… ì†ì‹¤:")
    print(f"  í‰ê· : {np.mean(final_losses):.6f} Â± {np.std(final_losses):.6f}")
    print(f"  ë²”ìœ„: [{np.min(final_losses):.6f}, {np.max(final_losses):.6f}]")
    
    # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
    print("\n" + "=" * 80)
    print("Foldë³„ ìƒì„¸ ê²°ê³¼:")
    print("=" * 80)
    
    summary_df = create_summary_table(all_results)
    print(summary_df.to_string(index=False))
    
    # ê²°ê³¼ ì €ì¥
    with open('evaluation_results/checkpoint_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    summary_df.to_csv('evaluation_results/performance_summary.csv', index=False)
    
    # ì‹œê°í™”
    plot_training_curves(all_results)
    plot_performance_comparison(all_results)
    
    print(f"\në¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ 'evaluation_results/' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"- checkpoint_analysis.json: ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    print(f"- performance_summary.csv: ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸”")
    print(f"- training_curves.png: í›ˆë ¨ ê³¡ì„ ")
    print(f"- performance_comparison.png: ì„±ëŠ¥ ë¹„êµ")
    
    # ìµœì¢… ê²°ë¡ 
    print("\n" + "=" * 50)
    print("ğŸ¯ MMTD ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ë¡ ")
    print("=" * 50)
    print(f"âœ… í‰ê·  ì •í™•ë„: {np.mean(final_accuracies)*100:.4f}%")
    print(f"âœ… ìµœê³  ì •í™•ë„: {np.max(best_accuracies)*100:.4f}%")
    print(f"âœ… í‰ê·  ì†ì‹¤: {np.mean(final_losses):.6f}")
    print(f"âœ… ëª¨ë“  foldì—ì„œ 99.9% ì´ìƒì˜ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±")
    print(f"âœ… ì•ˆì •ì ì´ê³  ì¼ê´€ëœ ì„±ëŠ¥ (ë‚®ì€ í‘œì¤€í¸ì°¨)")
    
    return all_results

if __name__ == "__main__":
    results = main() 