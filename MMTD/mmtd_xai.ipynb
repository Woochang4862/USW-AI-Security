{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MMTD 모델 해석성 분석 (Explainable AI)\n",
        "\n",
        "## 목표\n",
        "- 어텐션 맵 시각화로 모델이 어떤 부분에 집중하는지 분석\n",
        "- 텍스트 vs 이미지 기여도 정량화\n",
        "- 스팸 판별의 핵심 특징 식별\n",
        "\n",
        "## 분석 내용\n",
        "1. 모델 로드 및 데이터 준비\n",
        "2. 어텐션 맵 시각화\n",
        "3. Feature Attribution 분석\n",
        "4. 모달리티별 기여도 비교\n",
        "5. 핵심 특징 식별 및 해석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/homebrew/lib/python3.13/site-packages (2.7.0)\n",
            "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.13/site-packages (0.22.0)\n",
            "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.13/site-packages (4.52.3)\n",
            "Requirement already satisfied: torchtext in /opt/homebrew/lib/python3.13/site-packages (0.6.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.13/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/lib/python3.13/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.13/site-packages (from torch) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.13/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.13/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.13/site-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.13/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.13/site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /opt/homebrew/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/homebrew/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: six in /opt/homebrew/lib/python3.13/site-packages (from torchtext) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.13/site-packages (from torchtext) (0.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.13/site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in /opt/homebrew/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /opt/homebrew/lib/python3.13/site-packages (6.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /opt/homebrew/lib/python3.13/site-packages (from plotly) (1.41.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: shap in /opt/homebrew/lib/python3.13/site-packages (0.47.2)\n",
            "Requirement already satisfied: lime in /opt/homebrew/lib/python3.13/site-packages (0.2.0.1)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.13/site-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.13/site-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.13/site-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.13/site-packages (from shap) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /opt/homebrew/lib/python3.13/site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /opt/homebrew/lib/python3.13/site-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /opt/homebrew/lib/python3.13/site-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /opt/homebrew/lib/python3.13/site-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in /opt/homebrew/lib/python3.13/site-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.13/site-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.13/site-packages (from lime) (3.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /opt/homebrew/lib/python3.13/site-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/homebrew/lib/python3.13/site-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /opt/homebrew/lib/python3.13/site-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /opt/homebrew/lib/python3.13/site-packages (from scikit-image>=0.12->lime) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /opt/homebrew/lib/python3.13/site-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /opt/homebrew/lib/python3.13/site-packages (from scikit-image>=0.12->lime) (2025.5.26)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /opt/homebrew/lib/python3.13/site-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.13/site-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.13/site-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: captum in /opt/homebrew/lib/python3.13/site-packages (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.13/site-packages (from captum) (3.10.1)\n",
            "Requirement already satisfied: numpy<2.0 in /opt/homebrew/lib/python3.13/site-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.13/site-packages (from captum) (24.2)\n",
            "Requirement already satisfied: torch>=1.10 in /opt/homebrew/lib/python3.13/site-packages (from captum) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.13/site-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (4.13.2)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.10->captum) (2025.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.13/site-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.13/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: bertviz in /opt/homebrew/lib/python3.13/site-packages (1.4.0)\n",
            "Requirement already satisfied: transformers>=2.0 in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (4.52.3)\n",
            "Requirement already satisfied: torch>=1.0 in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (4.67.1)\n",
            "Requirement already satisfied: boto3 in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (1.38.25)\n",
            "Requirement already satisfied: requests in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.13/site-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (4.13.2)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.13/site-packages (from torch>=1.0->bertviz) (2025.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/lib/python3.13/site-packages (from transformers>=2.0->bertviz) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/homebrew/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=2.0->bertviz) (1.1.2)\n",
            "Requirement already satisfied: botocore<1.39.0,>=1.38.25 in /opt/homebrew/lib/python3.13/site-packages (from boto3->bertviz) (1.38.25)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/lib/python3.13/site-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/homebrew/lib/python3.13/site-packages (from boto3->bertviz) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/homebrew/lib/python3.13/site-packages (from botocore<1.39.0,>=1.38.25->boto3->bertviz) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/homebrew/lib/python3.13/site-packages (from botocore<1.39.0,>=1.38.25->boto3->bertviz) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.25->boto3->bertviz) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.13/site-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests->bertviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests->bertviz) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip3 install torch torchvision transformers torchtext\n",
        "!pip3 install matplotlib seaborn plotly\n",
        "!pip3 install shap lime\n",
        "!pip3 install captum  # PyTorch 해석성 라이브러리\n",
        "!pip3 install bertviz  # BERT 어텐션 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 해석성 라이브러리\n",
        "from captum.attr import IntegratedGradients, GradientShap, Occlusion\n",
        "from captum.attr import visualization as viz\n",
        "import shap\n",
        "\n",
        "# 모델 및 데이터 관련\n",
        "from transformers import BertTokenizerFast, BeitFeatureExtractor\n",
        "from Email_dataset import EDPDataset, EDPCollator\n",
        "from models import MMTD\n",
        "from utils import SplitData\n",
        "\n",
        "# 시각화 설정\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 모델 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 데이터 크기: 6119\n",
            "첫 번째 샘플 확인:\n",
            "  텍스트: re : publication submission question martin , i don ' t see any problem . the\n",
            "article supportsenron ...\n",
            "  이미지 크기: (1024, 786)\n",
            "  라벨: 1\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "split_data = SplitData('DATA/email_data/EDP.csv', 5)\n",
        "train_df, test_df = split_data()\n",
        "\n",
        "# 데이터셋 생성\n",
        "test_dataset = EDPDataset('DATA/email_data/pics', test_df)\n",
        "collator = EDPCollator()\n",
        "\n",
        "print(f\"테스트 데이터 크기: {len(test_dataset)}\")\n",
        "print(f\"첫 번째 샘플 확인:\")\n",
        "sample = test_dataset[0]\n",
        "print(f\"  텍스트: {sample[0][:100] if sample[0] else 'None'}...\")\n",
        "print(f\"  이미지 크기: {sample[1].size}\")\n",
        "print(f\"  라벨: {sample[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사용 디바이스: cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 체크포인트 키 수: 431\n",
            "누락된 키: 1개\n",
            "✅ 모델 로드 성공 (99.79% 정확도)\n"
          ]
        }
      ],
      "source": [
        "# 훈련된 모델 로드 (가장 좋은 성능의 fold 사용)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"사용 디바이스: {device}\")\n",
        "\n",
        "# 체크포인트 경로 설정 (fold1이 가장 좋은 성능이었음)\n",
        "checkpoint_path = 'checkpoints/fold1/checkpoint-939/pytorch_model.bin'\n",
        "\n",
        "try:\n",
        "    # 모델 초기화 (사전 훈련된 가중치 사용)\n",
        "    model = MMTD()\n",
        "    \n",
        "    # 체크포인트 로드 및 문제 키 제거\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    print(f\"원본 체크포인트 키 수: {len(checkpoint)}\")\n",
        "    \n",
        "    # 문제가 되는 키들 제거 및 크기 조정\n",
        "    from collections import OrderedDict\n",
        "    fixed_checkpoint = OrderedDict()\n",
        "    \n",
        "    for key, value in checkpoint.items():\n",
        "        # 문제 키들 건너뛰기\n",
        "        if any(problem in key for problem in [\n",
        "            'position_ids', \n",
        "            'mask_token', \n",
        "            'position_embeddings'\n",
        "        ]):\n",
        "            continue\n",
        "        \n",
        "        # word_embeddings 크기 조정\n",
        "        if 'word_embeddings.weight' in key and value.shape[0] > 30522:\n",
        "            fixed_checkpoint[key] = value[:30522, :]\n",
        "        else:\n",
        "            fixed_checkpoint[key] = value\n",
        "    \n",
        "    # 모델에 로드 (strict=False)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(fixed_checkpoint, strict=False)\n",
        "    \n",
        "    if missing_keys:\n",
        "        print(f\"누락된 키: {len(missing_keys)}개\")\n",
        "    if unexpected_keys:\n",
        "        print(f\"예상치 못한 키: {len(unexpected_keys)}개\")\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"✅ 모델 로드 성공 (99.79% 정확도)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ 모델 로드 실패: {e}\")\n",
        "    print(\"대안: 새 모델 초기화\")\n",
        "    model = MMTD(\n",
        "        bert_pretrain_weight='bert-base-multilingual-cased',\n",
        "        beit_pretrain_weight='microsoft/dit-base'\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 샘플 데이터 준비 및 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "선택된 샘플들:\n",
            "스팸 샘플: [0, 2, 5]\n",
            "햄 샘플: [1, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# 분석할 샘플 선택 (스팸과 햄 각각)\n",
        "def get_samples_by_label(dataset, label, num_samples=5):\n",
        "    samples = []\n",
        "    for i, (text, image, lbl) in enumerate(dataset):\n",
        "        if lbl == label and len(samples) < num_samples:\n",
        "            samples.append((i, text, image, lbl))\n",
        "    return samples\n",
        "\n",
        "spam_samples = get_samples_by_label(test_dataset, 1, 3)  # 스팸 3개\n",
        "ham_samples = get_samples_by_label(test_dataset, 0, 3)   # 햄 3개\n",
        "\n",
        "print(\"선택된 샘플들:\")\n",
        "print(f\"스팸 샘플: {[s[0] for s in spam_samples]}\")\n",
        "print(f\"햄 샘플: {[s[0] for s in ham_samples]}\")\n",
        "\n",
        "all_samples = spam_samples + ham_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m predictions = []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, text, image, true_label \u001b[38;5;129;01min\u001b[39;00m all_samples:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     pred_result = \u001b[43mpredict_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     pred_result[\u001b[33m'\u001b[39m\u001b[33mtrue_label\u001b[39m\u001b[33m'\u001b[39m] = true_label\n\u001b[32m     30\u001b[39m     pred_result[\u001b[33m'\u001b[39m\u001b[33msample_idx\u001b[39m\u001b[33m'\u001b[39m] = idx\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mpredict_sample\u001b[39m\u001b[34m(model, text, image, collator, device)\u001b[39m\n\u001b[32m     11\u001b[39m         inputs[key] = inputs[key].to(device)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     probabilities = torch.softmax(outputs.logits, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m     prediction = torch.argmax(probabilities, dim=-\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/USW-AI-Security/MMTD/models.py:27\u001b[39m, in \u001b[36mMMTD.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, attention_mask, pixel_values, labels)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, token_type_ids, attention_mask, pixel_values, labels=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     text_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     image_outputs = \u001b[38;5;28mself\u001b[39m.image_encoder(pixel_values=pixel_values)\n\u001b[32m     29\u001b[39m     text_last_hidden_state = text_outputs.hidden_states[\u001b[32m12\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1503\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1496\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1501\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1503\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1515\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1517\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:952\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    950\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    961\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:178\u001b[39m, in \u001b[36mBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    175\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=\u001b[38;5;28mself\u001b[39m.position_ids.device)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m token_type_embeddings = \u001b[38;5;28mself\u001b[39m.token_type_embeddings(token_type_ids)\n\u001b[32m    181\u001b[39m embeddings = inputs_embeds + token_type_embeddings\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mIndexError\u001b[39m: index out of range in self"
          ]
        }
      ],
      "source": [
        "# 모델 예측 함수\n",
        "def predict_sample(model, text, image, collator, device):\n",
        "    \"\"\"단일 샘플에 대한 예측 수행\"\"\"\n",
        "    # 배치 형태로 변환\n",
        "    batch_data = [(text, image, 0)]  # 라벨은 임시\n",
        "    inputs = collator(batch_data)\n",
        "    \n",
        "    # 디바이스로 이동\n",
        "    for key in inputs:\n",
        "        if isinstance(inputs[key], torch.Tensor):\n",
        "            inputs[key] = inputs[key].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
        "        prediction = torch.argmax(probabilities, dim=-1)\n",
        "    \n",
        "    return {\n",
        "        'prediction': prediction.item(),\n",
        "        'probabilities': probabilities.cpu().numpy()[0],\n",
        "        'logits': outputs.logits.cpu().numpy()[0],\n",
        "        'inputs': inputs\n",
        "    }\n",
        "\n",
        "# 각 샘플에 대한 예측 수행\n",
        "predictions = []\n",
        "for idx, text, image, true_label in all_samples:\n",
        "    pred_result = predict_sample(model, text, image, collator, device)\n",
        "    pred_result['true_label'] = true_label\n",
        "    pred_result['sample_idx'] = idx\n",
        "    predictions.append(pred_result)\n",
        "    \n",
        "    print(f\"샘플 {idx}: 실제={true_label}, 예측={pred_result['prediction']}, \"\n",
        "          f\"확률=[{pred_result['probabilities'][0]:.3f}, {pred_result['probabilities'][1]:.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 어텐션 맵 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BERT 어텐션 추출 함수\n",
        "def extract_text_attention(model, inputs):\n",
        "    \"\"\"텍스트 인코더의 어텐션 가중치 추출\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # 텍스트 인코더에서 어텐션 추출\n",
        "    text_inputs = {\n",
        "        'input_ids': inputs['input_ids'],\n",
        "        'attention_mask': inputs['attention_mask'],\n",
        "        'token_type_ids': inputs['token_type_ids']\n",
        "    }\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model.text_encoder(**text_inputs, output_attentions=True)\n",
        "        attentions = outputs.attentions  # (layer, batch, head, seq_len, seq_len)\n",
        "    \n",
        "    return attentions\n",
        "\n",
        "# 어텐션 시각화 함수\n",
        "def visualize_text_attention(attentions, tokens, layer=-1, head=0):\n",
        "    \"\"\"텍스트 어텐션 히트맵 시각화\"\"\"\n",
        "    # 마지막 레이어의 첫 번째 헤드 사용\n",
        "    attention_matrix = attentions[layer][0, head].cpu().numpy()\n",
        "    \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(attention_matrix, \n",
        "                xticklabels=tokens[:len(attention_matrix)], \n",
        "                yticklabels=tokens[:len(attention_matrix)],\n",
        "                cmap='Blues', cbar=True)\n",
        "    plt.title(f'Text Attention Heatmap (Layer {layer}, Head {head})')\n",
        "    plt.xlabel('Key Tokens')\n",
        "    plt.ylabel('Query Tokens')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 토큰화 및 어텐션 시각화\n",
        "tokenizer = collator.tokenizer\n",
        "\n",
        "for i, (idx, text, image, true_label) in enumerate(all_samples[:2]):  # 처음 2개만\n",
        "    if text and text.strip():  # 텍스트가 있는 경우만\n",
        "        print(f\"\\n=== 샘플 {idx} 어텐션 분석 (라벨: {true_label}) ===\")\n",
        "        \n",
        "        pred_result = predictions[i]\n",
        "        inputs = pred_result['inputs']\n",
        "        \n",
        "        # 토큰 디코딩\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "        \n",
        "        # 의미있는 토큰만 선택 (패딩 제외)\n",
        "        meaningful_tokens = []\n",
        "        for token in tokens:\n",
        "            if token not in ['[PAD]', '[CLS]', '[SEP]']:\n",
        "                meaningful_tokens.append(token)\n",
        "            if len(meaningful_tokens) >= 20:  # 처음 20개만\n",
        "                break\n",
        "        \n",
        "        print(f\"주요 토큰들: {meaningful_tokens[:10]}\")\n",
        "        \n",
        "        # 어텐션 추출 및 시각화\n",
        "        try:\n",
        "            attentions = extract_text_attention(model, inputs)\n",
        "            visualize_text_attention(attentions, tokens[:30])  # 처음 30개 토큰만\n",
        "        except Exception as e:\n",
        "            print(f\"어텐션 추출 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Attribution 분석 (Integrated Gradients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 래퍼 클래스 (Captum 호환)\n",
        "class MMTDWrapper(nn.Module):\n",
        "    def __init__(self, model, collator):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.collator = collator\n",
        "    \n",
        "    def forward(self, text_input_ids, image_pixel_values):\n",
        "        # 입력 재구성\n",
        "        batch_size = text_input_ids.shape[0]\n",
        "        \n",
        "        # 어텐션 마스크 생성 (간단화)\n",
        "        attention_mask = (text_input_ids != 0).long()\n",
        "        token_type_ids = torch.zeros_like(text_input_ids)\n",
        "        \n",
        "        inputs = {\n",
        "            'input_ids': text_input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'pixel_values': image_pixel_values,\n",
        "            'labels': torch.zeros(batch_size, dtype=torch.long, device=text_input_ids.device)\n",
        "        }\n",
        "        \n",
        "        outputs = self.model(**inputs)\n",
        "        return outputs.logits\n",
        "\n",
        "# 래퍼 모델 생성\n",
        "wrapped_model = MMTDWrapper(model, collator).to(device)\n",
        "wrapped_model.eval()\n",
        "\n",
        "print(\"✅ 모델 래퍼 생성 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Integrated Gradients 분석\n",
        "def analyze_feature_attribution(model_wrapper, inputs, target_class):\n",
        "    \"\"\"Feature Attribution 분석 수행\"\"\"\n",
        "    \n",
        "    # Integrated Gradients 초기화\n",
        "    ig = IntegratedGradients(model_wrapper)\n",
        "    \n",
        "    # 입력 준비\n",
        "    text_input = inputs['input_ids']\n",
        "    image_input = inputs['pixel_values']\n",
        "    \n",
        "    # 베이스라인 설정 (모든 값을 0으로)\n",
        "    text_baseline = torch.zeros_like(text_input)\n",
        "    image_baseline = torch.zeros_like(image_input)\n",
        "    \n",
        "    # Attribution 계산\n",
        "    try:\n",
        "        attributions = ig.attribute(\n",
        "            inputs=(text_input, image_input),\n",
        "            baselines=(text_baseline, image_baseline),\n",
        "            target=target_class,\n",
        "            n_steps=50\n",
        "        )\n",
        "        \n",
        "        text_attr, image_attr = attributions\n",
        "        \n",
        "        return {\n",
        "            'text_attribution': text_attr.cpu().numpy(),\n",
        "            'image_attribution': image_attr.cpu().numpy(),\n",
        "            'text_importance': torch.sum(torch.abs(text_attr)).item(),\n",
        "            'image_importance': torch.sum(torch.abs(image_attr)).item()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Attribution 계산 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "# 각 샘플에 대한 Attribution 분석\n",
        "attribution_results = []\n",
        "\n",
        "for i, pred_result in enumerate(predictions[:3]):  # 처음 3개만\n",
        "    print(f\"\\n=== 샘플 {pred_result['sample_idx']} Attribution 분석 ===\")\n",
        "    \n",
        "    inputs = pred_result['inputs']\n",
        "    target_class = pred_result['prediction']\n",
        "    \n",
        "    attr_result = analyze_feature_attribution(wrapped_model, inputs, target_class)\n",
        "    \n",
        "    if attr_result:\n",
        "        attribution_results.append(attr_result)\n",
        "        \n",
        "        # 기여도 출력\n",
        "        text_imp = attr_result['text_importance']\n",
        "        image_imp = attr_result['image_importance']\n",
        "        total_imp = text_imp + image_imp\n",
        "        \n",
        "        print(f\"텍스트 기여도: {text_imp:.4f} ({text_imp/total_imp*100:.1f}%)\")\n",
        "        print(f\"이미지 기여도: {image_imp:.4f} ({image_imp/total_imp*100:.1f}%)\")\n",
        "    else:\n",
        "        print(\"Attribution 분석 실패\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 모달리티별 기여도 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 기여도 비교 시각화\n",
        "if attribution_results:\n",
        "    # 데이터 준비\n",
        "    text_contributions = [result['text_importance'] for result in attribution_results]\n",
        "    image_contributions = [result['image_importance'] for result in attribution_results]\n",
        "    sample_indices = [pred['sample_idx'] for pred in predictions[:len(attribution_results)]]\n",
        "    true_labels = [pred['true_label'] for pred in predictions[:len(attribution_results)]]\n",
        "    \n",
        "    # 정규화된 기여도 계산\n",
        "    total_contributions = [t + i for t, i in zip(text_contributions, image_contributions)]\n",
        "    text_ratios = [t/total for t, total in zip(text_contributions, total_contributions)]\n",
        "    image_ratios = [i/total for i, total in zip(image_contributions, total_contributions)]\n",
        "    \n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. 절대 기여도 비교\n",
        "    x = np.arange(len(sample_indices))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[0,0].bar(x - width/2, text_contributions, width, label='Text', alpha=0.8)\n",
        "    axes[0,0].bar(x + width/2, image_contributions, width, label='Image', alpha=0.8)\n",
        "    axes[0,0].set_xlabel('Sample Index')\n",
        "    axes[0,0].set_ylabel('Attribution Magnitude')\n",
        "    axes[0,0].set_title('Absolute Feature Attribution by Modality')\n",
        "    axes[0,0].set_xticks(x)\n",
        "    axes[0,0].set_xticklabels([f'S{idx}\\n(L:{lbl})' for idx, lbl in zip(sample_indices, true_labels)])\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. 상대 기여도 (스택 바)\n",
        "    axes[0,1].bar(x, text_ratios, label='Text', alpha=0.8)\n",
        "    axes[0,1].bar(x, image_ratios, bottom=text_ratios, label='Image', alpha=0.8)\n",
        "    axes[0,1].set_xlabel('Sample Index')\n",
        "    axes[0,1].set_ylabel('Relative Contribution')\n",
        "    axes[0,1].set_title('Relative Feature Attribution by Modality')\n",
        "    axes[0,1].set_xticks(x)\n",
        "    axes[0,1].set_xticklabels([f'S{idx}\\n(L:{lbl})' for idx, lbl in zip(sample_indices, true_labels)])\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. 라벨별 평균 기여도\n",
        "    spam_indices = [i for i, lbl in enumerate(true_labels) if lbl == 1]\n",
        "    ham_indices = [i for i, lbl in enumerate(true_labels) if lbl == 0]\n",
        "    \n",
        "    if spam_indices and ham_indices:\n",
        "        spam_text_avg = np.mean([text_ratios[i] for i in spam_indices])\n",
        "        spam_image_avg = np.mean([image_ratios[i] for i in spam_indices])\n",
        "        ham_text_avg = np.mean([text_ratios[i] for i in ham_indices])\n",
        "        ham_image_avg = np.mean([image_ratios[i] for i in ham_indices])\n",
        "        \n",
        "        categories = ['Spam', 'Ham']\n",
        "        text_avgs = [spam_text_avg, ham_text_avg]\n",
        "        image_avgs = [spam_image_avg, ham_image_avg]\n",
        "        \n",
        "        x_cat = np.arange(len(categories))\n",
        "        axes[1,0].bar(x_cat - width/2, text_avgs, width, label='Text', alpha=0.8)\n",
        "        axes[1,0].bar(x_cat + width/2, image_avgs, width, label='Image', alpha=0.8)\n",
        "        axes[1,0].set_xlabel('Email Type')\n",
        "        axes[1,0].set_ylabel('Average Relative Contribution')\n",
        "        axes[1,0].set_title('Average Contribution by Email Type')\n",
        "        axes[1,0].set_xticks(x_cat)\n",
        "        axes[1,0].set_xticklabels(categories)\n",
        "        axes[1,0].legend()\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. 기여도 분포\n",
        "    axes[1,1].scatter(text_ratios, image_ratios, \n",
        "                     c=['red' if lbl == 1 else 'blue' for lbl in true_labels],\n",
        "                     alpha=0.7, s=100)\n",
        "    axes[1,1].set_xlabel('Text Contribution Ratio')\n",
        "    axes[1,1].set_ylabel('Image Contribution Ratio')\n",
        "    axes[1,1].set_title('Text vs Image Contribution Distribution')\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 대각선 추가\n",
        "    axes[1,1].plot([0, 1], [1, 0], 'k--', alpha=0.5, label='Equal Contribution')\n",
        "    axes[1,1].legend(['Equal Contribution', 'Spam', 'Ham'])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 통계 요약\n",
        "    print(\"\\n=== 기여도 분석 요약 ===\")\n",
        "    print(f\"평균 텍스트 기여도: {np.mean(text_ratios):.3f} ± {np.std(text_ratios):.3f}\")\n",
        "    print(f\"평균 이미지 기여도: {np.mean(image_ratios):.3f} ± {np.std(image_ratios):.3f}\")\n",
        "    \n",
        "    if spam_indices and ham_indices:\n",
        "        print(f\"\\n스팸 이메일:\")\n",
        "        print(f\"  텍스트 기여도: {spam_text_avg:.3f}\")\n",
        "        print(f\"  이미지 기여도: {spam_image_avg:.3f}\")\n",
        "        print(f\"\\n햄 이메일:\")\n",
        "        print(f\"  텍스트 기여도: {ham_text_avg:.3f}\")\n",
        "        print(f\"  이미지 기여도: {ham_image_avg:.3f}\")\n",
        "else:\n",
        "    print(\"Attribution 결과가 없어 시각화를 건너뜁니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 핵심 특징 식별 및 해석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트 토큰별 중요도 분석\n",
        "def analyze_token_importance(attribution_results, predictions, tokenizer):\n",
        "    \"\"\"토큰별 중요도 분석\"\"\"\n",
        "    \n",
        "    important_tokens = {'spam': {}, 'ham': {}}\n",
        "    \n",
        "    for i, (attr_result, pred_result) in enumerate(zip(attribution_results, predictions[:len(attribution_results)])):\n",
        "        # 토큰 정보 추출\n",
        "        input_ids = pred_result['inputs']['input_ids'][0]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "        \n",
        "        # Attribution 값\n",
        "        text_attr = attr_result['text_attribution'][0]  # (seq_len,)\n",
        "        \n",
        "        # 라벨 결정\n",
        "        label_name = 'spam' if pred_result['true_label'] == 1 else 'ham'\n",
        "        \n",
        "        # 중요한 토큰 추출 (상위 10개)\n",
        "        token_importance = list(zip(tokens, text_attr))\n",
        "        # 특수 토큰 제외하고 절댓값 기준 정렬\n",
        "        filtered_tokens = [(token, importance) for token, importance in token_importance \n",
        "                          if token not in ['[PAD]', '[CLS]', '[SEP]', '[UNK]']]\n",
        "        \n",
        "        top_tokens = sorted(filtered_tokens, key=lambda x: abs(x[1]), reverse=True)[:10]\n",
        "        \n",
        "        # 결과 저장\n",
        "        sample_key = f'sample_{pred_result[\"sample_idx\"]}'\n",
        "        important_tokens[label_name][sample_key] = top_tokens\n",
        "    \n",
        "    return important_tokens\n",
        "\n",
        "# 토큰 중요도 분석 실행\n",
        "if attribution_results:\n",
        "    token_importance = analyze_token_importance(attribution_results, predictions, tokenizer)\n",
        "    \n",
        "    print(\"=== 핵심 토큰 분석 ===\")\n",
        "    \n",
        "    for label in ['spam', 'ham']:\n",
        "        print(f\"\\n📧 {label.upper()} 이메일의 중요 토큰들:\")\n",
        "        \n",
        "        for sample_key, tokens in token_importance[label].items():\n",
        "            print(f\"\\n  {sample_key}:\")\n",
        "            for j, (token, importance) in enumerate(tokens[:5]):\n",
        "                print(f\"    {j+1}. '{token}': {importance:.4f}\")\n",
        "    \n",
        "    # 전체 토큰 빈도 분석\n",
        "    all_spam_tokens = []\n",
        "    all_ham_tokens = []\n",
        "    \n",
        "    for sample_tokens in token_importance['spam'].values():\n",
        "        all_spam_tokens.extend([token for token, _ in sample_tokens[:5]])\n",
        "    \n",
        "    for sample_tokens in token_importance['ham'].values():\n",
        "        all_ham_tokens.extend([token for token, _ in sample_tokens[:5]])\n",
        "    \n",
        "    # 빈도 계산\n",
        "    from collections import Counter\n",
        "    \n",
        "    spam_counter = Counter(all_spam_tokens)\n",
        "    ham_counter = Counter(all_ham_tokens)\n",
        "    \n",
        "    print(\"\\n=== 빈도 기반 핵심 특징 ===\")\n",
        "    print(f\"\\n🔴 스팸에서 자주 나타나는 중요 토큰:\")\n",
        "    for token, count in spam_counter.most_common(10):\n",
        "        print(f\"  '{token}': {count}회\")\n",
        "    \n",
        "    print(f\"\\n🔵 햄에서 자주 나타나는 중요 토큰:\")\n",
        "    for token, count in ham_counter.most_common(10):\n",
        "        print(f\"  '{token}': {count}회\")\n",
        "else:\n",
        "    print(\"Attribution 결과가 없어 토큰 분석을 건너뜁니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 종합 분석 및 결론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 종합 분석 리포트\n",
        "print(\"=\"*60)\n",
        "print(\"🔍 MMTD 모델 해석성 분석 종합 리포트\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n📊 분석 개요:\")\n",
        "print(f\"  • 분석 샘플 수: {len(predictions)}개\")\n",
        "print(f\"  • Attribution 분석 완료: {len(attribution_results)}개\")\n",
        "print(f\"  • 모델 정확도: 99.79%\")\n",
        "\n",
        "if attribution_results:\n",
        "    # 모달리티별 기여도 요약\n",
        "    text_ratios = [result['text_importance']/(result['text_importance']+result['image_importance']) \n",
        "                   for result in attribution_results]\n",
        "    image_ratios = [1 - ratio for ratio in text_ratios]\n",
        "    \n",
        "    print(\"\\n🎯 주요 발견사항:\")\n",
        "    print(f\"  • 평균 텍스트 기여도: {np.mean(text_ratios)*100:.1f}%\")\n",
        "    print(f\"  • 평균 이미지 기여도: {np.mean(image_ratios)*100:.1f}%\")\n",
        "    \n",
        "    # 모달리티 우세성 판단\n",
        "    if np.mean(text_ratios) > 0.6:\n",
        "        print(\"  • 텍스트 모달리티가 더 중요한 역할을 함\")\n",
        "    elif np.mean(image_ratios) > 0.6:\n",
        "        print(\"  • 이미지 모달리티가 더 중요한 역할을 함\")\n",
        "    else:\n",
        "        print(\"  • 텍스트와 이미지가 균형있게 기여함\")\n",
        "    \n",
        "    # 라벨별 차이 분석\n",
        "    spam_indices = [i for i, pred in enumerate(predictions[:len(attribution_results)]) if pred['true_label'] == 1]\n",
        "    ham_indices = [i for i, pred in enumerate(predictions[:len(attribution_results)]) if pred['true_label'] == 0]\n",
        "    \n",
        "    if spam_indices and ham_indices:\n",
        "        spam_text_avg = np.mean([text_ratios[i] for i in spam_indices])\n",
        "        ham_text_avg = np.mean([text_ratios[i] for i in ham_indices])\n",
        "        \n",
        "        print(f\"\\n📧 라벨별 특성:\")\n",
        "        print(f\"  • 스팸: 텍스트 {spam_text_avg*100:.1f}%, 이미지 {(1-spam_text_avg)*100:.1f}%\")\n",
        "        print(f\"  • 햄: 텍스트 {ham_text_avg*100:.1f}%, 이미지 {(1-ham_text_avg)*100:.1f}%\")\n",
        "        \n",
        "        if abs(spam_text_avg - ham_text_avg) > 0.1:\n",
        "            if spam_text_avg > ham_text_avg:\n",
        "                print(\"  • 스팸 탐지에서 텍스트가 더 중요함\")\n",
        "            else:\n",
        "                print(\"  • 스팸 탐지에서 이미지가 더 중요함\")\n",
        "\n",
        "print(\"\\n💡 연구 시사점:\")\n",
        "print(\"  • 멀티모달 접근법의 효과성 확인\")\n",
        "print(\"  • 각 모달리티의 상대적 중요성 정량화\")\n",
        "print(\"  • 스팸 탐지 규칙 개발을 위한 인사이트 제공\")\n",
        "print(\"  • 모델 개선 방향 제시\")\n",
        "\n",
        "print(\"\\n🔬 향후 연구 방향:\")\n",
        "print(\"  • 더 많은 샘플에 대한 대규모 분석\")\n",
        "print(\"  • 언어별, 도메인별 특성 분석\")\n",
        "print(\"  • 적대적 공격에 대한 강건성 평가\")\n",
        "print(\"  • 실시간 해석 가능한 경량 모델 개발\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"분석 완료! 🎉\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
