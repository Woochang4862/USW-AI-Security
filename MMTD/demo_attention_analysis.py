import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

class MMTDAttentionDemo:
    """
    MMTD Î™®Îç∏Ïùò Attention Í∏∞Î∞ò Ìï¥ÏÑùÏÑ± Ïó∞Íµ¨ Îç∞Î™®
    - Î™®Îç∏ Íµ¨Ï°∞ Î∂ÑÏÑù
    - Í∞úÎÖêÏ†Å Ïã§Ìóò ÏãúÎÆ¨Î†àÏù¥ÏÖò
    - Ïó∞Íµ¨ Î∞©Ìñ• Ï†úÏãú
    """
    
    def __init__(self):
        print("üéØ MMTD Attention Í∏∞Î∞ò Ìï¥ÏÑùÏÑ± Ïó∞Íµ¨ Îç∞Î™®")
        print("="*70)
        
    def analyze_model_structure(self):
        """MMTD Î™®Îç∏ Íµ¨Ï°∞Î•º Î∂ÑÏÑùÌï©ÎãàÎã§."""
        print("\nüìã MMTD Î™®Îç∏ Íµ¨Ï°∞ Î∂ÑÏÑù")
        print("-" * 50)
        
        # Î™®Îç∏ Ïª¥Ìè¨ÎÑåÌä∏ Î∂ÑÏÑù
        components = {
            "ÌÖçÏä§Ìä∏ Ïù∏ÏΩîÎçî": {
                "Î™®Îç∏": "BERT (bert-base-multilingual-cased)",
                "Ï∂úÎ†•": "768Ï∞®Ïõê hidden states (12 layers)",
                "ÌäπÏßï": "Îã§Íµ≠Ïñ¥ ÏßÄÏõê, 119,547 vocabulary size"
            },
            "Ïù¥ÎØ∏ÏßÄ Ïù∏ÏΩîÎçî": {
                "Î™®Îç∏": "BEiT (microsoft/dit-base)",
                "Ï∂úÎ†•": "768Ï∞®Ïõê hidden states (12 layers)",
                "ÌäπÏßï": "Vision Transformer Í∏∞Î∞ò"
            },
            "ÏúµÌï© Î†àÏù¥Ïñ¥": {
                "Î™®Îç∏": "Transformer Encoder Layer",
                "ÏûÖÎ†•": "ÌÖçÏä§Ìä∏ + Ïù¥ÎØ∏ÏßÄ hidden states Ïó∞Í≤∞",
                "Ï∂úÎ†•": "768Ï∞®Ïõê ÏúµÌï© ÌëúÌòÑ"
            },
            "Î∂ÑÎ•òÍ∏∞": {
                "Î™®Îç∏": "Linear Layer (768 ‚Üí 2)",
                "Ï∂úÎ†•": "Ïä§Ìå∏/ÌñÑ Î∂ÑÎ•ò ÌôïÎ•†"
            }
        }
        
        for component, details in components.items():
            print(f"\nüîß {component}:")
            for key, value in details.items():
                print(f"   {key}: {value}")
        
        print(f"\n‚úÖ Ï¥ù ÌååÎùºÎØ∏ÌÑ∞ Ïàò: ÏïΩ 340M (BERT: 177M + BEiT: 86M + ÏúµÌï©: 77M)")
        
    def simulate_attention_analysis(self):
        """Attention Î∂ÑÏÑù ÏãúÎÆ¨Î†àÏù¥ÏÖòÏùÑ ÏàòÌñâÌï©ÎãàÎã§."""
        print(f"\nüß™ Attention Í∏∞Î∞ò Ìï¥ÏÑùÏÑ± Î∂ÑÏÑù ÏãúÎÆ¨Î†àÏù¥ÏÖò")
        print("-" * 50)
        
        # ÏãúÎÆ¨Î†àÏù¥ÏÖò Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
        np.random.seed(42)
        n_samples = 10
        
        # Í∞ÄÏÉÅÏùò Î™®Îã¨Î¶¨Ìã∞Î≥Ñ Í∏∞Ïó¨ÎèÑ Îç∞Ïù¥ÌÑ∞
        text_contributions = np.random.beta(2, 3, n_samples)  # ÌÖçÏä§Ìä∏Í∞Ä Îçî Ï§ëÏöîÌïú Í≤ΩÌñ•
        image_contributions = np.random.beta(3, 2, n_samples)  # Ïù¥ÎØ∏ÏßÄÎèÑ Ï§ëÏöî
        
        # ÏúµÌï© Ìö®Í≥º (Î≥¥ÌÜµ Í∞úÎ≥Ñ Î™®Îã¨Î¶¨Ìã∞Î≥¥Îã§ Îçî Ï¢ãÏùå)
        fusion_boost = np.random.normal(0.1, 0.05, n_samples)
        fusion_results = np.minimum(text_contributions + image_contributions + fusion_boost, 1.0)
        
        # ÏÉÅÌò∏ÏûëÏö© Ìö®Í≥º
        interaction_effects = fusion_results - np.maximum(text_contributions, image_contributions)
        
        # Ïã§Ï†ú ÎùºÎ≤®Í≥º ÏòàÏ∏° (ÎÜíÏùÄ Ï†ïÌôïÎèÑ ÏãúÎÆ¨Î†àÏù¥ÏÖò)
        true_labels = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])  # 60% ÌñÑ, 40% Ïä§Ìå∏
        predictions = (fusion_results > 0.5).astype(int)
        
        # Í≤∞Í≥º Ï∂úÎ†•
        print(f"\nüìä ÏãúÎÆ¨Î†àÏù¥ÏÖò Í≤∞Í≥º ({n_samples}Í∞ú ÏÉòÌîå):")
        
        for i in range(n_samples):
            true_label = "üö® Ïä§Ìå∏" if true_labels[i] == 1 else "‚úÖ ÌñÑ"
            pred_label = "üö® Ïä§Ìå∏" if predictions[i] == 1 else "‚úÖ ÌñÑ"
            accuracy = "‚úÖ" if true_labels[i] == predictions[i] else "‚ùå"
            
            print(f"\n   ÏÉòÌîå {i+1}:")
            print(f"     Ïã§Ï†ú: {true_label} | ÏòàÏ∏°: {pred_label} {accuracy}")
            print(f"     üìù ÌÖçÏä§Ìä∏: {text_contributions[i]:.3f}")
            print(f"     üñºÔ∏è  Ïù¥ÎØ∏ÏßÄ: {image_contributions[i]:.3f}")
            print(f"     üîó ÏúµÌï©: {fusion_results[i]:.3f}")
            print(f"     ‚ö° ÏÉÅÌò∏ÏûëÏö©: {interaction_effects[i]:.3f}")
        
        # ÌÜµÍ≥Ñ ÏöîÏïΩ
        accuracy = np.mean(true_labels == predictions)
        avg_text = np.mean(text_contributions)
        avg_image = np.mean(image_contributions)
        avg_fusion = np.mean(fusion_results)
        avg_interaction = np.mean(interaction_effects)
        
        print(f"\nüìà ÌÜµÍ≥Ñ ÏöîÏïΩ:")
        print(f"   üéØ Ï†ïÌôïÎèÑ: {accuracy:.1%}")
        print(f"   üìù ÌèâÍ∑† ÌÖçÏä§Ìä∏ Í∏∞Ïó¨ÎèÑ: {avg_text:.3f}")
        print(f"   üñºÔ∏è  ÌèâÍ∑† Ïù¥ÎØ∏ÏßÄ Í∏∞Ïó¨ÎèÑ: {avg_image:.3f}")
        print(f"   üîó ÌèâÍ∑† ÏúµÌï© ÏÑ±Îä•: {avg_fusion:.3f}")
        print(f"   ‚ö° ÌèâÍ∑† ÏÉÅÌò∏ÏûëÏö© Ìö®Í≥º: {avg_interaction:.3f}")
        
        return {
            'text_contributions': text_contributions,
            'image_contributions': image_contributions,
            'fusion_results': fusion_results,
            'interaction_effects': interaction_effects,
            'true_labels': true_labels,
            'predictions': predictions
        }
    
    def create_demo_visualizations(self, results):
        """ÏãúÎÆ¨Î†àÏù¥ÏÖò Í≤∞Í≥ºÎ•º ÏãúÍ∞ÅÌôîÌï©ÎãàÎã§."""
        print(f"\nüé® Í≤∞Í≥º ÏãúÍ∞ÅÌôî ÏÉùÏÑ±...")
        
        try:
            # Ìè∞Ìä∏ ÏÑ§Ï†ï
            plt.rcParams['font.size'] = 10
            plt.rcParams['font.family'] = 'DejaVu Sans'
            
            # Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
            text_contrib = results['text_contributions']
            image_contrib = results['image_contributions']
            fusion_results = results['fusion_results']
            interactions = results['interaction_effects']
            true_labels = results['true_labels']
            predictions = results['predictions']
            
            # ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('MMTD Attention-based Interpretability Analysis (Demo)', 
                        fontsize=16, fontweight='bold')
            
            # 1. Î™®Îã¨Î¶¨Ìã∞Î≥Ñ Í∏∞Ïó¨ÎèÑ ÎπÑÍµê
            x = np.arange(len(text_contrib))
            width = 0.25
            
            axes[0,0].bar(x - width, text_contrib, width, label='Text', alpha=0.8, color='skyblue')
            axes[0,0].bar(x, image_contrib, width, label='Image', alpha=0.8, color='lightcoral')
            axes[0,0].bar(x + width, fusion_results, width, label='Fusion', alpha=0.8, color='gold')
            
            axes[0,0].set_xlabel('Sample Index')
            axes[0,0].set_ylabel('Contribution Score')
            axes[0,0].set_title('Modality Contribution Comparison')
            axes[0,0].legend()
            axes[0,0].set_xticks(x)
            
            # 2. ÏÉÅÌò∏ÏûëÏö© Ìö®Í≥º
            colors = ['red' if label == 1 else 'blue' for label in true_labels]
            bars = axes[0,1].bar(x, interactions, color=colors, alpha=0.7, edgecolor='black')
            axes[0,1].set_xlabel('Sample Index')
            axes[0,1].set_ylabel('Interaction Effect')
            axes[0,1].set_title('Multimodal Interaction Effect')
            axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.8)
            
            # ÏÉÅÌò∏ÏûëÏö© Í∞í ÌëúÏãú
            for i, (bar, value) in enumerate(zip(bars, interactions)):
                height = bar.get_height()
                axes[0,1].text(bar.get_x() + bar.get_width()/2., 
                              height + 0.01 if height >= 0 else height - 0.02,
                              f'{value:.2f}', ha='center', 
                              va='bottom' if height >= 0 else 'top', fontsize=8)
            
            # 3. ÌÖçÏä§Ìä∏ vs Ïù¥ÎØ∏ÏßÄ ÏÇ∞Ï†êÎèÑ
            spam_mask = true_labels == 1
            ham_mask = true_labels == 0
            
            if np.any(spam_mask):
                axes[0,2].scatter(text_contrib[spam_mask], image_contrib[spam_mask], 
                                c='red', label='Spam', alpha=0.8, s=100, edgecolors='darkred')
            if np.any(ham_mask):
                axes[0,2].scatter(text_contrib[ham_mask], image_contrib[ham_mask], 
                                c='blue', label='Ham', alpha=0.8, s=100, edgecolors='darkblue')
            
            axes[0,2].set_xlabel('Text Contribution')
            axes[0,2].set_ylabel('Image Contribution')
            axes[0,2].set_title('Text vs Image Contribution')
            axes[0,2].legend()
            axes[0,2].grid(True, alpha=0.3)
            
            # 4. Î™®Îã¨Î¶¨Ìã∞ ÏßÄÎ∞∞ÏÑ±
            text_dominant = np.sum(text_contrib > image_contrib)
            image_dominant = len(text_contrib) - text_dominant
            
            sizes = [text_dominant, image_dominant]
            labels = [f'Text Dominant ({text_dominant})', f'Image Dominant ({image_dominant})']
            colors_pie = ['lightblue', 'lightcoral']
            
            axes[1,0].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)
            axes[1,0].set_title('Modality Dominance')
            
            # 5. ÏòàÏ∏° Ï†ïÌôïÏÑ±
            correct = np.sum(true_labels == predictions)
            incorrect = len(true_labels) - correct
            
            accuracy_sizes = [correct, incorrect] if incorrect > 0 else [correct]
            accuracy_labels = [f'Correct ({correct})', f'Incorrect ({incorrect})'] if incorrect > 0 else [f'All Correct ({correct})']
            accuracy_colors = ['lightgreen', 'lightcoral'] if incorrect > 0 else ['lightgreen']
            
            axes[1,1].pie(accuracy_sizes, labels=accuracy_labels, autopct='%1.1f%%', 
                         colors=accuracy_colors, startangle=90)
            axes[1,1].set_title('Prediction Accuracy')
            
            # 6. ÏúµÌï© Ìö®Í≥º Î∂ÑÏÑù
            max_individual = np.maximum(text_contrib, image_contrib)
            
            axes[1,2].scatter(max_individual, fusion_results, c=colors, alpha=0.8, s=100)
            axes[1,2].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='No fusion benefit')
            axes[1,2].set_xlabel('Best Individual Modality')
            axes[1,2].set_ylabel('Fusion Result')
            axes[1,2].set_title('Fusion vs Best Individual Modality')
            axes[1,2].legend()
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('mmtd_attention_demo.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"‚úÖ ÏãúÍ∞ÅÌôî Ï†ÄÏû• ÏôÑÎ£å: mmtd_attention_demo.png")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ÏãúÍ∞ÅÌôî ÏÉùÏÑ± Ïã§Ìå®: {str(e)}")
    
    def propose_research_directions(self):
        """Ïó∞Íµ¨ Î∞©Ìñ•ÏùÑ Ï†úÏïàÌï©ÎãàÎã§."""
        print(f"\nüî¨ Ï†úÏïàÎêú Ïó∞Íµ¨ Î∞©Ìñ•")
        print("="*70)
        
        research_areas = {
            "1. Multi-Head Attention Î∂ÑÏÑù": [
                "‚Ä¢ BERTÏôÄ BEiTÏùò Í∞Å headÎ≥Ñ attention pattern Î∂ÑÏÑù",
                "‚Ä¢ Ïñ∏Ïñ¥Î≥Ñ, Ïù¥ÎØ∏ÏßÄ Ïú†ÌòïÎ≥Ñ attention Í∞ÄÏ§ëÏπò Ï∞®Ïù¥ Î∂ÑÏÑù",
                "‚Ä¢ Attention headÏùò Ïó≠Ìï† Î∂ÑÌôî Ïó∞Íµ¨"
            ],
            "2. Cross-Modal Attention Ïó∞Íµ¨": [
                "‚Ä¢ ÌÖçÏä§Ìä∏-Ïù¥ÎØ∏ÏßÄ Í∞Ñ ÏÉÅÌò∏ attention Îß§Ïª§ÎãàÏ¶ò Î∂ÑÏÑù",
                "‚Ä¢ ÏúµÌï© Î†àÏù¥Ïñ¥ÏóêÏÑúÏùò cross-modal interaction ÏãúÍ∞ÅÌôî",
                "‚Ä¢ Î™®Îã¨Î¶¨Ìã∞ Í∞Ñ Ï†ïÎ≥¥ Ï†ÑÎã¨ Í≤ΩÎ°ú Ï∂îÏ†Å"
            ],
            "3. Ïñ∏Ïñ¥Î≥Ñ Ìï¥ÏÑùÏÑ± Î∂ÑÏÑù": [
                "‚Ä¢ Îã§Íµ≠Ïñ¥ Ïä§Ìå∏ÏóêÏÑúÏùò Ïñ∏Ïñ¥Î≥Ñ attention pattern",
                "‚Ä¢ Ïñ∏Ïñ¥ ÌäπÌôî Ïä§Ìå∏ ÌÉêÏßÄ Ï†ÑÎûµ Î∂ÑÏÑù",
                "‚Ä¢ Ïñ∏Ïñ¥ Í∞Ñ Ï†ÑÏù¥ÌïôÏäµ Ìö®Í≥º Ï∏°Ï†ï"
            ],
            "4. Ïã§ÏãúÍ∞Ñ Ìï¥ÏÑùÏÑ± ÎèÑÍµ¨": [
                "‚Ä¢ Ïã§ÏãúÍ∞Ñ attention ÏãúÍ∞ÅÌôî ÎåÄÏãúÎ≥¥Îìú Í∞úÎ∞ú",
                "‚Ä¢ ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å Ìï¥ÏÑù Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Íµ¨Ï∂ï",
                "‚Ä¢ ÏùòÏÇ¨Í≤∞Ï†ï Í∑ºÍ±∞ ÏûêÎèô ÏÉùÏÑ± ÏãúÏä§ÌÖú"
            ],
            "5. ÏÑ±Îä• Ïú†ÏßÄ Ìï¥ÏÑùÏÑ± Ìñ•ÏÉÅ": [
                "‚Ä¢ Í∏∞Ï°¥ 99.7% Ï†ïÌôïÎèÑ Ïú†ÏßÄÌïòÎ©¥ÏÑú Ìï¥ÏÑùÏÑ± Í∞úÏÑ†",
                "‚Ä¢ Attention Í∏∞Î∞ò Î™®Îç∏ Í≤ΩÎüâÌôî Ïó∞Íµ¨",
                "‚Ä¢ Ìï¥ÏÑù Í∞ÄÎä•Ìïú ensemble Î∞©Î≤ïÎ°† Í∞úÎ∞ú"
            ]
        }
        
        for area, details in research_areas.items():
            print(f"\nüéØ {area}")
            for detail in details:
                print(f"   {detail}")
        
        print(f"\nüí° ÌïµÏã¨ Í∏∞Ïó¨Ï†ê:")
        print("   ‚Ä¢ Îã§Íµ≠Ïñ¥ Î©ÄÌã∞Î™®Îã¨ Ïä§Ìå∏ ÌÉêÏßÄÏóêÏÑúÏùò Ìï¥ÏÑùÏÑ± Ïó∞Íµ¨ (ÏÑ∏Í≥Ñ ÏµúÏ¥à)")
        print("   ‚Ä¢ Í≥†ÏÑ±Îä• Ïú†ÏßÄÌïòÎ©¥ÏÑú Ìï¥ÏÑù Í∞ÄÎä•Ìïú AI ÏãúÏä§ÌÖú Íµ¨Ï∂ï")
        print("   ‚Ä¢ Ïã§Î¨¥ÏóêÏÑú Î∞îÎ°ú ÌôúÏö© Í∞ÄÎä•Ìïú Ìï¥ÏÑùÏÑ± ÎèÑÍµ¨ Í∞úÎ∞ú")
        
    def run_complete_demo(self):
        """Ï†ÑÏ≤¥ Îç∞Î™®Î•º Ïã§ÌñâÌï©ÎãàÎã§."""
        print("\nüöÄ MMTD Attention Í∏∞Î∞ò Ìï¥ÏÑùÏÑ± Ïó∞Íµ¨ ÏôÑÏ†Ñ Îç∞Î™® ÏãúÏûë")
        
        # 1. Î™®Îç∏ Íµ¨Ï°∞ Î∂ÑÏÑù
        self.analyze_model_structure()
        
        # 2. ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïã§Ìñâ
        results = self.simulate_attention_analysis()
        
        # 3. ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
        self.create_demo_visualizations(results)
        
        # 4. Ïó∞Íµ¨ Î∞©Ìñ• Ï†úÏïà
        self.propose_research_directions()
        
        print(f"\n" + "="*70)
        print("üéâ MMTD Attention Í∏∞Î∞ò Ìï¥ÏÑùÏÑ± Ïó∞Íµ¨ Îç∞Î™® ÏôÑÎ£å!")
        print("="*70)
        
        print(f"\nüìù Ïã§Ìóò ÏöîÏïΩ:")
        print("   ‚úÖ Î™®Îç∏ Íµ¨Ï°∞ Î∂ÑÏÑù ÏôÑÎ£å")
        print("   ‚úÖ Attention Í∏∞Ïó¨ÎèÑ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏôÑÎ£å")
        print("   ‚úÖ Îã§Ï∞®Ïõê Í≤∞Í≥º ÏãúÍ∞ÅÌôî ÏôÑÎ£å")
        print("   ‚úÖ Ìñ•ÌõÑ Ïó∞Íµ¨ Î∞©Ìñ• Ï†úÏãú ÏôÑÎ£å")
        
        print(f"\nüéØ Îã§Ïùå Îã®Í≥Ñ:")
        print("   1. Ïã§Ï†ú Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏Î•º ÏÇ¨Ïö©Ìïú attention weights Ï∂îÏ∂ú")
        print("   2. Ïñ∏Ïñ¥Î≥Ñ/Ïù¥ÎØ∏ÏßÄÎ≥Ñ ÏÑ∏Î∂Ä Î∂ÑÏÑù")
        print("   3. ÎÖºÎ¨∏ ÏûëÏÑ± Î∞è ÌïôÌöå Î∞úÌëú")


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    demo = MMTDAttentionDemo()
    demo.run_complete_demo()


if __name__ == "__main__":
    main() 