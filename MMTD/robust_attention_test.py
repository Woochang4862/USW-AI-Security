import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from models import MMTD
from Email_dataset import EDPDataset, EDPCollator
from utils import SplitData
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

class RobustAttentionAnalyzer:
    """
    ëª¨ë“  í˜¸í™˜ì„± ë¬¸ì œë¥¼ í•´ê²°í•œ ê°•ë ¥í•œ Attention ë¶„ì„ê¸°
    """
    
    def __init__(self, checkpoint_path=None):
        self.checkpoint_path = checkpoint_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ Device: {self.device}")
        
        # ê¸°ë³¸ ëª¨ë¸ ì´ˆê¸°í™”
        self.initialize_model()
        
        # ë°ì´í„° ë¡œë“œ
        self.load_test_data()
        
    def initialize_model(self):
        """í˜¸í™˜ì„± ë¬¸ì œ ì—†ì´ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        try:
            # ê¸°ë³¸ ëª¨ë¸ ìƒì„± (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´)
            self.model = MMTD()
            print("âœ… ê¸°ë³¸ MMTD ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            
            # ì²´í¬í¬ì¸íŠ¸ê°€ ìˆë‹¤ë©´ ë¡œë“œ ì‹œë„
            if self.checkpoint_path and os.path.exists(os.path.join(self.checkpoint_path, 'pytorch_model.bin')):
                self.load_checkpoint()
            else:
                print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì—†ì´ ê¸°ë³¸ ì´ˆê¸°í™”ë¡œ ì§„í–‰")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            print("ğŸ”„ ìµœì†Œí•œì˜ ëª¨ë¸ë¡œ ì§„í–‰...")
            self.model = MMTD()
        
        self.model.to(self.device)
        self.model.eval()
        print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
        
    def load_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹œë„í•©ë‹ˆë‹¤."""
        checkpoint_file = os.path.join(self.checkpoint_path, 'pytorch_model.bin')
        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„: {checkpoint_file}")
        
        try:
            checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)
            missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
            
            loaded_params = len(checkpoint.keys()) - len(missing_keys)
            total_params = len(self.model.state_dict().keys())
            
            print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {loaded_params}/{total_params} íŒŒë¼ë¯¸í„°")
            
        except Exception as e:
            print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print("ğŸ”„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ì§„í–‰")
    
    def load_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")
        
        try:
            split_data = SplitData('DATA/email_data/EDP.csv', 5)
            train_df, test_df = split_data()
            
            # ì‘ì€ ìƒ˜í”Œë§Œ ì‚¬ìš©
            test_sample = test_df.head(10)
            
            self.test_dataset = EDPDataset('DATA/email_data/pics', test_sample)
            self.collator = EDPCollator()
            
            print(f"âœ… í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_sample)}")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            # ë”ë¯¸ ë°ì´í„°ë¡œ ì§„í–‰
            self.test_dataset = None
            self.collator = EDPCollator()
    
    def safe_forward_pass(self, batch):
        """ì•ˆì „í•œ forward passë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            # ê¸°ë³¸ forward pass
            with torch.no_grad():
                output = self.model(**batch)
                return output
        except Exception as e:
            print(f"  Forward pass ì˜¤ë¥˜: {str(e)}")
            return None
    
    def analyze_modality_contributions_basic(self, sample_idx):
        """ê¸°ë³¸ì ì¸ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        if self.test_dataset is None:
            return None
            
        try:
            sample = self.test_dataset[sample_idx]
            batch = self.collator([sample])
            
            # GPUë¡œ ì´ë™
            for key in batch:
                if isinstance(batch[key], torch.Tensor):
                    batch[key] = batch[key].to(self.device)
            
            # ì „ì²´ ì˜ˆì¸¡
            full_output = self.safe_forward_pass(batch)
            if full_output is None:
                return None
                
            full_probs = torch.softmax(full_output.logits, dim=-1)
            
            # í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡ (ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ ë…¸ì´ì¦ˆë¡œ ëŒ€ì²´)
            text_only_batch = batch.copy()
            text_only_batch['pixel_values'] = torch.randn_like(batch['pixel_values'])
            
            text_only_output = self.safe_forward_pass(text_only_batch)
            if text_only_output is not None:
                text_only_probs = torch.softmax(text_only_output.logits, dim=-1)
            else:
                text_only_probs = full_probs
            
            # ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡ (í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”© í† í°ìœ¼ë¡œ ëŒ€ì²´)
            image_only_batch = batch.copy()
            image_only_batch['input_ids'] = torch.zeros_like(batch['input_ids'])
            image_only_batch['attention_mask'] = torch.zeros_like(batch['attention_mask'])
            image_only_batch['token_type_ids'] = torch.zeros_like(batch['token_type_ids'])
            
            image_only_output = self.safe_forward_pass(image_only_batch)
            if image_only_output is not None:
                image_only_probs = torch.softmax(image_only_output.logits, dim=-1)
            else:
                image_only_probs = full_probs
            
            # ê²°ê³¼ ê³„ì‚°
            true_label = sample['labels']
            pred_class = torch.argmax(full_probs, dim=-1).item()
            confidence = full_probs[0][pred_class].item()
            
            # ìŠ¤íŒ¸ í™•ë¥ ë“¤
            text_spam_prob = text_only_probs[0][1].item()
            image_spam_prob = image_only_probs[0][1].item()
            full_spam_prob = full_probs[0][1].item()
            
            # ìƒí˜¸ì‘ìš© íš¨ê³¼ (ìœµí•©ì´ ê°œë³„ ëª¨ë‹¬ë¦¬í‹°ë³´ë‹¤ ì–¼ë§ˆë‚˜ ë” ì¢‹ì€ì§€)
            interaction = full_spam_prob - max(text_spam_prob, image_spam_prob)
            
            return {
                'sample_idx': sample_idx,
                'true_label': true_label,
                'predicted_class': pred_class,
                'confidence': confidence,
                'text_spam_prob': text_spam_prob,
                'image_spam_prob': image_spam_prob,
                'full_spam_prob': full_spam_prob,
                'interaction_effect': interaction,
                'dominant_modality': 'text' if text_spam_prob > image_spam_prob else 'image'
            }
            
        except Exception as e:
            print(f"  ìƒ˜í”Œ {sample_idx} ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def run_comprehensive_analysis(self):
        """í¬ê´„ì ì¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ¯ MMTD ëª¨ë¸ Attention ê¸°ë°˜ í•´ì„ì„± ì‹¤í—˜ (ê°•ë ¥í•œ ë²„ì „)")
        print("="*80)
        
        if self.test_dataset is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ì‹¤í—˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
            
        results = []
        
        # ìƒ˜í”Œë³„ ë¶„ì„
        total_samples = min(10, len(self.test_dataset))
        for i in range(total_samples):
            print(f"\nğŸ“Š ìƒ˜í”Œ {i+1}/{total_samples} ë¶„ì„:")
            
            result = self.analyze_modality_contributions_basic(i)
            if result is not None:
                results.append(result)
                
                # ê²°ê³¼ ì¶œë ¥
                true_emoji = "ğŸš¨" if result['true_label'] == 1 else "âœ…"
                pred_emoji = "ğŸš¨" if result['predicted_class'] == 1 else "âœ…"
                true_label_str = f"{true_emoji} {'ìŠ¤íŒ¸' if result['true_label'] == 1 else 'í–„'}"
                pred_label_str = f"{pred_emoji} {'ìŠ¤íŒ¸' if result['predicted_class'] == 1 else 'í–„'}"
                
                print(f"   ì‹¤ì œ: {true_label_str}")
                print(f"   ì˜ˆì¸¡: {pred_label_str} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {result['text_spam_prob']:.3f}")
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„: {result['image_spam_prob']:.3f}")
                print(f"   ğŸ”— ìœµí•© ê²°ê³¼: {result['full_spam_prob']:.3f}")
                print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {result['interaction_effect']:.3f}")
                print(f"   ğŸ† ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹°: {result['dominant_modality']}")
                
                # ì •í™•ì„± ì²´í¬
                is_correct = result['true_label'] == result['predicted_class']
                accuracy_icon = "âœ…" if is_correct else "âŒ"
                print(f"   {accuracy_icon} ì˜ˆì¸¡ ì •í™•ì„±: {'ë§ìŒ' if is_correct else 'í‹€ë¦¼'}")
            else:
                print("   âŒ ë¶„ì„ ì‹¤íŒ¨")
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        if results:
            self.summarize_analysis(results)
            self.create_visualizations(results)
        else:
            print("\nâŒ ë¶„ì„ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def summarize_analysis(self, results):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*80)
        print("ğŸ“ˆ ì¢…í•© ë¶„ì„ ê²°ê³¼")
        print("="*80)
        
        # ê¸°ë³¸ í†µê³„
        total_samples = len(results)
        correct_predictions = sum(1 for r in results if r['true_label'] == r['predicted_class'])
        accuracy = correct_predictions / total_samples
        
        print(f"ğŸ¯ ì „ì²´ ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.1%} ({correct_predictions}/{total_samples})")
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ í†µê³„
        avg_text = np.mean([r['text_spam_prob'] for r in results])
        avg_image = np.mean([r['image_spam_prob'] for r in results])
        avg_fusion = np.mean([r['full_spam_prob'] for r in results])
        avg_interaction = np.mean([r['interaction_effect'] for r in results])
        
        print(f"\nğŸ“Š ëª¨ë‹¬ë¦¬í‹°ë³„ í‰ê·  ê¸°ì—¬ë„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸: {avg_text:.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {avg_image:.3f}")
        print(f"   ğŸ”— ìœµí•©: {avg_fusion:.3f}")
        print(f"   âš¡ ìƒí˜¸ì‘ìš©: {avg_interaction:.3f}")
        
        # ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹° ë¶„ì„
        text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
        image_dominant = sum(1 for r in results if r['dominant_modality'] == 'image')
        
        print(f"\nğŸ† ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„±:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì§€ë°°: {text_dominant}/{total_samples} ({text_dominant/total_samples:.1%})")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì§€ë°°: {image_dominant}/{total_samples} ({image_dominant/total_samples:.1%})")
        
        # í´ë˜ìŠ¤ë³„ ë¶„ì„
        spam_results = [r for r in results if r['true_label'] == 1]
        ham_results = [r for r in results if r['true_label'] == 0]
        
        if spam_results:
            spam_accuracy = sum(1 for r in spam_results if r['predicted_class'] == 1) / len(spam_results)
            print(f"\nğŸš¨ ìŠ¤íŒ¸ ë©”ì¼ ë¶„ì„ ({len(spam_results)}ê°œ):")
            print(f"   ì •í™•ë„: {spam_accuracy:.1%}")
            print(f"   í‰ê·  ìœµí•© í™•ë¥ : {np.mean([r['full_spam_prob'] for r in spam_results]):.3f}")
        
        if ham_results:
            ham_accuracy = sum(1 for r in ham_results if r['predicted_class'] == 0) / len(ham_results)
            print(f"\nâœ… ì •ìƒ ë©”ì¼ ë¶„ì„ ({len(ham_results)}ê°œ):")
            print(f"   ì •í™•ë„: {ham_accuracy:.1%}")
            print(f"   í‰ê·  ìœµí•© í™•ë¥ : {np.mean([r['full_spam_prob'] for r in ham_results]):.3f}")
    
    def create_visualizations(self, results):
        """ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        if len(results) == 0:
            print("âš ï¸ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        try:
            # í°íŠ¸ ì„¤ì •
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['font.size'] = 10
            
            # ë°ì´í„° ì¤€ë¹„
            indices = list(range(len(results)))
            text_probs = [r['text_spam_prob'] for r in results]
            image_probs = [r['image_spam_prob'] for r in results]
            fusion_probs = [r['full_spam_prob'] for r in results]
            interactions = [r['interaction_effect'] for r in results]
            
            # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
            colors = ['red' if r['true_label'] == 1 else 'blue' for r in results]
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('MMTD Attention-based Interpretability Analysis', fontsize=16, fontweight='bold')
            
            # 1. ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¹„êµ
            width = 0.25
            x = np.arange(len(results))
            
            axes[0,0].bar(x - width, text_probs, width, label='Text', alpha=0.8, color='skyblue')
            axes[0,0].bar(x, image_probs, width, label='Image', alpha=0.8, color='lightcoral')
            axes[0,0].bar(x + width, fusion_probs, width, label='Fusion', alpha=0.8, color='gold')
            
            axes[0,0].set_xlabel('Sample Index')
            axes[0,0].set_ylabel('Spam Probability')
            axes[0,0].set_title('Modality Contribution Comparison')
            axes[0,0].legend()
            axes[0,0].set_xticks(x)
            
            # 2. ìƒí˜¸ì‘ìš© íš¨ê³¼
            bars = axes[0,1].bar(indices, interactions, color=colors, alpha=0.7, edgecolor='black')
            axes[0,1].set_xlabel('Sample Index')
            axes[0,1].set_ylabel('Interaction Effect')
            axes[0,1].set_title('Multimodal Interaction Effect')
            axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.8)
            
            # 3. í…ìŠ¤íŠ¸ vs ì´ë¯¸ì§€ ì‚°ì ë„
            spam_mask = [r['true_label'] == 1 for r in results]
            ham_mask = [r['true_label'] == 0 for r in results]
            
            if any(spam_mask):
                spam_text = [text_probs[i] for i in range(len(results)) if spam_mask[i]]
                spam_image = [image_probs[i] for i in range(len(results)) if spam_mask[i]]
                axes[0,2].scatter(spam_text, spam_image, c='red', label='Spam', alpha=0.8, s=100)
            
            if any(ham_mask):
                ham_text = [text_probs[i] for i in range(len(results)) if ham_mask[i]]
                ham_image = [image_probs[i] for i in range(len(results)) if ham_mask[i]]
                axes[0,2].scatter(ham_text, ham_image, c='blue', label='Ham', alpha=0.8, s=100)
            
            axes[0,2].set_xlabel('Text Spam Probability')
            axes[0,2].set_ylabel('Image Spam Probability')
            axes[0,2].set_title('Text vs Image Contribution')
            axes[0,2].legend()
            axes[0,2].grid(True, alpha=0.3)
            
            # 4. ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„± íŒŒì´ì°¨íŠ¸
            text_dominant_count = sum(1 for r in results if r['dominant_modality'] == 'text')
            image_dominant_count = len(results) - text_dominant_count
            
            sizes = [text_dominant_count, image_dominant_count]
            labels = [f'Text Dominant ({text_dominant_count})', f'Image Dominant ({image_dominant_count})']
            colors_pie = ['lightblue', 'lightcoral']
            
            axes[1,0].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)
            axes[1,0].set_title('Modality Dominance')
            
            # 5. ì˜ˆì¸¡ ì •í™•ì„±
            correct_count = sum(1 for r in results if r['true_label'] == r['predicted_class'])
            incorrect_count = len(results) - correct_count
            
            accuracy_sizes = [correct_count, incorrect_count] if incorrect_count > 0 else [correct_count]
            accuracy_labels = [f'Correct ({correct_count})', f'Incorrect ({incorrect_count})'] if incorrect_count > 0 else [f'All Correct ({correct_count})']
            accuracy_colors = ['lightgreen', 'lightcoral'] if incorrect_count > 0 else ['lightgreen']
            
            axes[1,1].pie(accuracy_sizes, labels=accuracy_labels, autopct='%1.1f%%', 
                         colors=accuracy_colors, startangle=90)
            axes[1,1].set_title('Prediction Accuracy')
            
            # 6. ìœµí•© íš¨ê³¼ vs ìµœëŒ€ ê°œë³„ ëª¨ë‹¬ë¦¬í‹°
            max_individual = [max(text_probs[i], image_probs[i]) for i in range(len(results))]
            
            axes[1,2].scatter(max_individual, fusion_probs, c=colors, alpha=0.8, s=100)
            axes[1,2].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='No fusion benefit')
            axes[1,2].set_xlabel('Max Individual Modality')
            axes[1,2].set_ylabel('Fusion Result')
            axes[1,2].set_title('Fusion vs Best Individual Modality')
            axes[1,2].legend()
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('mmtd_robust_attention_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"\nğŸ¨ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: mmtd_robust_attention_analysis.png")
            
        except Exception as e:
            print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ MMTD ê°•ë ¥í•œ Attention í•´ì„ì„± ì‹¤í—˜ ì‹œì‘")
    
    checkpoint_path = "checkpoints/fold1/checkpoint-939"
    
    # ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ì–´ë„ ì§„í–‰
    if not os.path.exists(checkpoint_path):
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: {checkpoint_path}")
        print("ğŸ“ ê¸°ë³¸ ì´ˆê¸°í™”ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        checkpoint_path = None
    
    try:
        analyzer = RobustAttentionAnalyzer(checkpoint_path)
        analyzer.run_comprehensive_analysis()
        
        print(f"\n" + "="*80)
        print("ğŸ‰ ì‹¤í—˜ ì™„ë£Œ! ì´ ì‹¤í—˜ìœ¼ë¡œ MMTD ëª¨ë¸ì˜ í•´ì„ì„±ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")
        print("="*80)
        
    except Exception as e:
        print(f"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 