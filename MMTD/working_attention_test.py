import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from models import MMTD
from Email_dataset import EDPDataset, EDPCollator
from utils import SplitData
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

class WorkingAttentionAnalyzer:
    """
    PyTorch ë²„ì „ ë¬¸ì œë¥¼ ìš°íšŒí•˜ì—¬ ì²´í¬í¬ì¸íŠ¸ë§Œ ë¡œë“œí•˜ëŠ” Attention ë¶„ì„ê¸°
    """
    
    def __init__(self, checkpoint_path):
        self.checkpoint_path = checkpoint_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {self.device}")
        
        # ì²´í¬í¬ì¸íŠ¸ë§Œ ë¡œë“œ (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´)
        self.load_model_from_checkpoint()
        
        # ë°ì´í„° ë¡œë“œ
        self.load_test_data()
        
    def load_model_from_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì§ì ‘ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # ë¹ˆ ëª¨ë¸ ì´ˆê¸°í™” (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´)
        self.model = MMTD()
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint_path = os.path.join(self.checkpoint_path, 'pytorch_model.bin')
        print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {checkpoint_path}")
        
        if os.path.exists(checkpoint_path):
            try:
                # weights_only=Falseë¡œ ì„¤ì •í•˜ì—¬ í˜¸í™˜ì„± ë¬¸ì œ ìš°íšŒ
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„
                missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
                
                loaded_keys = len(checkpoint.keys()) - len(missing_keys)
                total_keys = len(self.model.state_dict().keys())
                
                print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ!")
                print(f"ë¡œë”©ëœ íŒŒë¼ë¯¸í„°: {loaded_keys}/{total_keys}")
                print(f"Missing keys: {len(missing_keys)}")
                print(f"Unexpected keys: {len(unexpected_keys)}")
                
                if missing_keys and len(missing_keys) > 0:
                    print("ì£¼ìš” Missing keys:", missing_keys[:3])
                    
                self.model.to(self.device)
                self.model.eval()
                
            except Exception as e:
                print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                print("ê¸°ë³¸ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                self.model.to(self.device)
                self.model.eval()
        else:
            print(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
            self.model.to(self.device)
            self.model.eval()
        
    def load_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")
        split_data = SplitData('DATA/email_data/EDP.csv', 5)
        
        # ì²« ë²ˆì§¸ fold ì‚¬ìš©
        train_df, test_df = split_data()
        
        # ìŠ¤íŒ¸ê³¼ í–„ ìƒ˜í”Œì„ ê°ê° ì„ íƒ
        spam_samples = test_df[test_df['labels'] == 1].head(5)
        ham_samples = test_df[test_df['labels'] == 0].head(5)
        
        if len(spam_samples) == 0:
            print("ìŠ¤íŒ¸ ìƒ˜í”Œì´ ì—†ì–´ì„œ ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì‚¬ìš©")
            test_sample = test_df.head(10)
        elif len(ham_samples) == 0:
            print("í–„ ìƒ˜í”Œì´ ì—†ì–´ì„œ ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì‚¬ìš©")
            test_sample = test_df.head(10)
        else:
            test_sample = pd.concat([spam_samples, ham_samples])
        
        self.test_dataset = EDPDataset('DATA/email_data/pics', test_sample)
        self.collator = EDPCollator()
        
        print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_sample)}")
        print(f"ìŠ¤íŒ¸ ìƒ˜í”Œ: {len(spam_samples)}, í–„ ìƒ˜í”Œ: {len(ham_samples)}")
        
    def analyze_sample(self, sample_idx):
        """ê°œë³„ ìƒ˜í”Œì˜ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        sample = self.test_dataset[sample_idx]
        batch = self.collator([sample])
        
        # GPUë¡œ ì´ë™
        for key in batch:
            if isinstance(batch[key], torch.Tensor):
                batch[key] = batch[key].to(self.device)
        
        with torch.no_grad():
            try:
                # 1. ì „ì²´ ë©€í‹°ëª¨ë‹¬ ì˜ˆì¸¡
                full_output = self.model(**batch)
                full_probs = torch.softmax(full_output.logits, dim=-1)
                
                # 2. ê°œë³„ ì¸ì½”ë” ì¶œë ¥ (hidden states ìˆëŠ” ê²½ìš°ì—ë§Œ)
                text_outputs = self.model.text_encoder(
                    input_ids=batch['input_ids'],
                    token_type_ids=batch['token_type_ids'],
                    attention_mask=batch['attention_mask']
                )
                
                image_outputs = self.model.image_encoder(
                    pixel_values=batch['pixel_values']
                )
                
                # hidden_statesê°€ ìˆëŠ”ì§€ í™•ì¸
                if hasattr(text_outputs, 'hidden_states') and text_outputs.hidden_states is not None:
                    text_hidden = text_outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´
                else:
                    print("  í…ìŠ¤íŠ¸ hidden states ì—†ìŒ")
                    return None
                    
                if hasattr(image_outputs, 'hidden_states') and image_outputs.hidden_states is not None:
                    image_hidden = image_outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´
                else:
                    print("  ì´ë¯¸ì§€ hidden states ì—†ìŒ")
                    return None
                
                # 3. ëª¨ë‹¬ë¦¬í‹° ì„ë² ë”© ì¶”ê°€
                text_hidden_mod = text_hidden + torch.zeros(text_hidden.size()).to(self.device)
                image_hidden_mod = image_hidden + torch.ones(image_hidden.size()).to(self.device)
                
                # 4. í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡
                text_only_fused = torch.cat([text_hidden_mod, torch.zeros_like(image_hidden_mod)], dim=1)
                text_only_output = self.model.multi_modality_transformer_layer(text_only_fused)
                text_only_pooled = self.model.pooler(text_only_output[:, 0, :])
                text_only_logits = self.model.classifier(text_only_pooled)
                text_only_probs = torch.softmax(text_only_logits, dim=-1)
                
                # 5. ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•œ ì˜ˆì¸¡
                image_only_fused = torch.cat([torch.zeros_like(text_hidden_mod), image_hidden_mod], dim=1)
                image_only_output = self.model.multi_modality_transformer_layer(image_only_fused)
                image_only_pooled = self.model.pooler(image_only_output[:, 0, :])
                image_only_logits = self.model.classifier(image_only_pooled)
                image_only_probs = torch.softmax(image_only_logits, dim=-1)
                
                # 6. ê²°ê³¼ ê³„ì‚°
                true_label = sample['labels']
                pred_class = torch.argmax(full_probs, dim=-1).item()
                confidence = full_probs[0][pred_class].item()
                
                # ìŠ¤íŒ¸ í™•ë¥ ë“¤
                text_spam_prob = text_only_probs[0][1].item()
                image_spam_prob = image_only_probs[0][1].item()
                full_spam_prob = full_probs[0][1].item()
                
                # ìƒí˜¸ì‘ìš© íš¨ê³¼
                interaction = full_spam_prob - (text_spam_prob + image_spam_prob) / 2
                
                return {
                    'sample_idx': sample_idx,
                    'true_label': true_label,
                    'predicted_class': pred_class,
                    'confidence': confidence,
                    'text_spam_prob': text_spam_prob,
                    'image_spam_prob': image_spam_prob,
                    'full_spam_prob': full_spam_prob,
                    'interaction_effect': interaction
                }
                
            except Exception as e:
                print(f"  ìƒ˜í”Œ {sample_idx} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None
    
    def run_comprehensive_analysis(self):
        """í¬ê´„ì ì¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*70)
        print("MMTD ëª¨ë¸ Attention ê¸°ë°˜ í•´ì„ì„± ì‹¤í—˜")
        print("="*70)
        
        results = []
        
        # ìƒ˜í”Œë³„ ë¶„ì„
        for i in range(min(10, len(self.test_dataset))):
            print(f"\nğŸ“Š ìƒ˜í”Œ {i+1} ë¶„ì„:")
            
            result = self.analyze_sample(i)
            if result is not None:
                results.append(result)
                
                # ê²°ê³¼ ì¶œë ¥
                true_label_str = "ğŸš¨ ìŠ¤íŒ¸" if result['true_label'] == 1 else "âœ… í–„"
                pred_label_str = "ğŸš¨ ìŠ¤íŒ¸" if result['predicted_class'] == 1 else "âœ… í–„"
                
                print(f"   ì‹¤ì œ: {true_label_str}")
                print(f"   ì˜ˆì¸¡: {pred_label_str} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ë§Œ ìŠ¤íŒ¸ í™•ë¥ : {result['text_spam_prob']:.3f}")
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ë§Œ ìŠ¤íŒ¸ í™•ë¥ : {result['image_spam_prob']:.3f}")
                print(f"   ğŸ”— ì „ì²´(ìœµí•©) ìŠ¤íŒ¸ í™•ë¥ : {result['full_spam_prob']:.3f}")
                print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {result['interaction_effect']:.3f}")
                
                # ì •í™•ì„± ì²´í¬
                is_correct = result['true_label'] == result['predicted_class']
                print(f"   âœ… ì˜ˆì¸¡ ì •í™•ì„±: {'ë§ìŒ' if is_correct else 'í‹€ë¦¼'}")
            else:
                print("   âŒ ë¶„ì„ ì‹¤íŒ¨")
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        if results:
            self.summarize_results(results)
            self.visualize_results(results)
        else:
            print("\nâŒ ë¶„ì„ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def summarize_results(self, results):
        """ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*70)
        print("ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*70)
        
        # ì •í™•ë„ ê³„ì‚°
        correct_predictions = sum(1 for r in results if r['true_label'] == r['predicted_class'])
        accuracy = correct_predictions / len(results)
        print(f"ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.1%} ({correct_predictions}/{len(results)})")
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ í‰ê·  ê¸°ì—¬ë„
        avg_text = np.mean([r['text_spam_prob'] for r in results])
        avg_image = np.mean([r['image_spam_prob'] for r in results])
        avg_full = np.mean([r['full_spam_prob'] for r in results])
        avg_interaction = np.mean([r['interaction_effect'] for r in results])
        
        print(f"\nğŸ“Š ëª¨ë‹¬ë¦¬í‹°ë³„ í‰ê·  ìŠ¤íŒ¸ í™•ë¥ :")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸: {avg_text:.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {avg_image:.3f}")
        print(f"   ğŸ”— ì „ì²´(ìœµí•©): {avg_full:.3f}")
        print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {avg_interaction:.3f}")
        
        # ìŠ¤íŒ¸ê³¼ í–„ ë³„ ë¶„ì„
        spam_results = [r for r in results if r['true_label'] == 1]
        ham_results = [r for r in results if r['true_label'] == 0]
        
        if spam_results:
            spam_text_avg = np.mean([r['text_spam_prob'] for r in spam_results])
            spam_image_avg = np.mean([r['image_spam_prob'] for r in spam_results])
            spam_interaction_avg = np.mean([r['interaction_effect'] for r in spam_results])
            
            print(f"\nğŸš¨ ìŠ¤íŒ¸ ë©”ì¼ ë¶„ì„ ({len(spam_results)}ê°œ):")
            print(f"   í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {spam_text_avg:.3f}")
            print(f"   ì´ë¯¸ì§€ ê¸°ì—¬ë„: {spam_image_avg:.3f}")
            print(f"   ìƒí˜¸ì‘ìš© íš¨ê³¼: {spam_interaction_avg:.3f}")
        
        if ham_results:
            ham_text_avg = np.mean([r['text_spam_prob'] for r in ham_results])
            ham_image_avg = np.mean([r['image_spam_prob'] for r in ham_results])
            ham_interaction_avg = np.mean([r['interaction_effect'] for r in ham_results])
            
            print(f"\nâœ… ì •ìƒ ë©”ì¼ ë¶„ì„ ({len(ham_results)}ê°œ):")
            print(f"   í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {ham_text_avg:.3f}")
            print(f"   ì´ë¯¸ì§€ ê¸°ì—¬ë„: {ham_image_avg:.3f}")
            print(f"   ìƒí˜¸ì‘ìš© íš¨ê³¼: {ham_interaction_avg:.3f}")
    
    def visualize_results(self, results):
        """ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        if len(results) == 0:
            return
            
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'DejaVu Sans'
        
        # ë°ì´í„° ì¤€ë¹„
        text_probs = [r['text_spam_prob'] for r in results]
        image_probs = [r['image_spam_prob'] for r in results]
        full_probs = [r['full_spam_prob'] for r in results]
        interactions = [r['interaction_effect'] for r in results]
        
        # ìŠ¤íŒ¸/í–„ êµ¬ë¶„
        spam_indices = [i for i, r in enumerate(results) if r['true_label'] == 1]
        ham_indices = [i for i, r in enumerate(results) if r['true_label'] == 0]
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ì‚°ì ë„
        if spam_indices:
            axes[0,0].scatter([text_probs[i] for i in spam_indices], 
                            [image_probs[i] for i in spam_indices], 
                            c='red', label='Spam', alpha=0.8, s=120, edgecolors='darkred')
        if ham_indices:
            axes[0,0].scatter([text_probs[i] for i in ham_indices], 
                            [image_probs[i] for i in ham_indices], 
                            c='blue', label='Ham', alpha=0.8, s=120, edgecolors='darkblue')
        
        axes[0,0].set_xlabel('Text Spam Probability')
        axes[0,0].set_ylabel('Image Spam Probability')
        axes[0,0].set_title('Modality Contribution Distribution')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. ìƒ˜í”Œë³„ ê¸°ì—¬ë„ ë§‰ëŒ€ ê·¸ë˜í”„
        x = np.arange(len(results))
        width = 0.25
        
        axes[0,1].bar(x - width, text_probs, width, label='Text', alpha=0.8, color='skyblue')
        axes[0,1].bar(x, image_probs, width, label='Image', alpha=0.8, color='lightcoral')
        axes[0,1].bar(x + width, full_probs, width, label='Fusion', alpha=0.8, color='gold')
        
        axes[0,1].set_xlabel('Sample Index')
        axes[0,1].set_ylabel('Spam Probability')
        axes[0,1].set_title('Per-Sample Contribution Comparison')
        axes[0,1].legend()
        axes[0,1].set_xticks(x)
        
        # 3. ìƒí˜¸ì‘ìš© íš¨ê³¼
        colors = ['red' if r['true_label'] == 1 else 'blue' for r in results]
        bars = axes[1,0].bar(x, interactions, color=colors, alpha=0.7, edgecolor='black')
        axes[1,0].set_xlabel('Sample Index')
        axes[1,0].set_ylabel('Interaction Effect')
        axes[1,0].set_title('Interaction Effect (Red: Spam, Blue: Ham)')
        axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.8, linewidth=2)
        axes[1,0].set_xticks(x)
        
        # ìƒí˜¸ì‘ìš© íš¨ê³¼ ê°’ì„ ë§‰ëŒ€ ìœ„ì— í‘œì‹œ
        for i, (bar, value) in enumerate(zip(bars, interactions)):
            height = bar.get_height()
            axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 0.01 if height >= 0 else height - 0.02,
                          f'{value:.2f}', ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)
        
        # 4. ì˜ˆì¸¡ ì •í™•ì„± íŒŒì´ ì°¨íŠ¸
        correct_mask = [r['true_label'] == r['predicted_class'] for r in results]
        correct_count = sum(correct_mask)
        incorrect_count = len(results) - correct_count
        
        if incorrect_count > 0:
            sizes = [correct_count, incorrect_count]
            labels = [f'Correct ({correct_count})', f'Incorrect ({incorrect_count})']
            colors = ['lightgreen', 'lightcoral']
        else:
            sizes = [correct_count]
            labels = [f'All Correct ({correct_count})']
            colors = ['lightgreen']
        
        axes[1,1].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)
        axes[1,1].set_title('Prediction Accuracy')
        
        plt.tight_layout()
        plt.savefig('mmtd_attention_analysis_final.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"\nğŸ¨ ê²°ê³¼ ì‹œê°í™” ì €ì¥ë¨: mmtd_attention_analysis_final.png")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    checkpoint_path = "checkpoints/fold1/checkpoint-939"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸:")
        for fold in range(1, 6):
            fold_path = f"checkpoints/fold{fold}/checkpoint-939"
            if os.path.exists(fold_path):
                print(f"   âœ… {fold_path}")
        return
    
    try:
        print("ğŸš€ MMTD Attention ê¸°ë°˜ í•´ì„ì„± ì‹¤í—˜ ì‹œì‘")
        analyzer = WorkingAttentionAnalyzer(checkpoint_path)
        analyzer.run_comprehensive_analysis()
        
        print(f"\n" + "="*70)
        print("ğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
        print("="*70)
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 