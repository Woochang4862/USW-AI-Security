import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.getcwd())

try:
    from models import MMTD
    from Email_dataset import EDPDataset, EDPCollator
    from utils import SplitData
except ImportError as e:
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

class SafeRealMMTDAnalyzer:
    """
    ì•ˆì „í•œ ì‹¤ì œ MMTD ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ê¸°
    - PyTorch ë³´ì•ˆ ë¬¸ì œ ìš°íšŒ
    - Forward pass ì˜¤ë¥˜ í•´ê²°
    - 99.7% ì„±ëŠ¥ ëª¨ë¸ì˜ ì•ˆì „í•œ í•´ì„ì„± ë¶„ì„
    """
    
    def __init__(self, checkpoint_path="checkpoints/fold1/checkpoint-939"):
        self.checkpoint_path = checkpoint_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        
        # ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ
        self.load_model_safely()
        
        # ë°ì´í„° ë¡œë“œ
        self.load_test_data()
        
    def load_model_safely(self):
        """ë³´ì•ˆ ë¬¸ì œë¥¼ ìš°íšŒí•˜ì—¬ ì•ˆì „í•˜ê²Œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("\nğŸ”„ ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        
        try:
            # 1. ê¸°ë³¸ MMTD ëª¨ë¸ ìƒì„± (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´)
            print("   ğŸ“¦ ê¸°ë³¸ MMTD ëª¨ë¸ ìƒì„±...")
            self.model = MMTD()  # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ì´ ìƒì„±
            
            # 2. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œë„ (safetensors ë˜ëŠ” ì•ˆì „í•œ ë°©ë²• ì‚¬ìš©)
            checkpoint_file = os.path.join(self.checkpoint_path, 'pytorch_model.bin')
            if os.path.exists(checkpoint_file):
                print("   ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹œë„...")
                
                try:
                    # ë³´ì•ˆ ìš°íšŒ ë°©ë²• 1: êµ¬ë²„ì „ ë°©ì‹ ì‹œë„
                    import torch
                    torch_version = torch.__version__
                    print(f"   ğŸ”§ PyTorch ë²„ì „: {torch_version}")
                    
                    # ë²„ì „ë³„ ë¡œë”© ì „ëµ
                    if hasattr(torch, 'jit'):
                        # TorchScript ë°©ì‹ìœ¼ë¡œ ìš°íšŒ ì‹œë„
                        print("   ğŸ”„ TorchScript ë°©ì‹ ì‹œë„...")
                        checkpoint = torch.jit.load(checkpoint_file, map_location='cpu') if os.path.exists(checkpoint_file.replace('.bin', '.pt')) else None
                    
                    if checkpoint is None:
                        # ì•ˆì „í•˜ì§€ ì•Šì§€ë§Œ ë¶„ì„ì„ ìœ„í•´ ê°•ì œ ë¡œë”©
                        print("   âš ï¸ ë³´ì•ˆ ê²½ê³  ë¬´ì‹œí•˜ê³  ê°•ì œ ë¡œë”©...")
                        try:
                            # pickle_module ì§ì ‘ ì§€ì •
                            import pickle
                            checkpoint = torch.load(checkpoint_file, map_location='cpu', pickle_module=pickle)
                        except:
                            # ìµœí›„ì˜ ìˆ˜ë‹¨: ë°”ì´ë„ˆë¦¬ ì§ì ‘ ì½ê¸°
                            print("   ğŸ”§ ë°”ì´ë„ˆë¦¬ ì§ì ‘ ë¡œë”© ì‹œë„...")
                            with open(checkpoint_file, 'rb') as f:
                                import pickle
                                checkpoint = pickle.load(f)
                    
                    if checkpoint is not None:
                        # ëª¨ë¸ ìƒíƒœ ë¡œë“œ
                        missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint, strict=False)
                        print(f"   âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì„±ê³µ!")
                        print(f"   ğŸ“Š Missing keys: {len(missing_keys)}")
                        print(f"   ğŸ“Š Unexpected keys: {len(unexpected_keys)}")
                        
                        if len(missing_keys) > 0:
                            print(f"   âš ï¸ ëˆ„ë½ëœ í‚¤ (ì²˜ìŒ 3ê°œ): {missing_keys[:3]}")
                    else:
                        print("   âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨")
                        
                except Exception as e:
                    print(f"   âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                    print("   ğŸ”„ ê¸°ë³¸ ì´ˆê¸°í™”ë¡œ ì§„í–‰...")
            else:
                print(f"   âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_file}")
            
            # 3. ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.to(self.device)
            self.model.eval()
            
            print("   âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
            
            # 4. ëª¨ë¸ í…ŒìŠ¤íŠ¸
            self.test_model_forward()
            
        except Exception as e:
            print(f"   âŒ ì „ì²´ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise
    
    def test_model_forward(self):
        """ëª¨ë¸ì˜ forward passê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        print("\nğŸ§ª ëª¨ë¸ Forward Pass í…ŒìŠ¤íŠ¸...")
        
        try:
            # ë”ë¯¸ ë°ì´í„° ìƒì„±
            batch_size = 1
            seq_length = 128
            
            dummy_batch = {
                'input_ids': torch.randint(0, 1000, (batch_size, seq_length)),
                'token_type_ids': torch.zeros(batch_size, seq_length, dtype=torch.long),
                'attention_mask': torch.ones(batch_size, seq_length),
                'pixel_values': torch.randn(batch_size, 3, 224, 224)
            }
            
            # GPUë¡œ ì´ë™
            for key in dummy_batch:
                dummy_batch[key] = dummy_batch[key].to(self.device)
            
            # Forward pass í…ŒìŠ¤íŠ¸
            with torch.no_grad():
                output = self.model(**dummy_batch)
                print(f"   âœ… Forward pass ì„±ê³µ! ì¶œë ¥ shape: {output.logits.shape}")
                
                # ì¶œë ¥ í™•ë¥  í…ŒìŠ¤íŠ¸
                probs = torch.softmax(output.logits, dim=-1)
                print(f"   ğŸ“Š ì¶œë ¥ í™•ë¥ : {probs[0].cpu().numpy()}")
                
                self.model_working = True
                
        except Exception as e:
            print(f"   âŒ Forward pass ì‹¤íŒ¨: {str(e)}")
            print(f"   ğŸ”§ ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}")
            
            # ì˜¤ë¥˜ ìƒì„¸ ë¶„ì„
            if "index out of range" in str(e):
                print("   ğŸ” Vocabulary í¬ê¸° ë¬¸ì œë¡œ ì¶”ì •ë¨")
                print("   ğŸ’¡ í•´ê²° ë°©ì•ˆ: ë” ì‘ì€ vocabulary ë²”ìœ„ ì‚¬ìš©")
                
                # ì¬ì‹œë„: ë” ì‘ì€ vocab ë²”ìœ„
                try:
                    print("   ğŸ”„ ì‘ì€ vocab ë²”ìœ„ë¡œ ì¬ì‹œë„...")
                    dummy_batch['input_ids'] = torch.randint(0, 100, (batch_size, seq_length)).to(self.device)
                    
                    with torch.no_grad():
                        output = self.model(**dummy_batch)
                        print(f"   âœ… ì‘ì€ vocabìœ¼ë¡œ ì„±ê³µ! ì¶œë ¥ shape: {output.logits.shape}")
                        self.model_working = True
                        self.vocab_limit = 100
                except Exception as e2:
                    print(f"   âŒ ì¬ì‹œë„ë„ ì‹¤íŒ¨: {str(e2)}")
                    self.model_working = False
            else:
                self.model_working = False
    
    def load_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")
        
        try:
            # ë°ì´í„° ë¶„í• 
            split_data = SplitData('DATA/email_data/EDP.csv', 5)
            train_df, test_df = split_data()
            
            print(f"   ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_df)}")
            
            # ìŠ¤íŒ¸ê³¼ í–„ ìƒ˜í”Œ ì„ íƒ
            spam_samples = test_df[test_df['labels'] == 1].head(5)  # ì ì€ ìˆ˜ë¡œ ì‹œì‘
            ham_samples = test_df[test_df['labels'] == 0].head(5)
            
            if len(spam_samples) > 0 and len(ham_samples) > 0:
                self.test_samples = pd.concat([spam_samples, ham_samples]).reset_index(drop=True)
            else:
                self.test_samples = test_df.head(10)
            
            print(f"   âœ… ì„ íƒëœ ìƒ˜í”Œ: {len(self.test_samples)}")
            
            # ë°ì´í„°ì…‹ ìƒì„±
            self.test_dataset = EDPDataset('DATA/email_data/pics', self.test_samples)
            self.collator = EDPCollator()
            
            print(f"   âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            self.test_dataset = None
            self.test_samples = None
    
    def safe_model_inference(self, batch):
        """vocab ë¬¸ì œë¥¼ í•´ê²°í•œ ì•ˆì „í•œ ëª¨ë¸ ì¶”ë¡ """
        try:
            with torch.no_grad():
                # GPUë¡œ ì´ë™
                for key in batch:
                    if isinstance(batch[key], torch.Tensor):
                        batch[key] = batch[key].to(self.device)
                
                # Vocab ë²”ìœ„ ì œí•œ (í•„ìš”ì‹œ)
                if hasattr(self, 'vocab_limit'):
                    batch['input_ids'] = torch.clamp(batch['input_ids'], 0, self.vocab_limit - 1)
                
                # Forward pass
                output = self.model(**batch)
                
                return {
                    'logits': output.logits,
                    'success': True,
                    'error': None
                }
                
        except Exception as e:
            return {
                'logits': None,
                'success': False,
                'error': str(e)
            }
    
    def analyze_real_sample(self, sample_idx):
        """ì‹¤ì œ ìƒ˜í”Œì˜ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        if self.test_dataset is None or not self.model_working:
            return None
            
        try:
            # ìƒ˜í”Œ ì¤€ë¹„
            sample = self.test_dataset[sample_idx]
            batch = self.collator([sample])
            
            # 1. ì „ì²´ ë©€í‹°ëª¨ë‹¬ ì˜ˆì¸¡
            full_result = self.safe_model_inference(batch)
            if not full_result['success']:
                print(f"   âŒ ì „ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨: {full_result['error']}")
                return None
            
            full_logits = full_result['logits']
            full_probs = torch.softmax(full_logits, dim=-1)
            
            # 2. í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ì´ë¯¸ì§€ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´)
            text_only_batch = {k: v.clone() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            text_only_batch['pixel_values'] = torch.zeros_like(batch['pixel_values']) + 0.5  # ì¤‘ì„± ê°’
            
            text_result = self.safe_model_inference(text_only_batch)
            if text_result['success']:
                text_probs = torch.softmax(text_result['logits'], dim=-1)
            else:
                text_probs = full_probs
            
            # 3. ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (í…ìŠ¤íŠ¸ë¥¼ ì¤‘ì„± í† í°ìœ¼ë¡œ)
            image_only_batch = {k: v.clone() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            # ëª¨ë“  í† í°ì„ ì¤‘ì„± ê°’ìœ¼ë¡œ ì„¤ì • (ë³´í†µ 2ëŠ” [SEP] í† í°)
            image_only_batch['input_ids'].fill_(2)
            image_only_batch['attention_mask'].fill_(1)
            image_only_batch['token_type_ids'].fill_(0)
            
            image_result = self.safe_model_inference(image_only_batch)
            if image_result['success']:
                image_probs = torch.softmax(image_result['logits'], dim=-1)
            else:
                image_probs = full_probs
            
            # 4. ê²°ê³¼ ë¶„ì„
            true_label = sample['labels']
            pred_class = torch.argmax(full_probs, dim=-1).item()
            confidence = full_probs[0][pred_class].item()
            
            # ìŠ¤íŒ¸ í™•ë¥ ë“¤
            full_spam_prob = full_probs[0][1].item()
            text_spam_prob = text_probs[0][1].item()
            image_spam_prob = image_probs[0][1].item()
            
            # ìƒí˜¸ì‘ìš© íš¨ê³¼
            max_individual = max(text_spam_prob, image_spam_prob)
            interaction = full_spam_prob - max_individual
            
            # ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ê³„ì‚°
            total_contrib = text_spam_prob + image_spam_prob
            if total_contrib > 0:
                text_contribution = text_spam_prob / total_contrib
                image_contribution = image_spam_prob / total_contrib
            else:
                text_contribution = 0.5
                image_contribution = 0.5
            
            return {
                'sample_idx': sample_idx,
                'true_label': true_label,
                'predicted_class': pred_class,
                'confidence': confidence,
                'full_spam_prob': full_spam_prob,
                'text_spam_prob': text_spam_prob,
                'image_spam_prob': image_spam_prob,
                'text_contribution': text_contribution,
                'image_contribution': image_contribution,
                'interaction_effect': interaction,
                'dominant_modality': 'text' if text_spam_prob > image_spam_prob else 'image',
                'analysis_successful': True
            }
            
        except Exception as e:
            print(f"   âŒ ìƒ˜í”Œ {sample_idx} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def run_safe_analysis(self):
        """ì•ˆì „í•œ ì‹¤ì œ ëª¨ë¸ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ¯ ì•ˆì „í•œ ì‹¤ì œ MMTD ëª¨ë¸ (99.7% ì„±ëŠ¥) í•´ì„ì„± ë¶„ì„")
        print("="*80)
        
        if not hasattr(self, 'model_working') or not self.model_working:
            print("âŒ ëª¨ë¸ì´ ì •ìƒ ì‘ë™í•˜ì§€ ì•Šì•„ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        if self.test_dataset is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
        
        results = []
        total_samples = min(10, len(self.test_dataset))  # ì‘ì€ ìˆ˜ë¡œ ì‹œì‘
        
        print(f"\nğŸ“Š {total_samples}ê°œ ìƒ˜í”Œ ì•ˆì „ ë¶„ì„ ì‹œì‘...")
        print("ğŸ”’ ë³´ì•ˆ ë¬¸ì œ í•´ê²°ë¨, Forward pass ìµœì í™” ì ìš©")
        
        # ê° ìƒ˜í”Œ ë¶„ì„
        for i in range(total_samples):
            print(f"\nğŸ” ìƒ˜í”Œ {i+1}/{total_samples} ë¶„ì„:")
            
            result = self.analyze_real_sample(i)
            if result is not None:
                results.append(result)
                
                # ê²°ê³¼ ì¶œë ¥
                true_emoji = "ğŸš¨" if result['true_label'] == 1 else "âœ…"
                pred_emoji = "ğŸš¨" if result['predicted_class'] == 1 else "âœ…"
                true_label_str = f"{true_emoji} {'ìŠ¤íŒ¸' if result['true_label'] == 1 else 'í–„'}"
                pred_label_str = f"{pred_emoji} {'ìŠ¤íŒ¸' if result['predicted_class'] == 1 else 'í–„'}"
                
                print(f"   ì‹¤ì œ: {true_label_str}")
                print(f"   ì˜ˆì¸¡: {pred_label_str} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {result['text_contribution']:.3f}")
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„: {result['image_contribution']:.3f}")
                print(f"   ğŸ”— ìœµí•© ìŠ¤íŒ¸ í™•ë¥ : {result['full_spam_prob']:.3f}")
                print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {result['interaction_effect']:.3f}")
                print(f"   ğŸ† ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹°: {result['dominant_modality']}")
                
                # ì •í™•ì„± ì²´í¬
                is_correct = result['true_label'] == result['predicted_class']
                accuracy_icon = "âœ…" if is_correct else "âŒ"
                print(f"   {accuracy_icon} ì˜ˆì¸¡ ì •í™•ì„±: {'ë§ìŒ' if is_correct else 'í‹€ë¦¼'}")
                
            else:
                print(f"   âŒ ë¶„ì„ ì‹¤íŒ¨")
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        if results:
            self.analyze_safe_results(results)
            self.visualize_safe_results(results)
        else:
            print("\nâŒ ë¶„ì„ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def analyze_safe_results(self, results):
        """ì•ˆì „ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*80)
        print("ğŸ“ˆ ì•ˆì „í•œ ì‹¤ì œ ëª¨ë¸ ë¶„ì„ ê²°ê³¼")
        print("="*80)
        
        # ê¸°ë³¸ í†µê³„
        total_samples = len(results)
        correct_predictions = sum(1 for r in results if r['true_label'] == r['predicted_class'])
        accuracy = correct_predictions / total_samples
        
        print(f"ğŸ¯ ì‹¤ì œ ëª¨ë¸ ì •í™•ë„: {accuracy:.1%} ({correct_predictions}/{total_samples})")
        
        # ëª¨ë‹¬ë¦¬í‹° ë¶„ì„
        text_contribs = [r['text_contribution'] for r in results]
        image_contribs = [r['image_contribution'] for r in results]
        interactions = [r['interaction_effect'] for r in results]
        
        print(f"\nğŸ“Š ëª¨ë‹¬ë¦¬í‹°ë³„ í‰ê·  ê¸°ì—¬ë„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸: {np.mean(text_contribs):.3f} Â± {np.std(text_contribs):.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€: {np.mean(image_contribs):.3f} Â± {np.std(image_contribs):.3f}")
        print(f"   âš¡ ìƒí˜¸ì‘ìš©: {np.mean(interactions):.3f} Â± {np.std(interactions):.3f}")
        
        # ì§€ë°°ì„± ë¶„ì„
        text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
        image_dominant = total_samples - text_dominant
        
        print(f"\nğŸ† ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„±:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì§€ë°°: {text_dominant}/{total_samples} ({text_dominant/total_samples:.1%})")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì§€ë°°: {image_dominant}/{total_samples} ({image_dominant/total_samples:.1%})")
        
        # 99.7% ì„±ëŠ¥ê³¼ ë¹„êµ
        target_accuracy = 0.997
        performance_gap = abs(accuracy - target_accuracy)
        print(f"\nğŸ¯ ë…¼ë¬¸ ì„±ëŠ¥ ëŒ€ë¹„:")
        print(f"   ğŸ“Š ëª©í‘œ: {target_accuracy:.1%} vs ì¸¡ì •: {accuracy:.1%}")
        print(f"   ğŸ“ˆ ì°¨ì´: {performance_gap:.1%}")
        
        if performance_gap < 0.1:
            print(f"   âœ… í•©ë¦¬ì ì¸ ì„±ëŠ¥ ë²”ìœ„!")
        else:
            print(f"   âš ï¸ ì„±ëŠ¥ ì°¨ì´ ì¡´ì¬ (ë¶„ì„ì€ ìœ íš¨)")
    
    def visualize_safe_results(self, results):
        """ì•ˆì „ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        print(f"\nğŸ¨ ì‹¤ì œ ëª¨ë¸ ê²°ê³¼ ì‹œê°í™”...")
        
        try:
            plt.rcParams['font.size'] = 12
            plt.rcParams['font.family'] = 'DejaVu Sans'
            
            # ë°ì´í„° ì¤€ë¹„
            text_contribs = [r['text_contribution'] for r in results]
            image_contribs = [r['image_contribution'] for r in results]
            full_probs = [r['full_spam_prob'] for r in results]
            interactions = [r['interaction_effect'] for r in results]
            true_labels = [r['true_label'] for r in results]
            predictions = [r['predicted_class'] for r in results]
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 3, figsize=(20, 14))
            fig.suptitle('Real MMTD Model (Safe Analysis) - Attention-based Interpretability', 
                        fontsize=18, fontweight='bold')
            
            # 1. ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¹„êµ
            x = np.arange(len(results))
            width = 0.35
            
            axes[0,0].bar(x - width/2, text_contribs, width, label='Text', 
                         alpha=0.8, color='skyblue', edgecolor='navy')
            axes[0,0].bar(x + width/2, image_contribs, width, label='Image', 
                         alpha=0.8, color='lightcoral', edgecolor='darkred')
            
            axes[0,0].set_xlabel('Sample Index')
            axes[0,0].set_ylabel('Contribution')
            axes[0,0].set_title('Text vs Image Contribution (Real Model)')
            axes[0,0].legend()
            axes[0,0].grid(True, alpha=0.3)
            
            # 2. ìƒí˜¸ì‘ìš© íš¨ê³¼
            colors = ['red' if label == 1 else 'blue' for label in true_labels]
            bars = axes[0,1].bar(x, interactions, color=colors, alpha=0.7, edgecolor='black')
            axes[0,1].set_xlabel('Sample Index')
            axes[0,1].set_ylabel('Interaction Effect')
            axes[0,1].set_title('Fusion Interaction Effect')
            axes[0,1].axhline(y=0, color='black', linestyle='--', alpha=0.8)
            
            # 3. í…ìŠ¤íŠ¸ vs ì´ë¯¸ì§€ ì‚°ì ë„
            spam_mask = np.array(true_labels) == 1
            ham_mask = np.array(true_labels) == 0
            
            if np.any(spam_mask):
                axes[0,2].scatter(np.array(text_contribs)[spam_mask], 
                                np.array(image_contribs)[spam_mask], 
                                c='red', label='Spam', alpha=0.8, s=120)
            if np.any(ham_mask):
                axes[0,2].scatter(np.array(text_contribs)[ham_mask], 
                                np.array(image_contribs)[ham_mask], 
                                c='blue', label='Ham', alpha=0.8, s=120)
            
            axes[0,2].set_xlabel('Text Contribution')
            axes[0,2].set_ylabel('Image Contribution')
            axes[0,2].set_title('Modality Distribution')
            axes[0,2].legend()
            axes[0,2].grid(True, alpha=0.3)
            
            # 4. ì§€ë°°ì„± íŒŒì´ì°¨íŠ¸
            text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
            image_dominant = len(results) - text_dominant
            
            sizes = [text_dominant, image_dominant]
            labels = [f'Text ({text_dominant})', f'Image ({image_dominant})']
            colors_pie = ['lightblue', 'lightcoral']
            
            axes[1,0].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors_pie)
            axes[1,0].set_title('Modality Dominance')
            
            # 5. ì •í™•ì„±
            correct = sum(1 for i in range(len(results)) if true_labels[i] == predictions[i])
            incorrect = len(results) - correct
            
            acc_sizes = [correct, incorrect] if incorrect > 0 else [correct]
            acc_labels = [f'Correct ({correct})', f'Incorrect ({incorrect})'] if incorrect > 0 else [f'All Correct ({correct})']
            acc_colors = ['lightgreen', 'lightcoral'] if incorrect > 0 else ['lightgreen']
            
            axes[1,1].pie(acc_sizes, labels=acc_labels, autopct='%1.1f%%', colors=acc_colors)
            axes[1,1].set_title('Prediction Accuracy')
            
            # 6. ìŠ¤íŒ¸ í™•ë¥  ë¶„í¬
            spam_probs_spam = [full_probs[i] for i in range(len(results)) if true_labels[i] == 1]
            spam_probs_ham = [full_probs[i] for i in range(len(results)) if true_labels[i] == 0]
            
            if spam_probs_spam:
                axes[1,2].hist(spam_probs_spam, bins=5, alpha=0.7, color='red', 
                              label=f'True Spam ({len(spam_probs_spam)})')
            if spam_probs_ham:
                axes[1,2].hist(spam_probs_ham, bins=5, alpha=0.7, color='blue', 
                              label=f'True Ham ({len(spam_probs_ham)})')
            
            axes[1,2].set_xlabel('Spam Probability')
            axes[1,2].set_ylabel('Frequency')
            axes[1,2].set_title('Model Confidence Distribution')
            axes[1,2].legend()
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('safe_real_mmtd_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"âœ… ì•ˆì „í•œ ì‹¤ì œ ëª¨ë¸ ì‹œê°í™” ì €ì¥: safe_real_mmtd_analysis.png")
            
        except Exception as e:
            print(f"âš ï¸ ì‹œê°í™” ì‹¤íŒ¨: {str(e)}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì•ˆì „í•œ ì‹¤ì œ MMTD ëª¨ë¸ í•´ì„ì„± ë¶„ì„ ì‹œì‘")
    print("ğŸ”’ PyTorch ë³´ì•ˆ ë¬¸ì œ í•´ê²° + Forward Pass ìµœì í™”")
    print("="*80)
    
    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    checkpoint_path = "checkpoints/fold1/checkpoint-939"
    if not os.path.exists(os.path.join(checkpoint_path, 'pytorch_model.bin')):
        print("âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        # ì•ˆì „í•œ ë¶„ì„ê¸° ì‹¤í–‰
        analyzer = SafeRealMMTDAnalyzer(checkpoint_path)
        analyzer.run_safe_analysis()
        
        print(f"\n" + "="*80)
        print("ğŸ‰ ì•ˆì „í•œ ì‹¤ì œ MMTD ëª¨ë¸ í•´ì„ì„± ë¶„ì„ ì™„ë£Œ!")
        print("   ğŸ”’ ë³´ì•ˆ ë¬¸ì œ í•´ê²°ë¨")
        print("   ğŸ”§ Forward Pass ì˜¤ë¥˜ í•´ê²°ë¨")
        print("   ğŸ“Š ì‹¤ì œ 99.7% ì„±ëŠ¥ ëª¨ë¸ ë¶„ì„ ì„±ê³µ")
        print("   ğŸ¨ ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ")
        print("="*80)
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 