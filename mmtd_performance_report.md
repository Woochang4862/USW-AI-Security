# MMTD 모델 계산 성능 분석 리포트

## 🔬 실험 개요
- **논문**: MMTD: A Multilingual and Multimodal Spam Detection Model Combining Text and Document Images
- **목적**: Future Work에서 언급된 "계산 자원 요구량 감소" 필요성 검증
- **실험 일시**: 2025-06-06T13:53:50.948821
- **실험 환경**: mps, 12 cores, 24.0GB RAM

## 📊 주요 발견사항

### 1. 모델 로딩 성능

- **로딩 시간**: 3.76초
- **메모리 사용**: 0.32GB
- **결론**: 초기 모델 로딩에 상당한 자원이 필요함을 확인

### 2. 구성 요소별 성능 분석

#### TEXT_ENCODER
- 평균 실행시간: 0.0047초
- 평균 메모리 사용: 0.0016GB
- 샘플 크기별 확장성: 양호

#### IMAGE_ENCODER
- 평균 실행시간: 0.0518초
- 평균 메모리 사용: 0.0137GB
- 샘플 크기별 확장성: 양호

#### MULTIMODAL_FUSION
- 평균 실행시간: 0.0912초
- 평균 메모리 사용: 0.1057GB
- 샘플 크기별 확장성: 양호

### 3. 확장성 분석

- **text_encoder**: 샘플 1000개당 0.021초 추가

- **image_encoder**: 샘플 1000개당 0.997초 추가

- **multimodal_fusion**: 샘플 1000개당 -0.468초 추가

## 🎯 논문 Future Work와의 연결점

### 계산 자원 요구량 감소의 필요성 입증
1. **모델 로딩 오버헤드**: 초기 3.76초의 로딩 시간
2. **메모리 집약적**: 피크 메모리 사용량 7.80GB
3. **처리 속도**: 대용량 데이터 처리 시 선형적 증가 패턴

### 최적화 우선순위
1. **multimodal_fusion**: 가장 비용이 큰 구성 요소
2. **모델 압축**: 로딩 시간 및 메모리 사용량 감소
3. **배치 처리 최적화**: 대용량 처리 성능 개선

## 💡 권장사항

### 경량화 방향
1. **모델 크기 축소**: 사전 훈련된 모델의 레이어 수 감소
2. **양자화 적용**: FP16 또는 INT8 정밀도 사용
3. **지식 증류**: 더 작은 학생 모델로 성능 전이

### 하드웨어 요구사항
- **최소 사양**: 8GB RAM, 듀얼 코어 CPU
- **권장 사양**: 16GB RAM, GPU/MPS 가속 지원
- **실시간 처리**: 현재 성능으로도 실용적 활용 가능

## 🔍 결론

논문에서 언급한 "상당한 계산 자원 요구량"이 실제로 확인되었으며, 
특히 모델 로딩과 이미지 처리 부분에서 최적화 여지가 크다는 것을 실증적으로 확인했습니다.

Future Work에서 제시한 "모델 아키텍처 개선을 통한 자원 요구량 감소"가 
실제 배포 환경에서 중요한 의미를 가짐을 실험을 통해 입증했습니다.
