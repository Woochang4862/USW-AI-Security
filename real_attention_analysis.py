import os
import sys
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import warnings
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import json
from datetime import datetime

# Add src directory to path
sys.path.append('src')

# Import required modules
from models.original_mmtd_model import OriginalMMTD
from evaluation.dataset_loader import EDPDataset, EDPCollator
from evaluation.data_split import SplitData

warnings.filterwarnings('ignore')

class RealAttentionAnalyzer:
    """
    ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•œ MMTD Attention ê¸°ë°˜ í•´ì„ì„± ë¶„ì„ê¸°
    99.7% ì„±ëŠ¥ ëª¨ë¸ì— ëŒ€í•œ ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
    """
    
    def __init__(self, checkpoint_path: str, data_path: str = 'DATA/email_data/EDP.csv', 
                 images_path: str = 'DATA/email_data/pics'):
        """
        ì´ˆê¸°í™”
        
        Args:
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì˜ˆ: "checkpoints/fold1/checkpoint-939")
            data_path: ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ
            images_path: ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        """
        self.checkpoint_path = checkpoint_path
        self.data_path = data_path
        self.images_path = images_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else 
                                  "mps" if torch.backends.mps.is_available() else "cpu")
        
        print(f"ğŸ”§ Real Attention Analyzer ì´ˆê¸°í™”")
        print(f"   Device: {self.device}")
        print(f"   Checkpoint: {checkpoint_path}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_real_model()
        
        # ë°ì´í„° ë¡œë“œ
        self._load_test_data()
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬
        self.results_dir = "real_attention_results"
        os.makedirs(self.results_dir, exist_ok=True)
        
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _load_real_model(self) -> OriginalMMTD:
        """ì‹¤ì œ í›ˆë ¨ëœ MMTD ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("\nğŸ”„ ì‹¤ì œ MMTD ëª¨ë¸ ë¡œë”©...")
        
        try:
            # ì›ë³¸ê³¼ ë™ì¼í•œ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ì´ˆê¸°í™”
            model = OriginalMMTD(
                bert_pretrain_weight='bert-base-multilingual-cased',
                beit_pretrain_weight='microsoft/dit-base'
            )
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint_file = os.path.join(self.checkpoint_path, 'pytorch_model.bin')
            
            if not os.path.exists(checkpoint_file):
                raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_file}")
            
            print(f"   ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©: {checkpoint_file}")
            
            # ì•ˆì „í•œ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
            checkpoint = torch.load(checkpoint_file, map_location='cpu', weights_only=False)
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (strict=Falseë¡œ í˜¸í™˜ì„± ë¬¸ì œ ìš°íšŒ)
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint, strict=False)
            
            # ë¡œë”© ê²°ê³¼ ì¶œë ¥
            total_keys = len(model.state_dict())
            loaded_keys = total_keys - len(missing_keys)
            loading_rate = loaded_keys / total_keys * 100
            
            print(f"   âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì™„ë£Œ: {loaded_keys}/{total_keys} ({loading_rate:.1f}%)")
            
            if missing_keys:
                print(f"   âš ï¸ Missing keys: {len(missing_keys)}")
                if len(missing_keys) <= 5:
                    for key in missing_keys:
                        print(f"      - {key}")
                else:
                    print(f"      - {missing_keys[0]} ... (and {len(missing_keys)-1} more)")
            
            if unexpected_keys:
                print(f"   âš ï¸ Unexpected keys: {len(unexpected_keys)}")
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•˜ê³  ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            model.eval()
            model.to(self.device)
            
            print(f"   ğŸ¯ ëª¨ë¸ì´ {self.device}ë¡œ ì´ë™ ì™„ë£Œ")
            
            return model
            
        except Exception as e:
            print(f"   âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print(f"   ğŸ”„ ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´...")
            
            # ê¸°ë³¸ ëª¨ë¸ ìƒì„± (ì²´í¬í¬ì¸íŠ¸ ì—†ì´)
            model = OriginalMMTD()
            model.eval()
            model.to(self.device)
            return model
    
    def _load_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("\nğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")
        
        try:
            # ë°ì´í„° ë¶„í•  (5-fold ì¤‘ ì²« ë²ˆì§¸ ì‚¬ìš©)
            split_data = SplitData(self.data_path, 5)
            train_df, test_df = split_data()
            
            # ìŠ¤íŒ¸ê³¼ í–„ ìƒ˜í”Œì„ ê· ë“±í•˜ê²Œ ì„ íƒ
            spam_samples = test_df[test_df['labels'] == 1].head(10)
            ham_samples = test_df[test_df['labels'] == 0].head(10)
            
            # ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if len(spam_samples) == 0 or len(ham_samples) == 0:
                print("   âš ï¸ ìŠ¤íŒ¸ ë˜ëŠ” í–„ ìƒ˜í”Œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©")
                test_sample = test_df.head(20)
            else:
                test_sample = pd.concat([spam_samples, ham_samples])
            
            # ë°ì´í„°ì…‹ê³¼ ì½œë ˆì´í„° ìƒì„±
            self.test_dataset = EDPDataset(self.images_path, test_sample)
            self.collator = EDPCollator()
            
            print(f"   âœ… í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ:")
            print(f"      ì´ ìƒ˜í”Œ: {len(test_sample)}")
            print(f"      ìŠ¤íŒ¸: {len(spam_samples)}, í–„: {len(ham_samples)}")
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            print("   ğŸ”„ ë”ë¯¸ ë°ì´í„°ë¡œ ëŒ€ì²´")
            self.test_dataset = None
            self.collator = EDPCollator()
    
    def extract_attention_weights(self, sample_idx: int) -> Optional[Dict[str, Any]]:
        """ê°œë³„ ìƒ˜í”Œì—ì„œ attention weightsë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if self.test_dataset is None:
            return None
            
        try:
            # ìƒ˜í”Œ ë¡œë“œ
            sample = self.test_dataset[sample_idx]
            batch = self.collator([sample])
            
            # GPUë¡œ ì´ë™
            for key in batch:
                if isinstance(batch[key], torch.Tensor):
                    batch[key] = batch[key].to(self.device)
            
            with torch.no_grad():
                # Attention weightsì™€ í•¨ê»˜ forward pass
                outputs = self.model(
                    input_ids=batch['input_ids'],
                    token_type_ids=batch.get('token_type_ids'),
                    attention_mask=batch['attention_mask'],
                    pixel_values=batch['pixel_values'],
                    output_attentions=True  # ì¤‘ìš”: attention weights ì¶œë ¥ ìš”ì²­
                )
                
                # ê°œë³„ ì¸ì½”ë”ì˜ ì¶œë ¥ë„ ê°€ì ¸ì˜¤ê¸° (hidden states í¬í•¨)
                text_outputs = self.model.text_encoder(
                    input_ids=batch['input_ids'],
                    token_type_ids=batch.get('token_type_ids'),
                    attention_mask=batch['attention_mask'],
                    output_attentions=True,
                    output_hidden_states=True
                )
                
                image_outputs = self.model.image_encoder(
                    pixel_values=batch['pixel_values'],
                    output_attentions=True,
                    output_hidden_states=True
                )
                
                # ê²°ê³¼ ì •ë¦¬
                result = {
                    'sample_idx': sample_idx,
                    'true_label': sample['labels'],
                    'prediction_logits': outputs.logits.cpu(),
                    'prediction_probs': F.softmax(outputs.logits, dim=-1).cpu(),
                    'text_attentions': text_outputs.attentions,
                    'image_attentions': image_outputs.attentions,
                    'text_hidden_states': text_outputs.hidden_states,
                    'image_hidden_states': image_outputs.hidden_states
                }
                
                return result
                
        except Exception as e:
            print(f"   âš ï¸ ìƒ˜í”Œ {sample_idx} attention ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def analyze_modality_contributions(self, sample_idx: int) -> Optional[Dict[str, Any]]:
        """ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ë¥¼ ì‹¤ì œë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
        if self.test_dataset is None:
            return None
            
        try:
            sample = self.test_dataset[sample_idx]
            batch = self.collator([sample])
            
            # GPUë¡œ ì´ë™
            for key in batch:
                if isinstance(batch[key], torch.Tensor):
                    batch[key] = batch[key].to(self.device)
            
            with torch.no_grad():
                # 1. ì „ì²´ ë©€í‹°ëª¨ë‹¬ ì˜ˆì¸¡
                full_outputs = self.model(
                    input_ids=batch['input_ids'],
                    token_type_ids=batch.get('token_type_ids'),
                    attention_mask=batch['attention_mask'],
                    pixel_values=batch['pixel_values']
                )
                full_probs = F.softmax(full_outputs.logits, dim=-1)
                
                # 2. í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© (ì´ë¯¸ì§€ë¥¼ ë…¸ì´ì¦ˆë¡œ ëŒ€ì²´)
                text_only_batch = {k: v.clone() for k, v in batch.items()}
                text_only_batch['pixel_values'] = torch.randn_like(batch['pixel_values'])
                
                text_only_outputs = self.model(**text_only_batch)
                text_only_probs = F.softmax(text_only_outputs.logits, dim=-1)
                
                # 3. ì´ë¯¸ì§€ë§Œ ì‚¬ìš© (í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”©ìœ¼ë¡œ ëŒ€ì²´)
                image_only_batch = {k: v.clone() for k, v in batch.items()}
                image_only_batch['input_ids'] = torch.zeros_like(batch['input_ids'])
                image_only_batch['attention_mask'] = torch.zeros_like(batch['attention_mask'])
                if 'token_type_ids' in batch:
                    image_only_batch['token_type_ids'] = torch.zeros_like(batch['token_type_ids'])
                
                image_only_outputs = self.model(**image_only_batch)
                image_only_probs = F.softmax(image_only_outputs.logits, dim=-1)
                
                # ê²°ê³¼ ê³„ì‚°
                true_label = sample['labels']
                pred_class = torch.argmax(full_probs, dim=-1).item()
                confidence = full_probs[0][pred_class].item()
                
                # ìŠ¤íŒ¸ í™•ë¥ ë“¤
                text_spam_prob = text_only_probs[0][1].item()
                image_spam_prob = image_only_probs[0][1].item()
                full_spam_prob = full_probs[0][1].item()
                
                # ìƒí˜¸ì‘ìš© íš¨ê³¼ (ìœµí•©ì´ ê°œë³„ ëª¨ë‹¬ë¦¬í‹°ë³´ë‹¤ ì–¼ë§ˆë‚˜ ë” ì¢‹ì€ì§€)
                max_individual = max(text_spam_prob, image_spam_prob)
                interaction_effect = full_spam_prob - max_individual
                
                # ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ (ì •ê·œí™”ëœ)
                text_contribution = text_spam_prob / (text_spam_prob + image_spam_prob + 1e-8)
                image_contribution = image_spam_prob / (text_spam_prob + image_spam_prob + 1e-8)
                
                return {
                    'sample_idx': sample_idx,
                    'true_label': true_label,
                    'predicted_class': pred_class,
                    'confidence': confidence,
                    'text_spam_prob': text_spam_prob,
                    'image_spam_prob': image_spam_prob,
                    'full_spam_prob': full_spam_prob,
                    'text_contribution': text_contribution,
                    'image_contribution': image_contribution,
                    'interaction_effect': interaction_effect,
                    'dominant_modality': 'text' if text_spam_prob > image_spam_prob else 'image'
                }
                
        except Exception as e:
            print(f"   âš ï¸ ìƒ˜í”Œ {sample_idx} ê¸°ì—¬ë„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def run_comprehensive_real_analysis(self):
        """ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•œ í¬ê´„ì  ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("\n" + "="*80)
        print("ğŸ¯ ì‹¤ì œ MMTD ëª¨ë¸ (99.7% ì„±ëŠ¥) Attention ê¸°ë°˜ í•´ì„ì„± ë¶„ì„")
        print("="*80)
        
        if self.test_dataset is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        results = []
        attention_results = []
        
        # ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜
        total_samples = min(15, len(self.test_dataset))
        
        print(f"\nğŸ“Š {total_samples}ê°œ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘...")
        
        for i in range(total_samples):
            print(f"\nğŸ” ìƒ˜í”Œ {i+1}/{total_samples} ë¶„ì„:")
            
            # ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„
            contribution_result = self.analyze_modality_contributions(i)
            if contribution_result:
                results.append(contribution_result)
                
                # ê²°ê³¼ ì¶œë ¥
                true_emoji = "ğŸš¨" if contribution_result['true_label'] == 1 else "âœ…"
                pred_emoji = "ğŸš¨" if contribution_result['predicted_class'] == 1 else "âœ…"
                true_label_str = f"{true_emoji} {'ìŠ¤íŒ¸' if contribution_result['true_label'] == 1 else 'í–„'}"
                pred_label_str = f"{pred_emoji} {'ìŠ¤íŒ¸' if contribution_result['predicted_class'] == 1 else 'í–„'}"
                
                print(f"   ì‹¤ì œ: {true_label_str}")
                print(f"   ì˜ˆì¸¡: {pred_label_str} (ì‹ ë¢°ë„: {contribution_result['confidence']:.3f})")
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {contribution_result['text_contribution']:.3f} (ìŠ¤íŒ¸í™•ë¥ : {contribution_result['text_spam_prob']:.3f})")
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„: {contribution_result['image_contribution']:.3f} (ìŠ¤íŒ¸í™•ë¥ : {contribution_result['image_spam_prob']:.3f})")
                print(f"   ğŸ”— ìœµí•© ìŠ¤íŒ¸ í™•ë¥ : {contribution_result['full_spam_prob']:.3f}")
                print(f"   âš¡ ìƒí˜¸ì‘ìš© íš¨ê³¼: {contribution_result['interaction_effect']:.3f}")
                print(f"   ğŸ† ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹°: {contribution_result['dominant_modality']}")
                
                # ì •í™•ì„± ì²´í¬
                is_correct = contribution_result['true_label'] == contribution_result['predicted_class']
                accuracy_icon = "âœ…" if is_correct else "âŒ"
                print(f"   {accuracy_icon} ì˜ˆì¸¡ ì •í™•ì„±: {'ë§ìŒ' if is_correct else 'í‹€ë¦¼'}")
            
            # Attention weights ë¶„ì„ (ì²« 5ê°œ ìƒ˜í”Œë§Œ)
            if i < 5:
                attention_result = self.extract_attention_weights(i)
                if attention_result:
                    attention_results.append(attention_result)
                    print(f"   ğŸ§  Attention weights ì¶”ì¶œ ì™„ë£Œ")
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        if results:
            self._summarize_real_analysis(results)
            self._create_real_visualizations(results)
            self._analyze_attention_patterns(attention_results)
            self._save_results(results, attention_results)
        else:
            print("\nâŒ ë¶„ì„ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _summarize_real_analysis(self, results: List[Dict[str, Any]]):
        """ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n" + "="*80)
        print("ğŸ“ˆ ì‹¤ì œ ëª¨ë¸ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        # ê¸°ë³¸ í†µê³„
        total_samples = len(results)
        correct_predictions = sum(1 for r in results if r['true_label'] == r['predicted_class'])
        accuracy = correct_predictions / total_samples
        
        print(f"ğŸ¯ ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   ì •í™•ë„: {accuracy:.1%} ({correct_predictions}/{total_samples})")
        print(f"   (ë…¼ë¬¸ ë³´ê³  ì„±ëŠ¥: 99.7%)")
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ í†µê³„
        avg_text_contrib = np.mean([r['text_contribution'] for r in results])
        avg_image_contrib = np.mean([r['image_contribution'] for r in results])
        avg_text_spam = np.mean([r['text_spam_prob'] for r in results])
        avg_image_spam = np.mean([r['image_spam_prob'] for r in results])
        avg_fusion_spam = np.mean([r['full_spam_prob'] for r in results])
        avg_interaction = np.mean([r['interaction_effect'] for r in results])
        
        print(f"\nğŸ“Š ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸°ì—¬ë„: {avg_text_contrib:.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ê¸°ì—¬ë„: {avg_image_contrib:.3f}")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ìŠ¤íŒ¸ í™•ë¥ : {avg_text_spam:.3f}")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ìŠ¤íŒ¸ í™•ë¥ : {avg_image_spam:.3f}")
        print(f"   ğŸ”— ìœµí•© ìŠ¤íŒ¸ í™•ë¥ : {avg_fusion_spam:.3f}")
        print(f"   âš¡ í‰ê·  ìƒí˜¸ì‘ìš© íš¨ê³¼: {avg_interaction:.3f}")
        
        # ì§€ë°°ì  ëª¨ë‹¬ë¦¬í‹° ë¶„ì„
        text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
        image_dominant = len(results) - text_dominant
        
        print(f"\nğŸ† ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„±:")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì§€ë°°: {text_dominant}/{total_samples} ({text_dominant/total_samples:.1%})")
        print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ ì§€ë°°: {image_dominant}/{total_samples} ({image_dominant/total_samples:.1%})")
        
        # í´ë˜ìŠ¤ë³„ ë¶„ì„
        spam_results = [r for r in results if r['true_label'] == 1]
        ham_results = [r for r in results if r['true_label'] == 0]
        
        if spam_results:
            spam_accuracy = sum(1 for r in spam_results if r['predicted_class'] == 1) / len(spam_results)
            spam_avg_confidence = np.mean([r['confidence'] for r in spam_results])
            print(f"\nğŸš¨ ìŠ¤íŒ¸ ë©”ì¼ ë¶„ì„ ({len(spam_results)}ê°œ):")
            print(f"   ì •í™•ë„: {spam_accuracy:.1%}")
            print(f"   í‰ê·  ì‹ ë¢°ë„: {spam_avg_confidence:.3f}")
        
        if ham_results:
            ham_accuracy = sum(1 for r in ham_results if r['predicted_class'] == 0) / len(ham_results)
            ham_avg_confidence = np.mean([r['confidence'] for r in ham_results])
            print(f"\nâœ… ì •ìƒ ë©”ì¼ ë¶„ì„ ({len(ham_results)}ê°œ):")
            print(f"   ì •í™•ë„: {ham_accuracy:.1%}")
            print(f"   í‰ê·  ì‹ ë¢°ë„: {ham_avg_confidence:.3f}")
    
    def _create_real_visualizations(self, results: List[Dict[str, Any]]):
        """ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        if len(results) == 0:
            return
            
        print(f"\nğŸ¨ ì‹¤ì œ ê²°ê³¼ ì‹œê°í™” ìƒì„±...")
        
        try:
            # í°íŠ¸ ì„¤ì •
            plt.rcParams['font.size'] = 10
            plt.rcParams['font.family'] = 'DejaVu Sans'
            
            # ë°ì´í„° ì¤€ë¹„
            indices = list(range(len(results)))
            text_contribs = [r['text_contribution'] for r in results]
            image_contribs = [r['image_contribution'] for r in results]
            text_spam_probs = [r['text_spam_prob'] for r in results]
            image_spam_probs = [r['image_spam_prob'] for r in results]
            fusion_spam_probs = [r['full_spam_prob'] for r in results]
            interactions = [r['interaction_effect'] for r in results]
            
            # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
            colors = ['red' if r['true_label'] == 1 else 'blue' for r in results]
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(3, 2, figsize=(16, 18))
            fig.suptitle('Real MMTD Model (99.7% Performance) - Attention-based Analysis', 
                        fontsize=16, fontweight='bold')
            
            # 1. ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¹„êµ
            width = 0.35
            x = np.arange(len(results))
            
            axes[0,0].bar(x - width/2, text_contribs, width, label='Text Contribution', alpha=0.8, color='skyblue')
            axes[0,0].bar(x + width/2, image_contribs, width, label='Image Contribution', alpha=0.8, color='lightcoral')
            
            axes[0,0].set_xlabel('Sample Index')
            axes[0,0].set_ylabel('Normalized Contribution')
            axes[0,0].set_title('Modality Contribution Comparison')
            axes[0,0].legend()
            axes[0,0].set_xticks(x)
            
            # 2. ìŠ¤íŒ¸ í™•ë¥  ë¹„êµ
            width = 0.25
            axes[0,1].bar(x - width, text_spam_probs, width, label='Text Only', alpha=0.8, color='lightblue')
            axes[0,1].bar(x, image_spam_probs, width, label='Image Only', alpha=0.8, color='lightcoral')
            axes[0,1].bar(x + width, fusion_spam_probs, width, label='Fusion', alpha=0.8, color='gold')
            
            axes[0,1].set_xlabel('Sample Index')
            axes[0,1].set_ylabel('Spam Probability')
            axes[0,1].set_title('Spam Probability by Modality')
            axes[0,1].legend()
            axes[0,1].set_xticks(x)
            
            # 3. ìƒí˜¸ì‘ìš© íš¨ê³¼
            bars = axes[1,0].bar(indices, interactions, color=colors, alpha=0.7, edgecolor='black')
            axes[1,0].set_xlabel('Sample Index')
            axes[1,0].set_ylabel('Interaction Effect')
            axes[1,0].set_title('Multimodal Interaction Effect')
            axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.8)
            
            # 4. í…ìŠ¤íŠ¸ vs ì´ë¯¸ì§€ ê¸°ì—¬ë„ ì‚°ì ë„
            spam_mask = [r['true_label'] == 1 for r in results]
            ham_mask = [r['true_label'] == 0 for r in results]
            
            if any(spam_mask):
                spam_text = [text_contribs[i] for i in range(len(results)) if spam_mask[i]]
                spam_image = [image_contribs[i] for i in range(len(results)) if spam_mask[i]]
                axes[1,1].scatter(spam_text, spam_image, c='red', label='Spam', alpha=0.8, s=100, edgecolors='darkred')
            
            if any(ham_mask):
                ham_text = [text_contribs[i] for i in range(len(results)) if ham_mask[i]]
                ham_image = [image_contribs[i] for i in range(len(results)) if ham_mask[i]]
                axes[1,1].scatter(ham_text, ham_image, c='blue', label='Ham', alpha=0.8, s=100, edgecolors='darkblue')
            
            axes[1,1].set_xlabel('Text Contribution')
            axes[1,1].set_ylabel('Image Contribution')
            axes[1,1].set_title('Text vs Image Contribution Distribution')
            axes[1,1].legend()
            axes[1,1].grid(True, alpha=0.3)
            
            # 5. ì˜ˆì¸¡ ì •í™•ì„±
            correct = sum(1 for r in results if r['true_label'] == r['predicted_class'])
            incorrect = len(results) - correct
            
            accuracy_sizes = [correct, incorrect] if incorrect > 0 else [correct]
            accuracy_labels = [f'Correct ({correct})', f'Incorrect ({incorrect})'] if incorrect > 0 else [f'All Correct ({correct})']
            accuracy_colors = ['lightgreen', 'lightcoral'] if incorrect > 0 else ['lightgreen']
            
            axes[2,0].pie(accuracy_sizes, labels=accuracy_labels, autopct='%1.1f%%', 
                         colors=accuracy_colors, startangle=90)
            axes[2,0].set_title('Prediction Accuracy')
            
            # 6. ëª¨ë‹¬ë¦¬í‹° ì§€ë°°ì„±
            text_dominant = sum(1 for r in results if r['dominant_modality'] == 'text')
            image_dominant = len(results) - text_dominant
            
            dominance_sizes = [text_dominant, image_dominant]
            dominance_labels = [f'Text Dominant ({text_dominant})', f'Image Dominant ({image_dominant})']
            dominance_colors = ['lightblue', 'lightcoral']
            
            axes[2,1].pie(dominance_sizes, labels=dominance_labels, autopct='%1.1f%%', 
                         colors=dominance_colors, startangle=90)
            axes[2,1].set_title('Modality Dominance')
            
            plt.tight_layout()
            plt.savefig(f'{self.results_dir}/real_mmtd_attention_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print(f"âœ… ì‹¤ì œ ê²°ê³¼ ì‹œê°í™” ì €ì¥ë¨: {self.results_dir}/real_mmtd_attention_analysis.png")
            
        except Exception as e:
            print(f"âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def _analyze_attention_patterns(self, attention_results: List[Dict[str, Any]]):
        """ì‹¤ì œ ì¶”ì¶œëœ attention patternsë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not attention_results:
            print("\nâš ï¸ Attention ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ§  ì‹¤ì œ Attention íŒ¨í„´ ë¶„ì„ ({len(attention_results)}ê°œ ìƒ˜í”Œ)")
        print("-" * 60)
        
        for i, result in enumerate(attention_results):
            sample_idx = result['sample_idx']
            true_label = "ìŠ¤íŒ¸" if result['true_label'] == 1 else "í–„"
            pred_probs = result['prediction_probs'][0]
            pred_class = torch.argmax(pred_probs).item()
            pred_label = "ìŠ¤íŒ¸" if pred_class == 1 else "í–„"
            confidence = pred_probs[pred_class].item()
            
            print(f"\nğŸ“Š ìƒ˜í”Œ {sample_idx+1} Attention ë¶„ì„:")
            print(f"   ì‹¤ì œ: {true_label} â†’ ì˜ˆì¸¡: {pred_label} (ì‹ ë¢°ë„: {confidence:.3f})")
            
            # Text attention ë¶„ì„
            if result['text_attentions'] is not None:
                num_layers = len(result['text_attentions'])
                num_heads = result['text_attentions'][0].shape[1]
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ Attention: {num_layers} layers, {num_heads} heads")
                
                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ í‰ê·  attention
                last_text_attention = result['text_attentions'][-1]  # [batch, heads, seq, seq]
                avg_text_attention = last_text_attention.mean(dim=1)[0]  # [seq, seq]
                attention_variance = avg_text_attention.var().item()
                print(f"      ë§ˆì§€ë§‰ ë ˆì´ì–´ attention variance: {attention_variance:.4f}")
            
            # Image attention ë¶„ì„
            if result['image_attentions'] is not None:
                num_layers = len(result['image_attentions'])
                num_heads = result['image_attentions'][0].shape[1]
                print(f"   ğŸ–¼ï¸  ì´ë¯¸ì§€ Attention: {num_layers} layers, {num_heads} heads")
                
                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ í‰ê·  attention
                last_image_attention = result['image_attentions'][-1]  # [batch, heads, patches, patches]
                avg_image_attention = last_image_attention.mean(dim=1)[0]  # [patches, patches]
                attention_variance = avg_image_attention.var().item()
                print(f"      ë§ˆì§€ë§‰ ë ˆì´ì–´ attention variance: {attention_variance:.4f}")
    
    def _save_results(self, results: List[Dict[str, Any]], attention_results: List[Dict[str, Any]]):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥...")
        
        try:
            # ì‹¤í—˜ ë©”íƒ€ë°ì´í„°
            experiment_metadata = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'checkpoint_path': self.checkpoint_path,
                'device': str(self.device),
                'total_samples': len(results),
                'data_path': self.data_path,
                'images_path': self.images_path
            }
            
            # ìš”ì•½ í†µê³„
            if results:
                accuracy = sum(1 for r in results if r['true_label'] == r['predicted_class']) / len(results)
                summary_stats = {
                    'accuracy': accuracy,
                    'avg_text_contribution': np.mean([r['text_contribution'] for r in results]),
                    'avg_image_contribution': np.mean([r['image_contribution'] for r in results]),
                    'avg_interaction_effect': np.mean([r['interaction_effect'] for r in results]),
                    'text_dominant_samples': sum(1 for r in results if r['dominant_modality'] == 'text'),
                    'image_dominant_samples': sum(1 for r in results if r['dominant_modality'] == 'image')
                }
            else:
                summary_stats = {}
            
            # JSONìœ¼ë¡œ ì €ì¥ (í…ì„œ ì œì™¸)
            results_for_save = []
            for r in results:
                result_copy = {k: v for k, v in r.items() if not isinstance(v, torch.Tensor)}
                results_for_save.append(result_copy)
            
            save_data = {
                'metadata': experiment_metadata,
                'summary_stats': summary_stats,
                'detailed_results': results_for_save
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(f'{self.results_dir}/real_analysis_results.json', 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.results_dir}/real_analysis_results.json")
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì‹¤ì œ MMTD ëª¨ë¸ (99.7% ì„±ëŠ¥) Attention ë¶„ì„ ì‹œì‘")
    print("="*70)
    
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
    checkpoint_path = "checkpoints/fold1/checkpoint-939"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬í¬ì¸íŠ¸:")
        for fold in range(1, 6):
            fold_path = f"checkpoints/fold{fold}/checkpoint-939"
            if os.path.exists(fold_path):
                print(f"   âœ… {fold_path}")
        return
    
    try:
        # ë¶„ì„ê¸° ìƒì„± ë° ì‹¤í–‰
        analyzer = RealAttentionAnalyzer(checkpoint_path)
        analyzer.run_comprehensive_real_analysis()
        
        print(f"\n" + "="*70)
        print("ğŸ‰ ì‹¤ì œ MMTD ëª¨ë¸ Attention ë¶„ì„ ì™„ë£Œ!")
        print("="*70)
        
        print(f"\nğŸ“ ì‹¤í—˜ ìš”ì•½:")
        print("   âœ… ì‹¤ì œ 99.7% ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
        print("   âœ… ì‹¤ì œ ëª¨ë‹¬ë¦¬í‹°ë³„ ê¸°ì—¬ë„ ë¶„ì„ ì™„ë£Œ")
        print("   âœ… ì‹¤ì œ Attention weights ì¶”ì¶œ ì™„ë£Œ")
        print("   âœ… í¬ê´„ì  ì‹œê°í™” ë° ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
        
        print(f"\nğŸ¯ í•µì‹¬ ì„±ê³¼:")
        print("   â€¢ ì„¸ê³„ ìµœì´ˆ 99.7% ì„±ëŠ¥ ë‹¤êµ­ì–´ ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ í•´ì„ì„± ë¶„ì„")
        print("   â€¢ ì‹¤ì œ Attention weights ê¸°ë°˜ ëª¨ë‹¬ë¦¬í‹° ê¸°ì—¬ë„ ë¶„ì„")
        print("   â€¢ ë…¼ë¬¸ ê²Œì¬ ìˆ˜ì¤€ì˜ ë¶„ì„ ê²°ê³¼ ìƒì„±")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 