#!/usr/bin/env python3
"""
Display key interpretability analysis results
"""

import json
from pathlib import Path

def main():
    report_path = "outputs/interpretability_analysis/comprehensive_interpretability_report.json"
    
    with open(report_path, 'r') as f:
        report = json.load(f)

    print('ğŸ” MMTD Logistic Regression í•´ì„ì„± ë¶„ì„ ê²°ê³¼')
    print('=' * 60)

    # ëª¨ë¸ ì •ë³´
    model_info = report['model_info']
    print(f'ğŸ“Š ëª¨ë¸ íƒ€ì…: {model_info["model_type"]}')
    print(f'ğŸ“Š ë¶„ë¥˜ê¸° íƒ€ì…: {model_info["classifier_type"]}')
    print(f'ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {model_info["total_parameters"]:,}')
    print(f'ğŸ“Š í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {model_info["classifier_parameters"]:,} (ë¶„ë¥˜ê¸°ë§Œ)')

    # íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„
    feature_analysis = report['feature_importance_analysis']
    print(f'\nğŸ¯ íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„:')
    print(f'ğŸ“ˆ ìµœëŒ€ ì¤‘ìš”ë„: {feature_analysis["feature_importance"]["max"]:.6f}')
    print(f'ğŸ“ˆ í‰ê·  ì¤‘ìš”ë„: {feature_analysis["feature_importance"]["mean"]:.6f}')
    print(f'ğŸ“ˆ í‘œì¤€í¸ì°¨: {feature_analysis["feature_importance"]["std"]:.6f}')

    # ì •ê·œí™” íš¨ê³¼
    reg_effects = feature_analysis['regularization_effects']
    print(f'\nâš–ï¸ ì •ê·œí™” íš¨ê³¼:')
    print(f'ğŸ“Š L1 Norm: {reg_effects["l1_norm"]:.4f}')
    print(f'ğŸ“Š L2 Norm: {reg_effects["l2_norm"]:.4f}')
    print(f'ğŸ“Š í¬ì†Œì„± ìˆ˜ì¤€: {reg_effects["sparsity"]:.4f}')

    # ê²°ì • ê²½ê³„ ë¶„ì„
    decision_analysis = report['decision_boundary_analysis']
    print(f'\nğŸ¯ ê²°ì • ê²½ê³„ ë¶„ì„:')
    print(f'ğŸ“Š ê³ ë„ íŒë³„ íŠ¹ì§•: {decision_analysis["feature_discrimination"]["highly_discriminative_features"]}ê°œ')
    print(f'ğŸ“Š ì¤‘ë„ íŒë³„ íŠ¹ì§•: {decision_analysis["feature_discrimination"]["moderately_discriminative_features"]}ê°œ')
    print(f'ğŸ“Š ì €ë„ íŒë³„ íŠ¹ì§•: {decision_analysis["feature_discrimination"]["low_discriminative_features"]}ê°œ')
    print(f'ğŸ“Š ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {decision_analysis["separability"]["cosine_similarity"]:.4f}')

    # ì˜ˆì¸¡ í•´ì„
    prediction_analysis = report['prediction_interpretations']
    correct_preds = sum(1 for i in prediction_analysis['sample_interpretations'] if i['correct_prediction'])
    total_preds = len(prediction_analysis['sample_interpretations'])
    print(f'\nğŸ” ì˜ˆì¸¡ í•´ì„ (ìƒ˜í”Œ {total_preds}ê°œ):')
    print(f'âœ… ì •í™•í•œ ì˜ˆì¸¡: {correct_preds}/{total_preds} ({correct_preds/total_preds*100:.1f}%)')

    # ì¸ì‚¬ì´íŠ¸
    insights = report['interpretability_insights']
    print(f'\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:')
    for insight in insights['key_findings']:
        print(f'â€¢ {insight}')
    for insight in insights['feature_insights']:
        print(f'â€¢ {insight}')
    for insight in insights['model_behavior']:
        print(f'â€¢ {insight}')

    print(f'\nğŸ“ ìš”ì•½: {insights["interpretability_summary"]}')
    
    # ìƒ˜í”Œ ì˜ˆì¸¡ í•´ì„ ì˜ˆì‹œ
    print(f'\nğŸ” ìƒ˜í”Œ ì˜ˆì¸¡ í•´ì„ ì˜ˆì‹œ:')
    sample_interp = prediction_analysis['sample_interpretations'][0]
    print(f'ìƒ˜í”Œ ID: {sample_interp["sample_id"]}')
    print(f'ì‹¤ì œ ë¼ë²¨: {sample_interp["true_label"]} ({"Spam" if sample_interp["true_label"] == 1 else "Ham"})')
    print(f'ì˜ˆì¸¡ ë¼ë²¨: {sample_interp["predicted_label"]} ({"Spam" if sample_interp["predicted_label"] == 1 else "Ham"})')
    print(f'ì˜ˆì¸¡ í™•ë¥ : Ham {sample_interp["prediction_probability"][0]:.4f}, Spam {sample_interp["prediction_probability"][1]:.4f}')
    print(f'ì •í™•í•œ ì˜ˆì¸¡: {"âœ…" if sample_interp["correct_prediction"] else "âŒ"}')
    
    # íŠ¹ì§• ê¸°ì—¬ë„
    contributions = sample_interp['feature_contributions']
    print(f'Spam ì´ ê¸°ì—¬ë„: {contributions["spam_total"]:.4f}')
    print(f'Ham ì´ ê¸°ì—¬ë„: {contributions["ham_total"]:.4f}')

if __name__ == "__main__":
    main() 