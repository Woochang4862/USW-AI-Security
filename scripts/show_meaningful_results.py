#!/usr/bin/env python3
"""
ì˜ë¯¸ìˆëŠ” í•´ì„ì„± ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ìŠ¤í¬ë¦½íŠ¸
"""

import json
from pathlib import Path

def main():
    report_path = "outputs/meaningful_interpretability/meaningful_interpretability_report.json"
    
    with open(report_path, 'r') as f:
        report = json.load(f)

    print('ğŸ¯ ì˜ë¯¸ìˆëŠ” í•´ì„ì„± ë¶„ì„ ê²°ê³¼')
    print('=' * 50)

    # í…ìŠ¤íŠ¸ ì–´í…ì…˜ ë¶„ì„
    text_attention = report['attention_analysis']['text_attention']
    print(f'ğŸ“ í…ìŠ¤íŠ¸ ì–´í…ì…˜ í†µê³„:')
    print(f'â€¢ í‰ê·  ì–´í…ì…˜: {text_attention["attention_statistics"]["mean_attention"]:.6f}')
    print(f'â€¢ ìµœëŒ€ ì–´í…ì…˜: {text_attention["attention_statistics"]["max_attention"]:.6f}')
    print(f'â€¢ ì–´í…ì…˜ ì—”íŠ¸ë¡œí”¼: {text_attention["attention_statistics"]["attention_entropy"]:.4f}')

    print(f'\nğŸ”¥ ê°€ì¥ ì£¼ëª©ë°›ëŠ” í† í°ë“¤:')
    for i, (token, score) in enumerate(text_attention['top_attended_tokens'][:5]):
        if token:
            print(f'{i+1}. "{token}": {score:.6f}')

    # ì´ë¯¸ì§€ ì–´í…ì…˜ ë¶„ì„
    image_attention = report['attention_analysis']['image_attention']
    print(f'\nğŸ–¼ï¸ ì´ë¯¸ì§€ ì–´í…ì…˜ í†µê³„:')
    print(f'â€¢ í‰ê·  ì–´í…ì…˜: {image_attention["attention_statistics"]["mean_attention"]:.6f}')
    print(f'â€¢ ìµœëŒ€ ì–´í…ì…˜: {image_attention["attention_statistics"]["max_attention"]:.6f}')
    print(f'â€¢ ì–´í…ì…˜ ì§‘ì¤‘ë„: {image_attention["attention_statistics"]["attention_concentration"]:.6f}')

    # ëª¨ë‹¬ë¦¬í‹° ì¤‘ìš”ë„
    modality = report['modality_importance']
    print(f'\nâš–ï¸ ëª¨ë‹¬ë¦¬í‹° ì¤‘ìš”ë„ (50ìƒ˜í”Œ ë¶„ì„):')
    print(f'â€¢ í…ìŠ¤íŠ¸ë§Œ: {modality["text_only_accuracy"]:.4f} ({modality["text_only_accuracy"]*100:.1f}%)')
    print(f'â€¢ ì´ë¯¸ì§€ë§Œ: {modality["image_only_accuracy"]:.4f} ({modality["image_only_accuracy"]*100:.1f}%)')
    print(f'â€¢ ë©€í‹°ëª¨ë‹¬: {modality["multimodal_accuracy"]:.4f} ({modality["multimodal_accuracy"]*100:.1f}%)')
    print(f'â€¢ ì‹œë„ˆì§€ íš¨ê³¼: {modality["modality_contribution"]["synergy_effect"]:.4f}')

    # ê·¸ë˜ë””ì–¸íŠ¸ ì¤‘ìš”ë„ (fallback ì •ë³´)
    gradient = report['gradient_importance']
    if 'text_importance' in gradient:
        top_tokens = gradient['text_importance'].get('top_important_tokens', [])
        if top_tokens:
            print(f'\nğŸ“ˆ ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ ì¤‘ìš” í† í°ë“¤:')
            for i, (token, score) in enumerate(top_tokens[:3]):
                if token:
                    print(f'{i+1}. "{token}": {score:.6f}')

    # ì¸ì‚¬ì´íŠ¸
    insights = report['interpretability_insights']
    print(f'\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:')
    for insight in insights['attention_insights']:
        print(f'â€¢ {insight}')
    for insight in insights['modality_insights']:
        print(f'â€¢ {insight}')

    print(f'\nğŸ¯ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­:')
    for rec in insights['actionable_recommendations']:
        print(f'â€¢ {rec}')

    # ìƒ˜í”Œ ì •ë³´
    sample_info = report['attention_analysis']['sample_info']
    print(f'\nğŸ“Š ë¶„ì„ ëŒ€ìƒ ìƒ˜í”Œ:')
    print(f'â€¢ ë¼ë²¨: {sample_info["label"]} ({"Spam" if sample_info["label"] == 1 else "Ham"})')
    print(f'â€¢ í† í° ìˆ˜: {len([t for t in sample_info["tokens"] if t not in ["[CLS]", "[SEP]", "[PAD]"]])}ê°œ')
    
    # ì‹¤ì œ í† í°ë“¤ ì¤‘ ì˜ë¯¸ìˆëŠ” ê²ƒë“¤ í‘œì‹œ
    meaningful_tokens = [t for t in sample_info["tokens"] if t not in ["[CLS]", "[SEP]", "[PAD]"] and t is not None][:10]
    print(f'â€¢ ì£¼ìš” í† í°ë“¤: {", ".join(meaningful_tokens)}')

if __name__ == "__main__":
    main() 