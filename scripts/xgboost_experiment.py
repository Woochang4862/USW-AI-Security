#!/usr/bin/env python3
"""
XGBoostë¥¼ ì´ìš©í•œ í•´ì„ê°€ëŠ¥í•œ MMTD ì‹¤í—˜
Gradient Boostingì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ë¶„ë¥˜ì™€ SHAP ê¸°ë°˜ í•´ì„ì„±
"""

import os
import sys
import torch
import time
import json
import logging
from datetime import datetime
from pathlib import Path

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from models.interpretable_mmtd import create_interpretable_mmtd
from models.mmtd_data_loader import create_mmtd_data_module

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class XGBoostExperimentRunner:
    """XGBoost ê¸°ë°˜ í•´ì„ê°€ëŠ¥í•œ MMTD ì‹¤í—˜"""
    
    def __init__(self, output_dir: str = None):
        self.device = torch.device("mps" if torch.backends.mps.is_available() 
                                  else "cuda" if torch.cuda.is_available() 
                                  else "cpu")
        
        # Create timestamped output directory
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = output_dir or f"outputs/xgboost_{timestamp}"
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸš€ XGBoost í•´ì„ê°€ëŠ¥í•œ MMTD ì‹¤í—˜ ì‹œì‘")
        logger.info(f"ğŸ’» Device: {self.device}")
        logger.info(f"ğŸ“ Output: {self.output_dir}")
    
    def create_xgboost_model(self):
        """XGBoost ê¸°ë°˜ ëª¨ë¸ ìƒì„±"""
        logger.info("ğŸš€ XGBoost ëª¨ë¸ ìƒì„± ì¤‘...")
        
        # Create model with XGBoost classifier
        model = create_interpretable_mmtd(
            classifier_type="xgboost",
            classifier_config={
                'max_depth': 6,              # íŠ¸ë¦¬ ê¹Šì´ (ê³¼ì í•© ë°©ì§€)
                'learning_rate': 0.1,        # í•™ìŠµë¥  
                'n_estimators': 100,         # íŠ¸ë¦¬ ê°œìˆ˜
                'subsample': 0.8,            # ìƒ˜í”Œ ì„œë¸Œìƒ˜í”Œë§
                'colsample_bytree': 0.8,     # í”¼ì²˜ ì„œë¸Œìƒ˜í”Œë§
                'reg_alpha': 0.1,            # L1 ì •ê·œí™”
                'reg_lambda': 1.0,           # L2 ì •ê·œí™”
                'random_state': 42           # ì¬í˜„ì„±
            },
            device=self.device,
            checkpoint_path="MMTD/checkpoints/fold1/checkpoint-939/pytorch_model.bin"
        )
        
        logger.info(f"âœ… XGBoost ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
        
        return model, model.get_model_summary()
    
    def prepare_data(self):
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("ğŸ“š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        
        data_module = create_mmtd_data_module(
            csv_path="MMTD/DATA/email_data/EDP.csv",
            data_path="MMTD/DATA/email_data/pics",
            batch_size=32,      # XGBoostëŠ” ì ë‹¹í•œ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
            max_samples=None,   # ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
            num_workers=4,
            test_split=0.2,
            val_split=0.1
        )
        
        logger.info("âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ")
        logger.info(f"ğŸ“Š í›ˆë ¨ ìƒ˜í”Œ: {len(data_module.train_dataset):,}")
        logger.info(f"ğŸ“Š ê²€ì¦ ìƒ˜í”Œ: {len(data_module.val_dataset):,}")
        logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(data_module.test_dataset):,}")
        
        return data_module
    
    def run_xgboost_training(self):
        """XGBoost í›ˆë ¨ ì‹¤í–‰"""
        logger.info("ğŸš€ XGBoost í›ˆë ¨ ì‹œì‘")
        
        # Create model and data
        model, model_summary = self.create_xgboost_model()
        data_module = self.prepare_data()
        
        # XGBoost ì „ìš© í›ˆë ¨: 2ë‹¨ê³„ ì ‘ê·¼ë²•
        # 1ë‹¨ê³„: íŠ¹ì„± ì¶”ì¶œ ë° XGBoost í›ˆë ¨
        # 2ë‹¨ê³„: ì„±ëŠ¥ í‰ê°€ ë° í•´ì„ì„± ë¶„ì„
        
        logger.info("ğŸ”„ 1ë‹¨ê³„: XGBoost ë°ì´í„° ìˆ˜ì§‘ ë° í›ˆë ¨")
        
        # Freeze backbone for feature extraction
        model.eval()
        for name, param in model.named_parameters():
            if 'interpretable_classifier' not in name:
                param.requires_grad = False
        
        # í›ˆë ¨ ì„¤ì •
        num_epochs = 3  # XGBoostëŠ” ë¹ ë¥¸ ë°ì´í„° ìˆ˜ì§‘ë§Œ í•„ìš”
        training_history = []
        
        start_time = time.time()
        
        # ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ XGBoost í›ˆë ¨
        train_loader = data_module.train_dataloader()
        
        for epoch in range(num_epochs):
            logger.info(f"ğŸ“š ì—í¬í¬ {epoch + 1}/{num_epochs} - ë°ì´í„° ìˆ˜ì§‘ ë° XGBoost í›ˆë ¨")
            
            train_correct = 0
            train_total = 0
            
            for batch_idx, batch in enumerate(train_loader):
                # Move to device
                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                # Extract features only (no gradient computation)
                with torch.no_grad():
                    features = model.extract_features(
                        input_ids=batch['input_ids'],
                        attention_mask=batch['attention_mask'],
                        pixel_values=batch['pixel_values']
                    )
                
                # Train XGBoost incrementally
                model.interpretable_classifier.fit_incremental(features, batch['labels'])
                
                # Get predictions after fitting
                with torch.no_grad():
                    logits = model.interpretable_classifier(features)
                    predictions = torch.argmax(logits, dim=1)
                    train_correct += (predictions == batch['labels']).sum().item()
                    train_total += batch['labels'].size(0)
                
                # ë¡œê¹…
                if batch_idx % 80 == 0:
                    current_acc = train_correct / train_total if train_total > 0 else 0
                    logger.info(f"  ë°°ì¹˜ {batch_idx}: ì •í™•ë„ {current_acc:.4f}")
            
            # Validation phase
            logger.info("ğŸ” ê²€ì¦ ë‹¨ê³„")
            val_correct = 0
            val_total = 0
            
            val_loader = data_module.val_dataloader()
            with torch.no_grad():
                for batch in val_loader:
                    batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                            for k, v in batch.items()}
                    
                    # Extract features
                    features = model.extract_features(
                        input_ids=batch['input_ids'],
                        attention_mask=batch['attention_mask'],
                        pixel_values=batch['pixel_values']
                    )
                    
                    # Get predictions
                    logits = model.interpretable_classifier(features)
                    predictions = torch.argmax(logits, dim=1)
                    val_correct += (predictions == batch['labels']).sum().item()
                    val_total += batch['labels'].size(0)
            
            # Calculate metrics
            train_accuracy = train_correct / train_total
            val_accuracy = val_correct / val_total
            
            # Log results
            epoch_results = {
                'epoch': epoch + 1,
                'train_loss': 0.0,  # XGBoost doesn't use loss
                'train_accuracy': train_accuracy,
                'val_loss': 0.0,    # XGBoost doesn't use loss
                'val_accuracy': val_accuracy,
                'learning_rate': 0.0  # No gradient-based learning
            }
            training_history.append(epoch_results)
            
            logger.info(f"  í›ˆë ¨ ì •í™•ë„: {train_accuracy:.4f}, ê²€ì¦ ì •í™•ë„: {val_accuracy:.4f}")
            
            # XGBoostëŠ” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ì¼ì° ì¢…ë£Œ ê°€ëŠ¥
            if epoch >= 1 and val_accuracy > 0.85:  # ê¸°ë³¸ ì„±ëŠ¥ì´ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                logger.info(f"âœ… XGBoost ì¶©ë¶„íˆ í›ˆë ¨ë¨ (ê²€ì¦ ì •í™•ë„: {val_accuracy:.4f})")
                break
        
        training_time = time.time() - start_time
        
        # Final validation
        best_val_accuracy = val_accuracy
        
        # 2ë‹¨ê³„: ìµœì¢… ì„±ëŠ¥ ê²€ì¦
        logger.info("ğŸ”„ 2ë‹¨ê³„: ìµœì¢… XGBoost ì„±ëŠ¥ ê²€ì¦")
        
        final_val_correct = 0
        final_val_total = 0
        
        val_loader = data_module.val_dataloader()
        with torch.no_grad():
            for batch in val_loader:
                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                # Extract features
                features = model.extract_features(
                    input_ids=batch['input_ids'],
                    attention_mask=batch['attention_mask'],
                    pixel_values=batch['pixel_values']
                )
                
                # Get predictions
                logits = model.interpretable_classifier(features)
                predictions = torch.argmax(logits, dim=1)
                final_val_correct += (predictions == batch['labels']).sum().item()
                final_val_total += batch['labels'].size(0)
        
        final_val_accuracy = final_val_correct / final_val_total
        best_val_accuracy = max(best_val_accuracy, final_val_accuracy)
        
        training_results = {
            'training_history': training_history,
            'best_val_accuracy': best_val_accuracy,
            'final_val_accuracy': final_val_accuracy,
            'total_training_time': training_time,
            'epochs_trained': epoch + 1,
            'early_stopped': False,
            'backbone_parameters': 0,  # Backboneì€ freezeë¨
            'xgboost_fitted': hasattr(model.interpretable_classifier, 'is_fitted') and model.interpretable_classifier.is_fitted,
            'training_method': 'feature_extraction_and_xgboost_fitting'
        }
        
        logger.info(f"â±ï¸ í›ˆë ¨ ì™„ë£Œ: {training_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“ˆ ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_accuracy:.4f}")
        logger.info(f"ğŸ“Š ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_val_accuracy:.4f}")
        logger.info(f"ğŸš€ XGBoost í”¼íŒ… ìƒíƒœ: {training_results['xgboost_fitted']}")
        
        return model, training_results, model_summary
    
    def run_comprehensive_evaluation(self, model, data_module):
        """í¬ê´„ì  í‰ê°€ ì‹¤í–‰"""
        logger.info("ğŸ“Š í¬ê´„ì  í‰ê°€ ì‹œì‘")
        
        # Test evaluation
        model.eval()
        test_loss = 0.0
        test_correct = 0
        test_total = 0
        all_predictions = []
        all_labels = []
        all_probabilities = []
        
        test_loader = data_module.test_dataloader()
        with torch.no_grad():
            for batch_idx, batch in enumerate(test_loader):
                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                outputs = model(**batch)
                loss = outputs.loss
                
                test_loss += loss.item()
                predictions = torch.argmax(outputs.logits, dim=1)
                test_correct += (predictions == batch['labels']).sum().item()
                test_total += batch['labels'].size(0)
                
                # Get probabilities
                probs = torch.softmax(outputs.logits, dim=1)
                all_probabilities.extend(probs.cpu().numpy())
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(batch['labels'].cpu().numpy())
                
                if batch_idx % 40 == 0:
                    logger.info(f"  í‰ê°€ ë°°ì¹˜ {batch_idx} ì™„ë£Œ")
        
        # Calculate comprehensive metrics
        from sklearn.metrics import (
            precision_recall_fscore_support, confusion_matrix, 
            roc_auc_score, classification_report
        )
        import numpy as np
        
        accuracy = test_correct / test_total
        avg_loss = test_loss / len(test_loader)
        
        # Get probabilities for class 1 (spam)
        probs_class1 = np.array(all_probabilities)[:, 1]
        
        precision, recall, f1_score, _ = precision_recall_fscore_support(
            all_labels, all_predictions, average='weighted'
        )
        
        auc_score = roc_auc_score(all_labels, probs_class1)
        
        test_results = {
            'accuracy': accuracy,
            'loss': avg_loss,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'auc_score': auc_score,
            'confusion_matrix': confusion_matrix(all_labels, all_predictions).tolist(),
            'classification_report': classification_report(all_labels, all_predictions, output_dict=True)
        }
        
        logger.info(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}")
        logger.info(f"ğŸ“‰ í…ŒìŠ¤íŠ¸ ì†ì‹¤: {avg_loss:.4f}")
        logger.info(f"ğŸ” F1 ìŠ¤ì½”ì–´: {f1_score:.4f}")
        logger.info(f"ğŸ“ˆ AUC ìŠ¤ì½”ì–´: {auc_score:.4f}")
        
        return test_results
    
    def analyze_xgboost_interpretability(self, model, data_module):
        """XGBoost í•´ì„ì„± ë¶„ì„"""
        logger.info("ğŸš€ XGBoost í•´ì„ì„± ë¶„ì„ ì‹œì‘")
        
        try:
            # Get XGBoost specific interpretability
            interpretability_results = {}
            
            # 1. Tree information
            tree_info = model.get_tree_info()
            interpretability_results['tree_info'] = tree_info
            logger.info(f"ğŸŒ³ XGBoost Trees: {tree_info.get('n_estimators', 0)}")
            
            # 2. Multiple feature importance types
            importance_types = ['gain', 'weight', 'cover']
            feature_importances = {}
            
            for importance_type in importance_types:
                try:
                    importance = model.get_xgboost_importance(importance_type=importance_type)
                    if importance.sum() > 0:
                        importance_stats = {
                            'mean_importance': float(torch.mean(importance)),
                            'max_importance': float(torch.max(importance)),
                            'std_importance': float(torch.std(importance)),
                            'top_10_features': torch.topk(importance, k=10).indices.tolist(),
                            'top_10_values': torch.topk(importance, k=10).values.tolist()
                        }
                        feature_importances[importance_type] = importance_stats
                        logger.info(f"ğŸ“ˆ {importance_type} importance ë¶„ì„ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"Failed to get {importance_type} importance: {e}")
            
            interpretability_results['feature_importances'] = feature_importances
            
            # 3. SHAP values analysis (ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œ)
            logger.info("ğŸ” SHAP ê°’ ë¶„ì„ ì¤‘...")
            try:
                # Get a small sample for SHAP analysis
                val_loader = data_module.val_dataloader()
                sample_batch = next(iter(val_loader))
                sample_batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                               for k, v in sample_batch.items()}
                
                # Limit to 50 samples for computational efficiency
                sample_size = min(50, sample_batch['input_ids'].shape[0])
                sample_input_ids = sample_batch['input_ids'][:sample_size]
                sample_attention_mask = sample_batch['attention_mask'][:sample_size]
                sample_pixel_values = sample_batch['pixel_values'][:sample_size]
                
                shap_values = model.get_shap_values(
                    sample_input_ids, 
                    sample_attention_mask, 
                    sample_pixel_values, 
                    max_samples=sample_size
                )
                
                if shap_values is not None:
                    shap_stats = {
                        'shap_shape': list(shap_values.shape),
                        'mean_abs_shap': float(np.mean(np.abs(shap_values))),
                        'max_abs_shap': float(np.max(np.abs(shap_values))),
                        'samples_analyzed': sample_size,
                        'features_analyzed': shap_values.shape[1] if len(shap_values.shape) > 1 else 0
                    }
                    interpretability_results['shap_analysis'] = shap_stats
                    logger.info(f"ğŸ¯ SHAP ê°’ ë¶„ì„ ì™„ë£Œ: {sample_size}ê°œ ìƒ˜í”Œ, {shap_stats['features_analyzed']}ê°œ í”¼ì²˜")
                else:
                    logger.warning("SHAP ê°’ ê³„ì‚° ì‹¤íŒ¨")
                    interpretability_results['shap_analysis'] = None
                    
            except Exception as e:
                logger.warning(f"SHAP ë¶„ì„ ì‹¤íŒ¨: {e}")
                interpretability_results['shap_analysis'] = None
            
            logger.info("âœ… XGBoost í•´ì„ì„± ë¶„ì„ ì™„ë£Œ")
            return interpretability_results
            
        except Exception as e:
            logger.warning(f"âš ï¸ í•´ì„ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def run_full_xgboost_experiment(self):
        """ì „ì²´ XGBoost ì‹¤í—˜ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ XGBoost ì „ì²´ ì‹¤í—˜ ì‹œì‘")
            
            # 1. Training
            trained_model, training_results, model_summary = self.run_xgboost_training()
            
            # 2. Data preparation for evaluation  
            data_module = self.prepare_data()
            
            # 3. Comprehensive evaluation
            test_results = self.run_comprehensive_evaluation(trained_model, data_module)
            
            # 4. XGBoost specific interpretability analysis
            interpretability_analysis = self.analyze_xgboost_interpretability(trained_model, data_module)
            
            # 5. Save results
            final_results = {
                'experiment_info': {
                    'timestamp': datetime.now().isoformat(),
                    'device': str(self.device),
                    'model_type': 'InterpretableMMTD_XGBoost',
                    'classifier_type': 'xgboost',
                    'note': 'XGBoost experiment for high-performance gradient boosting with SHAP interpretability',
                    'advantages': [
                        'High performance gradient boosting',
                        'Multiple feature importance types (gain, weight, cover)',
                        'SHAP values for instance-level explanations',
                        'Tree structure visualization',
                        'Built-in regularization (L1/L2)',
                        'Handle missing values automatically',
                        'Parallel training',
                        'Early stopping support',
                        'Robust to outliers',
                        'Feature selection via importance',
                        'Cross-validation built-in'
                    ]
                },
                'model_summary': model_summary,
                'training_results': training_results,
                'test_results': test_results,
                'interpretability_analysis': interpretability_analysis
            }
            
            # Save results
            results_path = os.path.join(self.output_dir, "xgboost_results.json")
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(final_results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_path}")
            
            # Print summary
            self.print_xgboost_summary(final_results)
            
            logger.info("âœ… XGBoost ì‹¤í—˜ ì™„ë£Œ!")
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ XGBoost ì‹¤í—˜ ì‹¤íŒ¨: {e}")
            raise
    
    def print_xgboost_summary(self, results):
        """XGBoost ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸš€ XGBoost í•´ì„ê°€ëŠ¥í•œ MMTD ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼")
        print("="*70)
        
        # Advantages
        advantages = results['experiment_info']['advantages']
        print("âœ¨ XGBoostì˜ ì¥ì :")
        for advantage in advantages:
            print(f"  ğŸŒŸ {advantage}")
        
        # Performance results
        test_results = results['test_results']
        print(f"\nğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
        print(f"  ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_results['accuracy']:.4f}")
        print(f"  ğŸ” F1 ìŠ¤ì½”ì–´: {test_results['f1_score']:.4f}")
        print(f"  ğŸ“ˆ AUC ìŠ¤ì½”ì–´: {test_results['auc_score']:.4f}")
        print(f"  ğŸ“‰ í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_results['loss']:.4f}")
        
        # Training info
        training_results = results['training_results']
        print(f"\nğŸ“ˆ í›ˆë ¨ ì •ë³´:")
        print(f"  ğŸ“Š ìµœê³  ê²€ì¦ ì •í™•ë„: {training_results['best_val_accuracy']:.4f}")
        print(f"  â±ï¸ í›ˆë ¨ ì‹œê°„: {training_results['total_training_time']:.1f}ì´ˆ")
        print(f"  ğŸ”„ ì—í¬í¬ ìˆ˜: {training_results['epochs_trained']}")
        
        # XGBoost-specific interpretability info
        if 'interpretability_analysis' in results and results['interpretability_analysis']:
            analysis = results['interpretability_analysis']
            print(f"\nğŸš€ XGBoost í•´ì„ì„± ë¶„ì„:")
            
            if 'tree_info' in analysis:
                tree_info = analysis['tree_info']
                print(f"  ğŸŒ³ Estimator ìˆ˜: {tree_info.get('n_estimators', 'N/A')}")
                print(f"  ğŸŒ² ìµœëŒ€ ê¹Šì´: {tree_info.get('max_depth', 'N/A')}")
                print(f"  ğŸ“ í•™ìŠµë¥ : {tree_info.get('learning_rate', 'N/A')}")
            
            if 'feature_importances' in analysis:
                importances = analysis['feature_importances']
                print(f"  ğŸ“ˆ Feature importance íƒ€ì…: {list(importances.keys())}")
                for imp_type, stats in importances.items():
                    print(f"    {imp_type}: í‰ê·  {stats['mean_importance']:.6f}, ìµœëŒ€ {stats['max_importance']:.6f}")
            
            if 'shap_analysis' in analysis and analysis['shap_analysis']:
                shap_info = analysis['shap_analysis']
                print(f"  ğŸ¯ SHAP ë¶„ì„:")
                print(f"    ë¶„ì„ ìƒ˜í”Œ ìˆ˜: {shap_info['samples_analyzed']}")
                print(f"    ë¶„ì„ í”¼ì²˜ ìˆ˜: {shap_info['features_analyzed']}")
                print(f"    í‰ê·  SHAP ê°’: {shap_info['mean_abs_shap']:.6f}")
        
        # Model info
        model_info = results['model_summary']
        print(f"\nğŸ§  ëª¨ë¸ ì •ë³´:")
        print(f"  ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {model_info['total_parameters']:,}")
        print(f"  ğŸš€ ë¶„ë¥˜ê¸° íŒŒë¼ë¯¸í„°: {model_info['classifier_parameters']:,}")
        
        print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼: {self.output_dir}")
        print("="*70)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    runner = XGBoostExperimentRunner()
    results = runner.run_full_xgboost_experiment()
    return results


if __name__ == "__main__":
    results = main() 