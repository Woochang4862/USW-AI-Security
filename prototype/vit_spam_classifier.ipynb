{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "# ì´ë¯¸ì§€ ê¸°ë°˜ ìŠ¤íŒ¸ íƒì§€ë¥¼ ìœ„í•œ ViT Fine-tuning ğŸ”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Vision Transformer (ViT)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê¸°ë°˜ ìŠ¤íŒ¸ì„ íƒì§€í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ë°ì´í„°ì…‹\n",
    "- Kaggle Spam Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers scikit-learn pandas numpy pillow tqdm kagglehub\n",
    "!nvidia-smi  # GPU í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "dataset_path = kagglehub.dataset_download(\"asifjamal123/spam-image-dataset\")\n",
    "print(\"Dataset path:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        \n",
    "        # ìŠ¤íŒ¸ ì´ë¯¸ì§€ ë¡œë“œ (label=1)\n",
    "        spam_dir = os.path.join(image_dir, 'spam')\n",
    "        for img_name in os.listdir(spam_dir):\n",
    "            if img_name.lower().endswith(self.valid_extensions):\n",
    "                img_path = os.path.join(spam_dir, img_name)\n",
    "                try:\n",
    "                    # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img.verify()\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
    "        \n",
    "        # ì •ìƒ ì´ë¯¸ì§€ ë¡œë“œ (label=0)\n",
    "        ham_dir = os.path.join(image_dir, 'ham')\n",
    "        for img_name in os.listdir(ham_dir):\n",
    "            if img_name.lower().endswith(self.valid_extensions):\n",
    "                img_path = os.path.join(ham_dir, img_name)\n",
    "                try:\n",
    "                    # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img.verify()\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
    "        \n",
    "        print(f\"Successfully loaded {len(self.images)} valid images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path} at runtime: {str(e)}\")\n",
    "            # ì—ëŸ¬ ë°œìƒ ì‹œ ëŒ€ì²´ ì´ë¯¸ì§€ ë°˜í™˜ (ê²€ì€ìƒ‰ ì´ë¯¸ì§€)\n",
    "            if self.transform:\n",
    "                return torch.zeros((3, 224, 224)), self.labels[idx]\n",
    "            return Image.new('RGB', (224, 224), 'black'), self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ViT ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTSpamClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.vit = ViTForImageClassification.from_pretrained(\n",
    "            'google/vit-base-patch16-224',\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.vit(pixel_values)\n",
    "        return outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. í•™ìŠµ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# ë°ì´í„° ë³€í™˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "dataset = SpamImageDataset(dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTSpamClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Train Metrics - Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Rec: {train_rec:.4f}, F1: {train_f1:.4f}')\n",
    "    \n",
    "    # ê²€ì¦\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    print(f'Val Loss: {val_loss:.4f}')\n",
    "    print(f'Val Metrics - Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, Rec: {val_rec:.4f}, F1: {val_f1:.4f}')\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_vit_spam_classifier.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ í‰ê°€ ë° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
    "best_model = ViTSpamClassifier().to(device)\n",
    "best_model.load_state_dict(torch.load('best_vit_spam_classifier.pth'))\n",
    "\n",
    "# ì „ì²´ ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ìƒì„¸ í‰ê°€\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1 = validate(best_model, val_loader, criterion, device)\n",
    "\n",
    "print('\\nFinal Evaluation Results:')\n",
    "print(f'Accuracy: {val_acc:.4f}')\n",
    "print(f'Precision: {val_prec:.4f}')\n",
    "print(f'Recall: {val_rec:.4f}')\n",
    "print(f'F1-Score: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (ì˜ˆ: íŠ¹ì • ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€)\n",
    "test_dir = \"/content/images/\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”\n",
    "image_paths = []\n",
    "for ext in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "    image_paths.extend(glob.glob(os.path.join(test_dir, f'*{ext}')))\n",
    "    image_paths.extend(glob.glob(os.path.join(test_dir, f'*{ext.upper()}')))\n",
    "\n",
    "if not image_paths:\n",
    "    print(\"í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    results = predict_images(best_model, image_paths, device)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'íŒŒì¼ëª…':<40} {'ì •ìƒ í™•ë¥ ':>10} {'ìŠ¤íŒ¸ í™•ë¥ ':>10} {'íŒì •':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"{result['filename']:<40} {result['normal_prob']:>10.4f} {result['spam_prob']:>10.4f} {result['prediction']:>10}\")\n",
    "    \n",
    "    # í†µê³„ ì¶œë ¥\n",
    "    spam_count = sum(1 for r in results if r['prediction'] == 'ìŠ¤íŒ¸')\n",
    "    normal_count = len(results) - spam_count\n",
    "    \n",
    "    print(\"\\ní†µê³„:\")\n",
    "    print(f\"ì „ì²´ ì´ë¯¸ì§€: {len(results)}ê°œ\")\n",
    "    print(f\"ì •ìƒ ì´ë¯¸ì§€: {normal_count}ê°œ ({normal_count/len(results)*100:.1f}%)\")\n",
    "    print(f\"ìŠ¤íŒ¸ ì´ë¯¸ì§€: {spam_count}ê°œ ({spam_count/len(results)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vit_spam_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
