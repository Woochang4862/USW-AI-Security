{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "# 이미지 기반 스팸 탐지를 위한 ViT Fine-tuning 🔍\n",
    "\n",
    "이 노트북은 Vision Transformer (ViT)를 사용하여 이미지 기반 스팸을 탐지하는 모델을 구현합니다.\n",
    "\n",
    "## 데이터셋\n",
    "- Kaggle Spam Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers scikit-learn pandas numpy pillow tqdm kagglehub\n",
    "!nvidia-smi  # GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 다운로드 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle 데이터셋 다운로드\n",
    "dataset_path = kagglehub.dataset_download(\"asifjamal123/spam-image-dataset\")\n",
    "print(\"Dataset path:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        \n",
    "        # 스팸 이미지 로드 (label=1)\n",
    "        spam_dir = os.path.join(image_dir, 'spam')\n",
    "        for img_name in os.listdir(spam_dir):\n",
    "            if img_name.lower().endswith(self.valid_extensions):\n",
    "                img_path = os.path.join(spam_dir, img_name)\n",
    "                try:\n",
    "                    # 이미지 유효성 검사\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img.verify()\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
    "        \n",
    "        # 정상 이미지 로드 (label=0)\n",
    "        ham_dir = os.path.join(image_dir, 'ham')\n",
    "        for img_name in os.listdir(ham_dir):\n",
    "            if img_name.lower().endswith(self.valid_extensions):\n",
    "                img_path = os.path.join(ham_dir, img_name)\n",
    "                try:\n",
    "                    # 이미지 유효성 검사\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img.verify()\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
    "        \n",
    "        print(f\"Successfully loaded {len(self.images)} valid images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path} at runtime: {str(e)}\")\n",
    "            # 에러 발생 시 대체 이미지 반환 (검은색 이미지)\n",
    "            if self.transform:\n",
    "                return torch.zeros((3, 224, 224)), self.labels[idx]\n",
    "            return Image.new('RGB', (224, 224), 'black'), self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ViT 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTSpamClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.vit = ViTForImageClassification.from_pretrained(\n",
    "            'google/vit-base-patch16-224',\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.vit(pixel_values)\n",
    "        return outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# 데이터 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = SpamImageDataset(dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ViTSpamClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 학습 루프\n",
    "best_val_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    # 학습\n",
    "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Train Metrics - Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Rec: {train_rec:.4f}, F1: {train_f1:.4f}')\n",
    "    \n",
    "    # 검증\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    print(f'Val Loss: {val_loss:.4f}')\n",
    "    print(f'Val Metrics - Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, Rec: {val_rec:.4f}, F1: {val_f1:.4f}')\n",
    "    \n",
    "    # 최고 성능 모델 저장\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_vit_spam_classifier.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 평가 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 로드\n",
    "best_model = ViTSpamClassifier().to(device)\n",
    "best_model.load_state_dict(torch.load('best_vit_spam_classifier.pth'))\n",
    "\n",
    "# 전체 검증 세트에 대한 상세 평가\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1 = validate(best_model, val_loader, criterion, device)\n",
    "\n",
    "print('\\nFinal Evaluation Results:')\n",
    "print(f'Accuracy: {val_acc:.4f}')\n",
    "print(f'Precision: {val_prec:.4f}')\n",
    "print(f'Recall: {val_rec:.4f}')\n",
    "print(f'F1-Score: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트할 이미지 경로 설정 (예: 특정 디렉토리의 모든 이미지)\n",
    "test_dir = \"/content/images/\"  # 테스트할 이미지가 있는 디렉토리 경로로 변경해주세요\n",
    "image_paths = []\n",
    "for ext in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "    image_paths.extend(glob.glob(os.path.join(test_dir, f'*{ext}')))\n",
    "    image_paths.extend(glob.glob(os.path.join(test_dir, f'*{ext.upper()}')))\n",
    "\n",
    "if not image_paths:\n",
    "    print(\"테스트할 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"총 {len(image_paths)}개의 이미지를 처리합니다.\")\n",
    "    \n",
    "    # 이미지 예측 수행\n",
    "    results = predict_images(best_model, image_paths, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n예측 결과:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'파일명':<40} {'정상 확률':>10} {'스팸 확률':>10} {'판정':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"{result['filename']:<40} {result['normal_prob']:>10.4f} {result['spam_prob']:>10.4f} {result['prediction']:>10}\")\n",
    "    \n",
    "    # 통계 출력\n",
    "    spam_count = sum(1 for r in results if r['prediction'] == '스팸')\n",
    "    normal_count = len(results) - spam_count\n",
    "    \n",
    "    print(\"\\n통계:\")\n",
    "    print(f\"전체 이미지: {len(results)}개\")\n",
    "    print(f\"정상 이미지: {normal_count}개 ({normal_count/len(results)*100:.1f}%)\")\n",
    "    print(f\"스팸 이미지: {spam_count}개 ({spam_count/len(results)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vit_spam_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
