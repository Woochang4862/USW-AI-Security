{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "# ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ í”„ë¡œí† íƒ€ì… ğŸ”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ViT + BERT + SVMì„ ì‚¬ìš©í•œ ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ì˜ í”„ë¡œí† íƒ€ì… êµ¬í˜„ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "1. ì´ë¯¸ì§€ ì²˜ë¦¬: Vision Transformer (ViT)\n",
    "2. í…ìŠ¤íŠ¸ ì²˜ë¦¬: BERT\n",
    "3. ë¶„ë¥˜ê¸°: SVM\n",
    "\n",
    "## ë°ì´í„°ì…‹\n",
    "- Dredze Email Dataset (ì´ë¯¸ì§€ ìŠ¤íŒ¸)\n",
    "- SpamAssassin Dataset (í…ìŠ¤íŠ¸ ìŠ¤íŒ¸)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_libs"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch torchvision scikit-learn pandas numpy pillow tqdm\n",
    "!nvidia-smi  # GPU í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive_mount"
   },
   "source": [
    "## 2. Google Drive ì—°ë™ ë° ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "!mkdir -p '/content/drive/MyDrive/spam_detection_project/{data,models,checkpoints}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_definition"
   },
   "source": [
    "## 3. ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "multimodal_model"
   },
   "outputs": [],
   "source": [
    "class MultimodalSpamDetector:\n",
    "    def __init__(self):\n",
    "        # ViT ì´ˆê¸°í™”\n",
    "        self.vit_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "        \n",
    "        # BERT ì´ˆê¸°í™”\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        # SVM ë¶„ë¥˜ê¸°\n",
    "        self.svm = SVC(kernel='rbf', probability=True)\n",
    "        \n",
    "        # GPU ì‚¬ìš© ì„¤ì •\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.vit.to(self.device)\n",
    "        self.bert.to(self.device)\n",
    "    \n",
    "    def extract_image_features(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        inputs = self.vit_extractor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.vit(**inputs)\n",
    "            image_features = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # [CLS] í† í° ì‚¬ìš©\n",
    "        \n",
    "        return image_features\n",
    "    \n",
    "    def extract_text_features(self, text):\n",
    "        inputs = self.bert_tokenizer(text, padding=True, truncation=True, max_length=512,\n",
    "                                    return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(**inputs)\n",
    "            text_features = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # [CLS] í† í° ì‚¬ìš©\n",
    "        \n",
    "        return text_features\n",
    "    \n",
    "    def combine_features(self, image_features, text_features):\n",
    "        # ë‹¨ìˆœ concatenation ë°©ì‹ìœ¼ë¡œ íŠ¹ì§• ê²°í•©\n",
    "        return np.concatenate([image_features, text_features], axis=1)\n",
    "    \n",
    "    def train(self, image_paths, texts, labels):\n",
    "        combined_features = []\n",
    "        \n",
    "        for img_path, text in tqdm(zip(image_paths, texts), total=len(image_paths)):\n",
    "            image_feat = self.extract_image_features(img_path)\n",
    "            text_feat = self.extract_text_features(text)\n",
    "            combined = self.combine_features(image_feat, text_feat)\n",
    "            combined_features.append(combined.squeeze())\n",
    "        \n",
    "        X = np.array(combined_features)\n",
    "        self.svm.fit(X, labels)\n",
    "    \n",
    "    def predict(self, image_path, text):\n",
    "        image_feat = self.extract_image_features(image_path)\n",
    "        text_feat = self.extract_text_features(text)\n",
    "        combined = self.combine_features(image_feat, text_feat)\n",
    "        \n",
    "        return self.svm.predict(combined), self.svm.predict_proba(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loading"
   },
   "source": [
    "## 4. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"ë°ì´í„° ë¡œë”© í•¨ìˆ˜ - ì‹¤ì œ ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì • í•„ìš”\"\"\"\n",
    "    image_paths = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    # ì—¬ê¸°ì— ì‹¤ì œ ë°ì´í„° ë¡œë”© ë¡œì§ êµ¬í˜„\n",
    "    # Dredze Datasetê³¼ SpamAssassin Dataset ë¡œë”©\n",
    "    \n",
    "    return image_paths, texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 5. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_evaluate"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë”©\n",
    "data_dir = '/content/drive/MyDrive/spam_detection_project/data'\n",
    "image_paths, texts, labels = load_data(data_dir)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ\n",
    "model = MultimodalSpamDetector()\n",
    "model.train(image_paths, texts, labels)\n",
    "\n",
    "# í‰ê°€\n",
    "predictions = []\n",
    "for img_path, text in zip(image_paths[:10], texts[:10]):  # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ\n",
    "    pred, prob = model.predict(img_path, text)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\n",
    "accuracy = accuracy_score(labels[:10], predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels[:10], predictions, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_model"
   },
   "source": [
    "## 6. ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# SVM ëª¨ë¸ ì €ì¥\n",
    "save_path = '/content/drive/MyDrive/spam_detection_project/models/svm_model.joblib'\n",
    "joblib.dump(model.svm, save_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "spam_detection_prototype.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 