{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "# ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ (ViT + BERT) ğŸ”\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ Vision Transformer (ViT)ì™€ BERTë¥¼ ê²°í•©í•˜ì—¬ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ ë©€í‹°ëª¨ë‹¬ ìŠ¤íŒ¸ íƒì§€ ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ë°ì´í„°ì…‹\n",
        "- SpamAssassin Public Corpus (í…ìŠ¤íŠ¸)\n",
        "- Kaggle Spam Image Dataset (ì´ë¯¸ì§€)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1WRT0dU2C13"
      },
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEdqP2yJ4jPz",
        "outputId": "39195d9b-2d3b-4cba-e057-80d97406fc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwoochang4862\u001b[0m (\u001b[33mwoochang4862-university-of-suwon\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swyo-1me2C14",
        "outputId": "136c9348-d5cd-4f1d-ee1b-d6584e75835a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Collecting email\n",
            "  Using cached email-4.0.2.tar.gz (1.2 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Tue May 27 13:22:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision transformers scikit-learn pandas numpy pillow tqdm kagglehub email\n",
        "!nvidia-smi  # GPU í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xpVSV4w2C17"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import email\n",
        "from tqdm import tqdm\n",
        "import kagglehub\n",
        "import glob\n",
        "import random\n",
        "import wandb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YyFo-gV2C19"
      },
      "source": [
        "## 2. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXLY5Xrf2C1-",
        "outputId": "07264685-4634-4705-dd5b-db5338889c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text dataset path: /kaggle/input/spamassassin-public-corpus\n",
            "Image dataset path: /kaggle/input/spam-image-dataset\n"
          ]
        }
      ],
      "source": [
        "# SpamAssassin ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "text_dataset_path = kagglehub.dataset_download(\"beatoa/spamassassin-public-corpus\")\n",
        "print(\"Text dataset path:\", text_dataset_path)\n",
        "\n",
        "# ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "image_dataset_path = kagglehub.dataset_download(\"asifjamal123/spam-image-dataset\")\n",
        "print(\"Image dataset path:\", image_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch4b_4W2C2A"
      },
      "source": [
        "## 3. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aWgZN4A2C2C"
      },
      "outputs": [],
      "source": [
        "def parse_email(file_path):\n",
        "    \"\"\"ì´ë©”ì¼ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ\"\"\"\n",
        "    with open(file_path, 'r', encoding='latin-1') as f:\n",
        "        msg = email.message_from_file(f)\n",
        "\n",
        "    body = \"\"\n",
        "    if msg.is_multipart():\n",
        "        for part in msg.walk():\n",
        "            if part.get_content_type() == \"text/plain\":\n",
        "                body += part.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
        "    else:\n",
        "        body = msg.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
        "\n",
        "    return body.strip()\n",
        "\n",
        "class MultimodalSpamDataset(Dataset):\n",
        "    def __init__(self, text_dir, image_dir, transform=None, max_length=512):\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ\n",
        "        self.images = []\n",
        "        self.image_labels = []\n",
        "        self.valid_extensions = ('.jpg', '.jpeg', '.png', '.gif')\n",
        "\n",
        "        # ìŠ¤íŒ¸ ì´ë¯¸ì§€\n",
        "        spam_img_dir = os.path.join(image_dir, 'SPAM IMAGE dataset/SpamImages/SpamImages')\n",
        "        for img_name in os.listdir(spam_img_dir):\n",
        "            if img_name.lower().endswith(self.valid_extensions):\n",
        "                img_path = os.path.join(spam_img_dir, img_name)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()\n",
        "                    self.images.append(img_path)\n",
        "                    self.image_labels.append(1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
        "\n",
        "        # ì •ìƒ ì´ë¯¸ì§€\n",
        "        ham_img_dir = os.path.join(image_dir, 'SPAM IMAGE dataset/NaturalImages/NaturalImages')\n",
        "        for img_name in os.listdir(ham_img_dir):\n",
        "            if img_name.lower().endswith(self.valid_extensions):\n",
        "                img_path = os.path.join(ham_img_dir, img_name)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()\n",
        "                    self.images.append(img_path)\n",
        "                    self.image_labels.append(0)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
        "        self.texts = []\n",
        "        self.text_labels = []\n",
        "\n",
        "        # ìŠ¤íŒ¸ í…ìŠ¤íŠ¸\n",
        "        spam_text_dir = os.path.join(text_dir, 'spam_2/spam_2')\n",
        "        for text_file in os.listdir(spam_text_dir):\n",
        "            text_path = os.path.join(spam_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(1)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # ì •ìƒ í…ìŠ¤íŠ¸ (easy_ham)\n",
        "        ham_text_dir = os.path.join(text_dir, 'easy_ham/easy_ham')\n",
        "        for text_file in os.listdir(ham_text_dir):\n",
        "            text_path = os.path.join(ham_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(0)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # ì •ìƒ í…ìŠ¤íŠ¸ (hard_ham)\n",
        "        ham_text_dir = os.path.join(text_dir, 'hard_ham/hard_ham')\n",
        "        for text_file in os.listdir(ham_text_dir):\n",
        "            text_path = os.path.join(ham_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(0)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # ëœë¤ ì¡°í•© ìƒì„±\n",
        "        self.combined_data = []\n",
        "\n",
        "        # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ëœë¤í•œ í…ìŠ¤íŠ¸ í• ë‹¹\n",
        "        for i in range(len(self.images)):\n",
        "            # ëœë¤í•œ í…ìŠ¤íŠ¸ ì„ íƒ\n",
        "            text_idx = random.randint(0, len(self.texts) - 1)\n",
        "\n",
        "            # ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ìŠ¤íŒ¸ì´ë©´ ìŠ¤íŒ¸ìœ¼ë¡œ ë ˆì´ë¸”ë§\n",
        "            is_spam = 1 if (self.image_labels[i] == 1 or self.text_labels[text_idx] == 1) else 0\n",
        "\n",
        "            self.combined_data.append({\n",
        "                'image_path': self.images[i],\n",
        "                'text': self.texts[text_idx],\n",
        "                'label': is_spam,\n",
        "                'image_label': self.image_labels[i],\n",
        "                'text_label': self.text_labels[text_idx]\n",
        "            })\n",
        "\n",
        "        # ë°ì´í„°ì…‹ í†µê³„ ì¶œë ¥\n",
        "        spam_count = sum(1 for item in self.combined_data if item['label'] == 1)\n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"Total samples: {len(self.combined_data)}\")\n",
        "        print(f\"Spam samples: {spam_count} ({spam_count/len(self.combined_data)*100:.2f}%)\")\n",
        "        print(f\"Ham samples: {len(self.combined_data) - spam_count} ({(len(self.combined_data)-spam_count)/len(self.combined_data)*100:.2f}%)\")\n",
        "\n",
        "        # ì¡°í•© ìœ í˜•ë³„ í†µê³„\n",
        "        spam_spam = sum(1 for item in self.combined_data if item['image_label'] == 1 and item['text_label'] == 1)\n",
        "        spam_ham = sum(1 for item in self.combined_data if item['image_label'] == 1 and item['text_label'] == 0)\n",
        "        ham_spam = sum(1 for item in self.combined_data if item['image_label'] == 0 and item['text_label'] == 1)\n",
        "        ham_ham = sum(1 for item in self.combined_data if item['image_label'] == 0 and item['text_label'] == 0)\n",
        "\n",
        "        print(\"\\nCombination Statistics:\")\n",
        "        print(f\"Spam image + Spam text: {spam_spam}\")\n",
        "        print(f\"Spam image + Ham text: {spam_ham}\")\n",
        "        print(f\"Ham image + Spam text: {ham_spam}\")\n",
        "        print(f\"Ham image + Ham text: {ham_ham}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.combined_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.combined_data[idx]\n",
        "\n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        try:\n",
        "            image = Image.open(item['image_path']).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {item['image_path']}: {str(e)}\")\n",
        "            image = torch.zeros((3, 224, 224)) if self.transform else Image.new('RGB', (224, 224), 'black')\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ í† í°í™”\n",
        "        encoding = self.tokenizer(\n",
        "            item['text'],\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'label': item['label']\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHxjXTMD2C2E"
      },
      "source": [
        "## 4. ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoNSyD162C2G"
      },
      "outputs": [],
      "source": [
        "class MultimodalSpamClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # ViT ëª¨ë¸\n",
        "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
        "        self.vit_dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # BERT ëª¨ë¸\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert_dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # íŠ¹ì§• ê²°í•© ë° ë¶„ë¥˜\n",
        "        hidden_size = self.vit.config.hidden_size + self.bert.config.hidden_size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ\n",
        "        vit_outputs = self.vit(image)\n",
        "        image_features = self.vit_dropout(vit_outputs.last_hidden_state[:, 0])\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ\n",
        "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_features = self.bert_dropout(bert_outputs.last_hidden_state[:, 0])\n",
        "\n",
        "        # íŠ¹ì§• ê²°í•©\n",
        "        combined_features = torch.cat([image_features, text_features], dim=1)\n",
        "\n",
        "        # ë¶„ë¥˜\n",
        "        logits = self.classifier(combined_features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl2MkPSH2C2H"
      },
      "source": [
        "## 5. í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y6hSvaG2C2H"
      },
      "outputs": [],
      "source": [
        "# train_epoch í•¨ìˆ˜ ìˆ˜ì •\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
        "        images = batch['image'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # ë°°ì¹˜ë³„ ë¡œê¹…\n",
        "        if batch_idx % 10 == 0:  # 10ë°°ì¹˜ë§ˆë‹¤ ë¡œê¹…\n",
        "            wandb.log({\n",
        "                \"batch_loss\": loss.item(),\n",
        "                \"batch\": batch_idx + epoch * len(dataloader)\n",
        "            })\n",
        "\n",
        "    # ì—í­ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # wandbì— í˜¼ë™ í–‰ë ¬ ë¡œê¹…\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    return total_loss / len(dataloader), accuracy, precision, recall, f1\n",
        "\n",
        "# validate í•¨ìˆ˜ ìˆ˜ì •\n",
        "def validate(model, dataloader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            images = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(images, input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # ê²€ì¦ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # wandbì— í˜¼ë™ í–‰ë ¬ ë¡œê¹…\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Validation Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    wandb.log({\"val_confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    return total_loss / len(dataloader), accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EesKQ8Fy2C2I"
      },
      "source": [
        "## 6. ëª¨ë¸ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeUKfcRX2C2I",
        "outputId": "83490da3-8c5b-4c1b-baa9-02fd7e3888f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_151256-ck54fb54</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">experiment_6c4rpi5f</a></strong> to <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping corrupted image /kaggle/input/spam-image-dataset/SPAM IMAGE dataset/SpamImages/SpamImages/debut.jpg: cannot identify image file '/kaggle/input/spam-image-dataset/SPAM IMAGE dataset/SpamImages/SpamImages/debut.jpg'\n",
            "\n",
            "Dataset Statistics:\n",
            "Total samples: 1739\n",
            "Spam samples: 1185 (68.14%)\n",
            "Ham samples: 554 (31.86%)\n",
            "\n",
            "Combination Statistics:\n",
            "Spam image + Spam text: 282\n",
            "Spam image + Ham text: 647\n",
            "Ham image + Spam text: 256\n",
            "Ham image + Ham text: 554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:46<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2812\n",
            "Train Metrics - Acc: 0.8871, Prec: 0.8928, Rec: 0.9483, F1: 0.9197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:37<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1109\n",
            "Val Metrics - Acc: 0.9741, Prec: 0.9790, Rec: 0.9831, F1: 0.9811\n",
            "Model saved!\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:52<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0941\n",
            "Train Metrics - Acc: 0.9763, Prec: 0.9831, Rec: 0.9821, F1: 0.9826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:36<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0885\n",
            "Val Metrics - Acc: 0.9799, Prec: 0.9873, Rec: 0.9831, F1: 0.9852\n",
            "Model saved!\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:52<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0422\n",
            "Train Metrics - Acc: 0.9899, Prec: 0.9895, Rec: 0.9958, F1: 0.9926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:37<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0752\n",
            "Val Metrics - Acc: 0.9741, Prec: 0.9790, Rec: 0.9831, F1: 0.9811\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:46<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0219\n",
            "Train Metrics - Acc: 0.9942, Prec: 0.9927, Rec: 0.9989, F1: 0.9958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:40<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0596\n",
            "Val Metrics - Acc: 0.9799, Prec: 0.9792, Rec: 0.9916, F1: 0.9853\n",
            "Model saved!\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:48<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0118\n",
            "Train Metrics - Acc: 0.9993, Prec: 1.0000, Rec: 0.9989, F1: 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:41<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0578\n",
            "Val Metrics - Acc: 0.9770, Prec: 0.9791, Rec: 0.9873, F1: 0.9832\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:45<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0072\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:36<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0590\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9873, Rec: 0.9873, F1: 0.9873\n",
            "Model saved!\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:51<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:36<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0637\n",
            "Val Metrics - Acc: 0.9770, Prec: 0.9791, Rec: 0.9873, F1: 0.9832\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:49<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0044\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:36<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0599\n",
            "Val Metrics - Acc: 0.9856, Prec: 0.9874, Rec: 0.9916, F1: 0.9895\n",
            "Model saved!\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:45<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0040\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:40<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0618\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9833, Rec: 0.9916, F1: 0.9874\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [04:44<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0033\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:40<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0622\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9833, Rec: 0.9916, F1: 0.9874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>batch_loss</td><td>â–ˆâ–„â–‚â–‚â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–</td></tr><tr><td>train_accuracy</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_f1</td><td>â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–</td></tr><tr><td>train_precision</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_recall</td><td>â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_accuracy</td><td>â–â–…â–â–…â–ƒâ–†â–ƒâ–ˆâ–†â–†</td></tr><tr><td>val_f1</td><td>â–â–„â–â–…â–ƒâ–†â–ƒâ–ˆâ–†â–†</td></tr><tr><td>val_loss</td><td>â–ˆâ–…â–ƒâ–â–â–â–‚â–â–‚â–‚</td></tr><tr><td>val_precision</td><td>â–â–ˆâ–â–â–â–ˆâ–â–ˆâ–…â–…</td></tr><tr><td>val_recall</td><td>â–â–â–â–ˆâ–…â–…â–…â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1736</td></tr><tr><td>batch_loss</td><td>0.00429</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_accuracy</td><td>1</td></tr><tr><td>train_f1</td><td>1</td></tr><tr><td>train_loss</td><td>0.00335</td></tr><tr><td>train_precision</td><td>1</td></tr><tr><td>train_recall</td><td>1</td></tr><tr><td>val_accuracy</td><td>0.98276</td></tr><tr><td>val_f1</td><td>0.98739</td></tr><tr><td>val_loss</td><td>0.0622</td></tr><tr><td>val_precision</td><td>0.98326</td></tr><tr><td>val_recall</td><td>0.99156</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_6c4rpi5f</strong> at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54</a><br> View project at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a><br>Synced 5 W&B file(s), 20 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_151256-ck54fb54/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "config = {\n",
        "    \"architecture\": \"ViT-BERT-Multimodal\",\n",
        "    \"dataset\": \"SpamAssassin + Spam Image Dataset\",\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 10,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"scheduler\": \"linear\",\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"image_size\": 224,\n",
        "    \"max_text_length\": 512\n",
        "}\n",
        "\n",
        "# wandb ì´ˆê¸°í™”\n",
        "wandb.init(\n",
        "    project=\"multimodal-spam-detection\",\n",
        "    config=config,\n",
        "    name=f\"experiment_{wandb.util.generate_id()}\"\n",
        ")\n",
        "\n",
        "BATCH_SIZE = config[\"batch_size\"]\n",
        "EPOCHS = config[\"epochs\"]\n",
        "LEARNING_RATE = config[\"learning_rate\"]\n",
        "\n",
        "# ë°ì´í„° ë³€í™˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
        "dataset = MultimodalSpamDataset(text_dataset_path, image_dataset_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultimodalSpamClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=config[\"weight_decay\"])\n",
        "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=EPOCHS)\n",
        "\n",
        "# wandbì— ëª¨ë¸ êµ¬ì¡° ë¡œê¹…\n",
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "best_val_f1 = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
        "\n",
        "    # í•™ìŠµ\n",
        "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, device, epoch\n",
        "    )\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    print(f'Train Metrics - Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Rec: {train_rec:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    # ê²€ì¦\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1 = validate(\n",
        "        model, val_loader, criterion, device, epoch\n",
        "    )\n",
        "    print(f'Val Loss: {val_loss:.4f}')\n",
        "    print(f'Val Metrics - Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, Rec: {val_rec:.4f}, F1: {val_f1:.4f}')\n",
        "\n",
        "    # í•™ìŠµë¥  ì¡°ì •\n",
        "    scheduler.step()\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "    # wandbì— ë©”íŠ¸ë¦­ ë¡œê¹…\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"train_precision\": train_prec,\n",
        "        \"train_recall\": train_rec,\n",
        "        \"train_f1\": train_f1,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"val_precision\": val_prec,\n",
        "        \"val_recall\": val_rec,\n",
        "        \"val_f1\": val_f1,\n",
        "        \"learning_rate\": current_lr\n",
        "    })\n",
        "\n",
        "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_multimodal_spam_classifier.pth')\n",
        "        wandb.save('best_multimodal_spam_classifier.pth')\n",
        "        print('Model saved!')\n",
        "\n",
        "# wandb ì‹¤í—˜ ì¢…ë£Œ\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3iLS4mg2C2J"
      },
      "source": [
        "## 7. ëª¨ë¸ í‰ê°€ ë° ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "yPoB5w5_2C2J",
        "outputId": "8799d56f-3cc1-4410-e5cc-ad50fdb7fb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_160915-u3bnnl9d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">final_evaluation</a></strong> to <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:19<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Evaluation Results:\n",
            "Accuracy: 0.9856\n",
            "Precision: 0.9874\n",
            "Recall: 0.9916\n",
            "F1-Score: 0.9895\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final_accuracy</td><td>â–</td></tr><tr><td>final_f1</td><td>â–</td></tr><tr><td>final_precision</td><td>â–</td></tr><tr><td>final_recall</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final_accuracy</td><td>0.98563</td></tr><tr><td>final_f1</td><td>0.98947</td></tr><tr><td>final_precision</td><td>0.98739</td></tr><tr><td>final_recall</td><td>0.99156</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">final_evaluation</strong> at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d</a><br> View project at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_160915-u3bnnl9d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
        "best_model = MultimodalSpamClassifier().to(device)\n",
        "best_model.load_state_dict(torch.load('best_multimodal_spam_classifier.pth'))\n",
        "\n",
        "# ì „ì²´ ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ìƒì„¸ í‰ê°€\n",
        "wandb.init(project=\"multimodal-spam-detection\", name=\"final_evaluation\")\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = validate(best_model, val_loader, criterion, device, EPOCHS)\n",
        "\n",
        "print('\\nFinal Evaluation Results:')\n",
        "print(f'Accuracy: {val_acc:.4f}')\n",
        "print(f'Precision: {val_prec:.4f}')\n",
        "print(f'Recall: {val_rec:.4f}')\n",
        "print(f'F1-Score: {val_f1:.4f}')\n",
        "\n",
        "# ìµœì¢… ê²°ê³¼ë¥¼ wandbì— ë¡œê¹…\n",
        "wandb.log({\n",
        "    \"final_accuracy\": val_acc,\n",
        "    \"final_precision\": val_prec,\n",
        "    \"final_recall\": val_rec,\n",
        "    \"final_f1\": val_f1\n",
        "})\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx3GYgro2C2K"
      },
      "source": [
        "## 8. ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDoMT6bM2C2K"
      },
      "outputs": [],
      "source": [
        "def predict_sample(model, image_path, text, device, transform):\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image, input_ids, attention_mask)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "    return {\n",
        "        'prediction': 'ìŠ¤íŒ¸' if prediction == 1 else 'ì •ìƒ',\n",
        "        'spam_prob': probs[0][1].item(),\n",
        "        'normal_prob': probs[0][0].item()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
        "test_image_path = \"/content/000a01c72c26$bec5c540$00000000@zv65vp7hlihg4p_storeblog_download000.jpg\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "test_text = \"\"\"\n",
        "Subject: ğŸ„ CHRISTMAS SPECIAL OFFER - MEN'S POWER PACK! ğŸ\n",
        "\n",
        "HELLO!\n",
        "\n",
        "CHRISTMAS MEN'S POWER CHARGE!\n",
        "SPECIAL HOLIDAY COMBO PACK - CIALIS + VIAGRA\n",
        "\n",
        "INCREDIBLE HOLIDAY SAVINGS:\n",
        "âœ¨ 10 + 10 = $129.95 (BEST VALUE!)\n",
        "âœ¨ 20 + 20 = $249.95\n",
        "âœ¨ 30 + 30 = $319.95\n",
        "\n",
        "ğŸ… HOLIDAY BONUS: 20% EXTRA DISCOUNT! ğŸ„\n",
        "\n",
        "Available Products:\n",
        "- Cialis Soft\n",
        "- Viagra Professional\n",
        "- Viagra Soft\n",
        "- Generic Viagra\n",
        "- Valium\n",
        "- Xanax\n",
        "- Soma\n",
        "- Ambien\n",
        "And many more!\n",
        "\n",
        "ğŸ’Š 100% GENUINE PRODUCTS\n",
        "âœˆï¸ WORLDWIDE SHIPPING\n",
        "ğŸ”’ SECURE PAYMENT\n",
        "\n",
        "DON'T MISS OUT ON THIS LIMITED TIME OFFER!\n",
        "\n",
        "CLICK HERE TO ORDER NOW!\n",
        "[suspicious_link_removed]\n",
        "\n",
        "To unsubscribe, reply with \"STOP\"\n",
        "\"\"\"  # í…ŒìŠ¤íŠ¸í•  ì´ë©”ì¼ í…ìŠ¤íŠ¸\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "    print(f\"íŒì •: {result['prediction']}\")\n",
        "    print(f\"ìŠ¤íŒ¸ í™•ë¥ : {result['spam_prob']:.4f}\")\n",
        "    print(f\"ì •ìƒ í™•ë¥ : {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zLulklYKlFh",
        "outputId": "a9e2d71a-fcd5-4441-be36-23c50aa5d06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "íŒì •: ìŠ¤íŒ¸\n",
            "ìŠ¤íŒ¸ í™•ë¥ : 1.0000\n",
            "ì •ìƒ í™•ë¥ : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
        "test_image_path = \"/content/IMG_2757.jpg\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "test_text = \"\"\"\n",
        "Subject: ğŸŒŸ Join Late Night Study Group - SWU AI Security Department!\n",
        "\n",
        "Hello from Suwon University's AI Security Department Late Night Study Group!\n",
        "\n",
        "We are a dedicated study group that meets every Tuesday night for intensive learning sessions.\n",
        "(Photo attached: Last week's study session - Our passionate team at 2:06 AM)\n",
        "\n",
        "ğŸ“š Study Focus Areas:\n",
        "- AI Security Project Labs\n",
        "- Coding Test Preparation\n",
        "- Team Project Collaboration\n",
        "- Career Development Insights\n",
        "\n",
        "âœ¨ Requirements:\n",
        "- Current student in SWU AI Security Department\n",
        "- Passionate and committed mindset\n",
        "- Available for late-night sessions (2-4 AM)\n",
        "- Strong team player attitude\n",
        "\n",
        "ğŸ’ Benefits:\n",
        "- Network with department peers\n",
        "- Hands-on project experience\n",
        "- Career opportunity sharing\n",
        "- Snacks and beverages provided\n",
        "\n",
        "Interested? Join our open KakaoTalk chat!\n",
        "[Link]\n",
        "\n",
        "* This semester's recruitment ends this week!\n",
        "* Limited to first 3 applicants - Don't miss out!\n",
        "\n",
        "Best regards,\n",
        "SWU AI Security Late Night Study Group\n",
        "\"\"\"  # í…ŒìŠ¤íŠ¸í•  ì´ë©”ì¼ í…ìŠ¤íŠ¸\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "    print(f\"íŒì •: {result['prediction']}\")\n",
        "    print(f\"ìŠ¤íŒ¸ í™•ë¥ : {result['spam_prob']:.4f}\")\n",
        "    print(f\"ì •ìƒ í™•ë¥ : {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LY-BUyGNeHs",
        "outputId": "f2b32610-fac9-43ff-83ad-555b9c6bbf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "íŒì •: ìŠ¤íŒ¸\n",
            "ìŠ¤íŒ¸ í™•ë¥ : 0.9836\n",
            "ì •ìƒ í™•ë¥ : 0.0164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
        "test_image_path = \"/content/IMG_2757.jpg\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "test_text = \"\"\"\n",
        "Subject: ğŸ„ CHRISTMAS SPECIAL OFFER - MEN'S POWER PACK! ğŸ\n",
        "\n",
        "HELLO!\n",
        "\n",
        "CHRISTMAS MEN'S POWER CHARGE!\n",
        "SPECIAL HOLIDAY COMBO PACK - CIALIS + VIAGRA\n",
        "\n",
        "INCREDIBLE HOLIDAY SAVINGS:\n",
        "âœ¨ 10 + 10 = $129.95 (BEST VALUE!)\n",
        "âœ¨ 20 + 20 = $249.95\n",
        "âœ¨ 30 + 30 = $319.95\n",
        "\n",
        "ğŸ… HOLIDAY BONUS: 20% EXTRA DISCOUNT! ğŸ„\n",
        "\n",
        "Available Products:\n",
        "- Cialis Soft\n",
        "- Viagra Professional\n",
        "- Viagra Soft\n",
        "- Generic Viagra\n",
        "- Valium\n",
        "- Xanax\n",
        "- Soma\n",
        "- Ambien\n",
        "And many more!\n",
        "\n",
        "ğŸ’Š 100% GENUINE PRODUCTS\n",
        "âœˆï¸ WORLDWIDE SHIPPING\n",
        "ğŸ”’ SECURE PAYMENT\n",
        "\n",
        "DON'T MISS OUT ON THIS LIMITED TIME OFFER!\n",
        "\n",
        "CLICK HERE TO ORDER NOW!\n",
        "[suspicious_link_removed]\n",
        "\n",
        "To unsubscribe, reply with \"STOP\"\n",
        "\"\"\"  # í…ŒìŠ¤íŠ¸í•  ì´ë©”ì¼ í…ìŠ¤íŠ¸\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "    print(f\"íŒì •: {result['prediction']}\")\n",
        "    print(f\"ìŠ¤íŒ¸ í™•ë¥ : {result['spam_prob']:.4f}\")\n",
        "    print(f\"ì •ìƒ í™•ë¥ : {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjb4DYdLPLHq",
        "outputId": "19a3f251-5ea9-4b08-a597-3b020a5906c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "íŒì •: ìŠ¤íŒ¸\n",
            "ìŠ¤íŒ¸ í™•ë¥ : 0.9922\n",
            "ì •ìƒ í™•ë¥ : 0.0078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_only(model, text, device):\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ê²€ì€ìƒ‰ ì´ë¯¸ì§€)\n",
        "    dummy_image = torch.zeros((1, 3, 224, 224)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(dummy_image, input_ids, attention_mask)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "    return {\n",
        "        'prediction': 'ìŠ¤íŒ¸' if prediction == 1 else 'ì •ìƒ',\n",
        "        'spam_prob': probs[0][1].item(),\n",
        "        'normal_prob': probs[0][0].item()\n",
        "    }\n",
        "\n",
        "# í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "test_text = \"\"\"\n",
        "From ilug-admin@linux.ie  Tue Aug  6 11:51:02 2002\n",
        "Return-Path: <ilug-admin@linux.ie>\n",
        "Delivered-To: yyyy@localhost.netnoteinc.com\n",
        "Received: from localhost (localhost [127.0.0.1])\n",
        "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\n",
        "\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
        "Received: from phobos [127.0.0.1]\n",
        "\tby localhost with IMAP (fetchmail-5.9.0)\n",
        "\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
        "Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\n",
        "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for\n",
        "    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
        "Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\n",
        "    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
        "Received: from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net\n",
        "    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for\n",
        "    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
        "X-Authentication-Warning: lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net\n",
        "    [64.0.57.142] claimed to be bettyjagessar.com\n",
        "Received: from 64.0.57.142 [202.63.165.34] by bettyjagessar.com\n",
        "    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
        "Message-Id: <1028311679.886@0.57.142>\n",
        "Date: Fri, 02 Aug 2002 23:37:59 0530\n",
        "To: ilug@linux.ie\n",
        "From: \"Start Now\" <startnow2002@hotmail.com>\n",
        "MIME-Version: 1.0\n",
        "Content-Type: text/plain; charset=\"US-ASCII\"; format=flowed\n",
        "Subject: [ILUG] STOP THE MLM INSANITY\n",
        "Sender: ilug-admin@linux.ie\n",
        "Errors-To: ilug-admin@linux.ie\n",
        "X-Mailman-Version: 1.1\n",
        "Precedence: bulk\n",
        "List-Id: Irish Linux Users' Group <ilug.linux.ie>\n",
        "X-Beenthere: ilug@linux.ie\n",
        "\n",
        "Greetings!\n",
        "\n",
        "You are receiving this letter because you have expressed an interest in\n",
        "receiving information about online business opportunities. If this is\n",
        "erroneous then please accept my most sincere apology. This is a one-time\n",
        "mailing, so no removal is necessary.\n",
        "\n",
        "If you've been burned, betrayed, and back-stabbed by multi-level marketing,\n",
        "MLM, then please read this letter. It could be the most important one that\n",
        "has ever landed in your Inbox.\n",
        "\n",
        "MULTI-LEVEL MARKETING IS A HUGE MISTAKE FOR MOST PEOPLE\n",
        "\n",
        "MLM has failed to deliver on its promises for the past 50 years. The pursuit\n",
        "of the \"MLM Dream\" has cost hundreds of thousands of people their friends,\n",
        "their fortunes and their sacred honor. The fact is that MLM is fatally\n",
        "flawed, meaning that it CANNOT work for most people.\n",
        "\n",
        "The companies and the few who earn the big money in MLM are NOT going to\n",
        "tell you the real story. FINALLY, there is someone who has the courage to\n",
        "cut through the hype and lies and tell the TRUTH about MLM.\n",
        "\n",
        "HERE'S GOOD NEWS\n",
        "\n",
        "There IS an alternative to MLM that WORKS, and works BIG! If you haven't yet\n",
        "abandoned your dreams, then you need to see this. Earning the kind of income\n",
        "you've dreamed about is easier than you think!\n",
        "\n",
        "With your permission, I'd like to send you a brief letter that will tell you\n",
        "WHY MLM doesn't work for most people and will then introduce you to\n",
        "something so new and refreshing that you'll wonder why you haven't heard of\n",
        "this before.\n",
        "\n",
        "I promise that there will be NO unwanted follow up, NO sales pitch, no one\n",
        "will call you, and your email address will only be used to send you the\n",
        "information. Period.\n",
        "\n",
        "To receive this free, life-changing information, simply click Reply, type\n",
        "\"Send Info\" in the Subject box and hit Send. I'll get the information to you\n",
        "within 24 hours. Just look for the words MLM WALL OF SHAME in your Inbox.\n",
        "\n",
        "Cordially,\n",
        "\n",
        "Siddhi\n",
        "\n",
        "P.S. Someone recently sent the letter to me and it has been the most\n",
        "eye-opening, financially beneficial information I have ever received. I\n",
        "honestly believe that you will feel the same way once you've read it. And\n",
        "it's FREE!\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "This email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". You are receiving\n",
        "this email because you EXPLICITLY signed yourself up to our list with our\n",
        "online signup form or through use of our FFA Links Page and E-MailDOM\n",
        "systems, which have EXPLICIT terms of use which state that through its use\n",
        "you agree to receive our emailings.  You may also be a member of a Altra\n",
        "Computer Systems list or one of many numerous FREE Marketing Services and as\n",
        "such you agreed when you signed up for such list that you would also be\n",
        "receiving this emailing.\n",
        "Due to the above, this email message cannot be considered unsolicitated, or\n",
        "spam.\n",
        "-----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "--\n",
        "Irish Linux Users' Group: ilug@linux.ie\n",
        "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
        "List maintainer: listmaster@linux.ie\n",
        "\"\"\"\n",
        "\n",
        "result = predict_text_only(best_model, test_text, device)\n",
        "\n",
        "print(\"\\ní…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "print(f\"íŒì •: {result['prediction']}\")\n",
        "print(f\"ìŠ¤íŒ¸ í™•ë¥ : {result['spam_prob']:.4f}\")\n",
        "print(f\"ì •ìƒ í™•ë¥ : {result['normal_prob']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PvdAWI3OraM",
        "outputId": "e00105f0-efee-445c-9fbe-51600875f4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼:\n",
            "íŒì •: ì •ìƒ\n",
            "ìŠ¤íŒ¸ í™•ë¥ : 0.0263\n",
            "ì •ìƒ í™•ë¥ : 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_wxYUUb8Qmhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}