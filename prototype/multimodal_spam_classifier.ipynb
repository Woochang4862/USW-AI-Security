{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "# Î©ÄÌã∞Î™®Îã¨ Ïä§Ìå∏ ÌÉêÏßÄ Î™®Îç∏ (ViT + BERT) üîç\n",
        "\n",
        "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏùÄ Vision Transformer (ViT)ÏôÄ BERTÎ•º Í≤∞Ìï©ÌïòÏó¨ Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ Í∏∞Î∞òÏùò Î©ÄÌã∞Î™®Îã¨ Ïä§Ìå∏ ÌÉêÏßÄ Î™®Îç∏ÏùÑ Íµ¨ÌòÑÌï©ÎãàÎã§.\n",
        "\n",
        "## Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "- SpamAssassin Public Corpus (ÌÖçÏä§Ìä∏)\n",
        "- Kaggle Spam Image Dataset (Ïù¥ÎØ∏ÏßÄ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1WRT0dU2C13"
      },
      "source": [
        "## 1. ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEdqP2yJ4jPz",
        "outputId": "39195d9b-2d3b-4cba-e057-80d97406fc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwoochang4862\u001b[0m (\u001b[33mwoochang4862-university-of-suwon\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swyo-1me2C14",
        "outputId": "136c9348-d5cd-4f1d-ee1b-d6584e75835a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Collecting email\n",
            "  Using cached email-4.0.2.tar.gz (1.2 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Tue May 27 13:22:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision transformers scikit-learn pandas numpy pillow tqdm kagglehub email\n",
        "!nvidia-smi  # GPU ÌôïÏù∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xpVSV4w2C17"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import email\n",
        "from tqdm import tqdm\n",
        "import kagglehub\n",
        "import glob\n",
        "import random\n",
        "import wandb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YyFo-gV2C19"
      },
      "source": [
        "## 2. Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXLY5Xrf2C1-",
        "outputId": "07264685-4634-4705-dd5b-db5338889c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text dataset path: /kaggle/input/spamassassin-public-corpus\n",
            "Image dataset path: /kaggle/input/spam-image-dataset\n"
          ]
        }
      ],
      "source": [
        "# SpamAssassin Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú\n",
        "text_dataset_path = kagglehub.dataset_download(\"beatoa/spamassassin-public-corpus\")\n",
        "print(\"Text dataset path:\", text_dataset_path)\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú\n",
        "image_dataset_path = kagglehub.dataset_download(\"asifjamal123/spam-image-dataset\")\n",
        "print(\"Image dataset path:\", image_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch4b_4W2C2A"
      },
      "source": [
        "## 3. Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aWgZN4A2C2C"
      },
      "outputs": [],
      "source": [
        "def parse_email(file_path):\n",
        "    \"\"\"Ïù¥Î©îÏùº ÌååÏùºÏùÑ ÌååÏã±ÌïòÏó¨ Î≥∏Î¨∏ ÌÖçÏä§Ìä∏Î•º Ï∂îÏ∂ú\"\"\"\n",
        "    with open(file_path, 'r', encoding='latin-1') as f:\n",
        "        msg = email.message_from_file(f)\n",
        "\n",
        "    body = \"\"\n",
        "    if msg.is_multipart():\n",
        "        for part in msg.walk():\n",
        "            if part.get_content_type() == \"text/plain\":\n",
        "                body += part.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
        "    else:\n",
        "        body = msg.get_payload(decode=True).decode('latin-1', errors='ignore')\n",
        "\n",
        "    return body.strip()\n",
        "\n",
        "class MultimodalSpamDataset(Dataset):\n",
        "    def __init__(self, text_dir, image_dir, transform=None, max_length=512):\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "        self.images = []\n",
        "        self.image_labels = []\n",
        "        self.valid_extensions = ('.jpg', '.jpeg', '.png', '.gif')\n",
        "\n",
        "        # Ïä§Ìå∏ Ïù¥ÎØ∏ÏßÄ\n",
        "        spam_img_dir = os.path.join(image_dir, 'SPAM IMAGE dataset/SpamImages/SpamImages')\n",
        "        for img_name in os.listdir(spam_img_dir):\n",
        "            if img_name.lower().endswith(self.valid_extensions):\n",
        "                img_path = os.path.join(spam_img_dir, img_name)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()\n",
        "                    self.images.append(img_path)\n",
        "                    self.image_labels.append(1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
        "\n",
        "        # Ï†ïÏÉÅ Ïù¥ÎØ∏ÏßÄ\n",
        "        ham_img_dir = os.path.join(image_dir, 'SPAM IMAGE dataset/NaturalImages/NaturalImages')\n",
        "        for img_name in os.listdir(ham_img_dir):\n",
        "            if img_name.lower().endswith(self.valid_extensions):\n",
        "                img_path = os.path.join(ham_img_dir, img_name)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        img.verify()\n",
        "                    self.images.append(img_path)\n",
        "                    self.image_labels.append(0)\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Skipping corrupted image {img_path}: {str(e)}\")\n",
        "\n",
        "        # ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "        self.texts = []\n",
        "        self.text_labels = []\n",
        "\n",
        "        # Ïä§Ìå∏ ÌÖçÏä§Ìä∏\n",
        "        spam_text_dir = os.path.join(text_dir, 'spam_2/spam_2')\n",
        "        for text_file in os.listdir(spam_text_dir):\n",
        "            text_path = os.path.join(spam_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(1)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # Ï†ïÏÉÅ ÌÖçÏä§Ìä∏ (easy_ham)\n",
        "        ham_text_dir = os.path.join(text_dir, 'easy_ham/easy_ham')\n",
        "        for text_file in os.listdir(ham_text_dir):\n",
        "            text_path = os.path.join(ham_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(0)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # Ï†ïÏÉÅ ÌÖçÏä§Ìä∏ (hard_ham)\n",
        "        ham_text_dir = os.path.join(text_dir, 'hard_ham/hard_ham')\n",
        "        for text_file in os.listdir(ham_text_dir):\n",
        "            text_path = os.path.join(ham_text_dir, text_file)\n",
        "            try:\n",
        "                text = parse_email(text_path)\n",
        "                self.texts.append(text)\n",
        "                self.text_labels.append(0)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error parsing email {text_path}: {str(e)}\")\n",
        "\n",
        "        # ÎûúÎç§ Ï°∞Ìï© ÏÉùÏÑ±\n",
        "        self.combined_data = []\n",
        "\n",
        "        # Í∞Å Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌï¥ ÎûúÎç§Ìïú ÌÖçÏä§Ìä∏ Ìï†Îãπ\n",
        "        for i in range(len(self.images)):\n",
        "            # ÎûúÎç§Ìïú ÌÖçÏä§Ìä∏ ÏÑ†ÌÉù\n",
        "            text_idx = random.randint(0, len(self.texts) - 1)\n",
        "\n",
        "            # Ïù¥ÎØ∏ÏßÄÎÇò ÌÖçÏä§Ìä∏ Ï§ë ÌïòÎÇòÎùºÎèÑ Ïä§Ìå∏Ïù¥Î©¥ Ïä§Ìå∏ÏúºÎ°ú Î†àÏù¥Î∏îÎßÅ\n",
        "            is_spam = 1 if (self.image_labels[i] == 1 or self.text_labels[text_idx] == 1) else 0\n",
        "\n",
        "            self.combined_data.append({\n",
        "                'image_path': self.images[i],\n",
        "                'text': self.texts[text_idx],\n",
        "                'label': is_spam,\n",
        "                'image_label': self.image_labels[i],\n",
        "                'text_label': self.text_labels[text_idx]\n",
        "            })\n",
        "\n",
        "        # Îç∞Ïù¥ÌÑ∞ÏÖã ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
        "        spam_count = sum(1 for item in self.combined_data if item['label'] == 1)\n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"Total samples: {len(self.combined_data)}\")\n",
        "        print(f\"Spam samples: {spam_count} ({spam_count/len(self.combined_data)*100:.2f}%)\")\n",
        "        print(f\"Ham samples: {len(self.combined_data) - spam_count} ({(len(self.combined_data)-spam_count)/len(self.combined_data)*100:.2f}%)\")\n",
        "\n",
        "        # Ï°∞Ìï© Ïú†ÌòïÎ≥Ñ ÌÜµÍ≥Ñ\n",
        "        spam_spam = sum(1 for item in self.combined_data if item['image_label'] == 1 and item['text_label'] == 1)\n",
        "        spam_ham = sum(1 for item in self.combined_data if item['image_label'] == 1 and item['text_label'] == 0)\n",
        "        ham_spam = sum(1 for item in self.combined_data if item['image_label'] == 0 and item['text_label'] == 1)\n",
        "        ham_ham = sum(1 for item in self.combined_data if item['image_label'] == 0 and item['text_label'] == 0)\n",
        "\n",
        "        print(\"\\nCombination Statistics:\")\n",
        "        print(f\"Spam image + Spam text: {spam_spam}\")\n",
        "        print(f\"Spam image + Ham text: {spam_ham}\")\n",
        "        print(f\"Ham image + Spam text: {ham_spam}\")\n",
        "        print(f\"Ham image + Ham text: {ham_ham}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.combined_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.combined_data[idx]\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
        "        try:\n",
        "            image = Image.open(item['image_path']).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {item['image_path']}: {str(e)}\")\n",
        "            image = torch.zeros((3, 224, 224)) if self.transform else Image.new('RGB', (224, 224), 'black')\n",
        "\n",
        "        # ÌÖçÏä§Ìä∏ ÌÜ†ÌÅ∞Ìôî\n",
        "        encoding = self.tokenizer(\n",
        "            item['text'],\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'label': item['label']\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHxjXTMD2C2E"
      },
      "source": [
        "## 4. Î©ÄÌã∞Î™®Îã¨ Î™®Îç∏ Ï†ïÏùò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoNSyD162C2G"
      },
      "outputs": [],
      "source": [
        "class MultimodalSpamClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # ViT Î™®Îç∏\n",
        "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
        "        self.vit_dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # BERT Î™®Îç∏\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert_dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # ÌäπÏßï Í≤∞Ìï© Î∞è Î∂ÑÎ•ò\n",
        "        hidden_size = self.vit.config.hidden_size + self.bert.config.hidden_size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "        # Ïù¥ÎØ∏ÏßÄ ÌäπÏßï Ï∂îÏ∂ú\n",
        "        vit_outputs = self.vit(image)\n",
        "        image_features = self.vit_dropout(vit_outputs.last_hidden_state[:, 0])\n",
        "\n",
        "        # ÌÖçÏä§Ìä∏ ÌäπÏßï Ï∂îÏ∂ú\n",
        "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_features = self.bert_dropout(bert_outputs.last_hidden_state[:, 0])\n",
        "\n",
        "        # ÌäπÏßï Í≤∞Ìï©\n",
        "        combined_features = torch.cat([image_features, text_features], dim=1)\n",
        "\n",
        "        # Î∂ÑÎ•ò\n",
        "        logits = self.classifier(combined_features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl2MkPSH2C2H"
      },
      "source": [
        "## 5. ÌïôÏäµ Î∞è ÌèâÍ∞Ä Ìï®Ïàò Ï†ïÏùò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y6hSvaG2C2H"
      },
      "outputs": [],
      "source": [
        "# train_epoch Ìï®Ïàò ÏàòÏ†ï\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
        "        images = batch['image'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Î∞∞ÏπòÎ≥Ñ Î°úÍπÖ\n",
        "        if batch_idx % 10 == 0:  # 10Î∞∞ÏπòÎßàÎã§ Î°úÍπÖ\n",
        "            wandb.log({\n",
        "                \"batch_loss\": loss.item(),\n",
        "                \"batch\": batch_idx + epoch * len(dataloader)\n",
        "            })\n",
        "\n",
        "    # ÏóêÌè≠Î≥Ñ Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # wandbÏóê ÌòºÎèô ÌñâÎ†¨ Î°úÍπÖ\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    return total_loss / len(dataloader), accuracy, precision, recall, f1\n",
        "\n",
        "# validate Ìï®Ïàò ÏàòÏ†ï\n",
        "def validate(model, dataloader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            images = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(images, input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Í≤ÄÏ¶ù Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # wandbÏóê ÌòºÎèô ÌñâÎ†¨ Î°úÍπÖ\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Validation Confusion Matrix - Epoch {epoch+1}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    wandb.log({\"val_confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    return total_loss / len(dataloader), accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EesKQ8Fy2C2I"
      },
      "source": [
        "## 6. Î™®Îç∏ ÌïôÏäµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oeUKfcRX2C2I",
        "outputId": "83490da3-8c5b-4c1b-baa9-02fd7e3888f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_151256-ck54fb54</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">experiment_6c4rpi5f</a></strong> to <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping corrupted image /kaggle/input/spam-image-dataset/SPAM IMAGE dataset/SpamImages/SpamImages/debut.jpg: cannot identify image file '/kaggle/input/spam-image-dataset/SPAM IMAGE dataset/SpamImages/SpamImages/debut.jpg'\n",
            "\n",
            "Dataset Statistics:\n",
            "Total samples: 1739\n",
            "Spam samples: 1185 (68.14%)\n",
            "Ham samples: 554 (31.86%)\n",
            "\n",
            "Combination Statistics:\n",
            "Spam image + Spam text: 282\n",
            "Spam image + Ham text: 647\n",
            "Ham image + Spam text: 256\n",
            "Ham image + Ham text: 554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:46<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2812\n",
            "Train Metrics - Acc: 0.8871, Prec: 0.8928, Rec: 0.9483, F1: 0.9197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:37<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1109\n",
            "Val Metrics - Acc: 0.9741, Prec: 0.9790, Rec: 0.9831, F1: 0.9811\n",
            "Model saved!\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:52<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0941\n",
            "Train Metrics - Acc: 0.9763, Prec: 0.9831, Rec: 0.9821, F1: 0.9826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:36<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0885\n",
            "Val Metrics - Acc: 0.9799, Prec: 0.9873, Rec: 0.9831, F1: 0.9852\n",
            "Model saved!\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:52<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0422\n",
            "Train Metrics - Acc: 0.9899, Prec: 0.9895, Rec: 0.9958, F1: 0.9926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:37<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0752\n",
            "Val Metrics - Acc: 0.9741, Prec: 0.9790, Rec: 0.9831, F1: 0.9811\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:46<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0219\n",
            "Train Metrics - Acc: 0.9942, Prec: 0.9927, Rec: 0.9989, F1: 0.9958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:40<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0596\n",
            "Val Metrics - Acc: 0.9799, Prec: 0.9792, Rec: 0.9916, F1: 0.9853\n",
            "Model saved!\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:48<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0118\n",
            "Train Metrics - Acc: 0.9993, Prec: 1.0000, Rec: 0.9989, F1: 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:41<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0578\n",
            "Val Metrics - Acc: 0.9770, Prec: 0.9791, Rec: 0.9873, F1: 0.9832\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:45<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0072\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:36<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0590\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9873, Rec: 0.9873, F1: 0.9873\n",
            "Model saved!\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:51<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:36<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0637\n",
            "Val Metrics - Acc: 0.9770, Prec: 0.9791, Rec: 0.9873, F1: 0.9832\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:49<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0044\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:36<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0599\n",
            "Val Metrics - Acc: 0.9856, Prec: 0.9874, Rec: 0.9916, F1: 0.9895\n",
            "Model saved!\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:45<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0040\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:40<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0618\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9833, Rec: 0.9916, F1: 0.9874\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [04:44<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0033\n",
            "Train Metrics - Acc: 1.0000, Prec: 1.0000, Rec: 1.0000, F1: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:40<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0622\n",
            "Val Metrics - Acc: 0.9828, Prec: 0.9833, Rec: 0.9916, F1: 0.9874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>batch_loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>train_accuracy</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_f1</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train_precision</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_recall</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_accuracy</td><td>‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñÜ‚ñÜ</td></tr><tr><td>val_f1</td><td>‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñÜ‚ñÜ</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ</td></tr><tr><td>val_precision</td><td>‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÖ‚ñÖ</td></tr><tr><td>val_recall</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>1736</td></tr><tr><td>batch_loss</td><td>0.00429</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_accuracy</td><td>1</td></tr><tr><td>train_f1</td><td>1</td></tr><tr><td>train_loss</td><td>0.00335</td></tr><tr><td>train_precision</td><td>1</td></tr><tr><td>train_recall</td><td>1</td></tr><tr><td>val_accuracy</td><td>0.98276</td></tr><tr><td>val_f1</td><td>0.98739</td></tr><tr><td>val_loss</td><td>0.0622</td></tr><tr><td>val_precision</td><td>0.98326</td></tr><tr><td>val_recall</td><td>0.99156</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_6c4rpi5f</strong> at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/ck54fb54</a><br> View project at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a><br>Synced 5 W&B file(s), 20 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_151256-ck54fb54/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
        "config = {\n",
        "    \"architecture\": \"ViT-BERT-Multimodal\",\n",
        "    \"dataset\": \"SpamAssassin + Spam Image Dataset\",\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 10,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"scheduler\": \"linear\",\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"image_size\": 224,\n",
        "    \"max_text_length\": 512\n",
        "}\n",
        "\n",
        "# wandb Ï¥àÍ∏∞Ìôî\n",
        "wandb.init(\n",
        "    project=\"multimodal-spam-detection\",\n",
        "    config=config,\n",
        "    name=f\"experiment_{wandb.util.generate_id()}\"\n",
        ")\n",
        "\n",
        "BATCH_SIZE = config[\"batch_size\"]\n",
        "EPOCHS = config[\"epochs\"]\n",
        "LEARNING_RATE = config[\"learning_rate\"]\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è Îç∞Ïù¥ÌÑ∞Î°úÎçî ÏÉùÏÑ±\n",
        "dataset = MultimodalSpamDataset(text_dataset_path, image_dataset_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultimodalSpamClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=config[\"weight_decay\"])\n",
        "scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=EPOCHS)\n",
        "\n",
        "# wandbÏóê Î™®Îç∏ Íµ¨Ï°∞ Î°úÍπÖ\n",
        "wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "best_val_f1 = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
        "\n",
        "    # ÌïôÏäµ\n",
        "    train_loss, train_acc, train_prec, train_rec, train_f1 = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, device, epoch\n",
        "    )\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    print(f'Train Metrics - Acc: {train_acc:.4f}, Prec: {train_prec:.4f}, Rec: {train_rec:.4f}, F1: {train_f1:.4f}')\n",
        "\n",
        "    # Í≤ÄÏ¶ù\n",
        "    val_loss, val_acc, val_prec, val_rec, val_f1 = validate(\n",
        "        model, val_loader, criterion, device, epoch\n",
        "    )\n",
        "    print(f'Val Loss: {val_loss:.4f}')\n",
        "    print(f'Val Metrics - Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, Rec: {val_rec:.4f}, F1: {val_f1:.4f}')\n",
        "\n",
        "    # ÌïôÏäµÎ•† Ï°∞Ï†ï\n",
        "    scheduler.step()\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "    # wandbÏóê Î©îÌä∏Î¶≠ Î°úÍπÖ\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"train_precision\": train_prec,\n",
        "        \"train_recall\": train_rec,\n",
        "        \"train_f1\": train_f1,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"val_precision\": val_prec,\n",
        "        \"val_recall\": val_rec,\n",
        "        \"val_f1\": val_f1,\n",
        "        \"learning_rate\": current_lr\n",
        "    })\n",
        "\n",
        "    # ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ Ï†ÄÏû•\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_multimodal_spam_classifier.pth')\n",
        "        wandb.save('best_multimodal_spam_classifier.pth')\n",
        "        print('Model saved!')\n",
        "\n",
        "# wandb Ïã§Ìóò Ï¢ÖÎ£å\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3iLS4mg2C2J"
      },
      "source": [
        "## 7. Î™®Îç∏ ÌèâÍ∞Ä Î∞è Î∂ÑÏÑù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "yPoB5w5_2C2J",
        "outputId": "8799d56f-3cc1-4410-e5cc-ad50fdb7fb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_160915-u3bnnl9d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">final_evaluation</a></strong> to <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44/44 [00:19<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Evaluation Results:\n",
            "Accuracy: 0.9856\n",
            "Precision: 0.9874\n",
            "Recall: 0.9916\n",
            "F1-Score: 0.9895\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final_accuracy</td><td>‚ñÅ</td></tr><tr><td>final_f1</td><td>‚ñÅ</td></tr><tr><td>final_precision</td><td>‚ñÅ</td></tr><tr><td>final_recall</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final_accuracy</td><td>0.98563</td></tr><tr><td>final_f1</td><td>0.98947</td></tr><tr><td>final_precision</td><td>0.98739</td></tr><tr><td>final_recall</td><td>0.99156</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">final_evaluation</strong> at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection/runs/u3bnnl9d</a><br> View project at: <a href='https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection' target=\"_blank\">https://wandb.ai/woochang4862-university-of-suwon/multimodal-spam-detection</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_160915-u3bnnl9d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ Î°úÎìú\n",
        "best_model = MultimodalSpamClassifier().to(device)\n",
        "best_model.load_state_dict(torch.load('best_multimodal_spam_classifier.pth'))\n",
        "\n",
        "# Ï†ÑÏ≤¥ Í≤ÄÏ¶ù ÏÑ∏Ìä∏Ïóê ÎåÄÌïú ÏÉÅÏÑ∏ ÌèâÍ∞Ä\n",
        "wandb.init(project=\"multimodal-spam-detection\", name=\"final_evaluation\")\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = validate(best_model, val_loader, criterion, device, EPOCHS)\n",
        "\n",
        "print('\\nFinal Evaluation Results:')\n",
        "print(f'Accuracy: {val_acc:.4f}')\n",
        "print(f'Precision: {val_prec:.4f}')\n",
        "print(f'Recall: {val_rec:.4f}')\n",
        "print(f'F1-Score: {val_f1:.4f}')\n",
        "\n",
        "# ÏµúÏ¢Ö Í≤∞Í≥ºÎ•º wandbÏóê Î°úÍπÖ\n",
        "wandb.log({\n",
        "    \"final_accuracy\": val_acc,\n",
        "    \"final_precision\": val_prec,\n",
        "    \"final_recall\": val_rec,\n",
        "    \"final_f1\": val_f1\n",
        "})\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx3GYgro2C2K"
      },
      "source": [
        "## 8. ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDoMT6bM2C2K"
      },
      "outputs": [],
      "source": [
        "def predict_sample(model, image_path, text, device, transform):\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image, input_ids, attention_mask)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "    return {\n",
        "        'prediction': 'Ïä§Ìå∏' if prediction == 1 else 'Ï†ïÏÉÅ',\n",
        "        'spam_prob': probs[0][1].item(),\n",
        "        'normal_prob': probs[0][0].item()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏòàÏãú Îç∞Ïù¥ÌÑ∞Î°ú ÌÖåÏä§Ìä∏\n",
        "test_image_path = \"/content/000a01c72c26$bec5c540$00000000@zv65vp7hlihg4p_storeblog_download000.jpg\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú\n",
        "test_text = \"\"\"\n",
        "Subject: üéÑ CHRISTMAS SPECIAL OFFER - MEN'S POWER PACK! üéÅ\n",
        "\n",
        "HELLO!\n",
        "\n",
        "CHRISTMAS MEN'S POWER CHARGE!\n",
        "SPECIAL HOLIDAY COMBO PACK - CIALIS + VIAGRA\n",
        "\n",
        "INCREDIBLE HOLIDAY SAVINGS:\n",
        "‚ú® 10 + 10 = $129.95 (BEST VALUE!)\n",
        "‚ú® 20 + 20 = $249.95\n",
        "‚ú® 30 + 30 = $319.95\n",
        "\n",
        "üéÖ HOLIDAY BONUS: 20% EXTRA DISCOUNT! üéÑ\n",
        "\n",
        "Available Products:\n",
        "- Cialis Soft\n",
        "- Viagra Professional\n",
        "- Viagra Soft\n",
        "- Generic Viagra\n",
        "- Valium\n",
        "- Xanax\n",
        "- Soma\n",
        "- Ambien\n",
        "And many more!\n",
        "\n",
        "üíä 100% GENUINE PRODUCTS\n",
        "‚úàÔ∏è WORLDWIDE SHIPPING\n",
        "üîí SECURE PAYMENT\n",
        "\n",
        "DON'T MISS OUT ON THIS LIMITED TIME OFFER!\n",
        "\n",
        "CLICK HERE TO ORDER NOW!\n",
        "[suspicious_link_removed]\n",
        "\n",
        "To unsubscribe, reply with \"STOP\"\n",
        "\"\"\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥Î©îÏùº ÌÖçÏä§Ìä∏\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nÏòàÏ∏° Í≤∞Í≥º:\")\n",
        "    print(f\"ÌåêÏ†ï: {result['prediction']}\")\n",
        "    print(f\"Ïä§Ìå∏ ÌôïÎ•†: {result['spam_prob']:.4f}\")\n",
        "    print(f\"Ï†ïÏÉÅ ÌôïÎ•†: {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zLulklYKlFh",
        "outputId": "a9e2d71a-fcd5-4441-be36-23c50aa5d06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ÏòàÏ∏° Í≤∞Í≥º:\n",
            "ÌåêÏ†ï: Ïä§Ìå∏\n",
            "Ïä§Ìå∏ ÌôïÎ•†: 1.0000\n",
            "Ï†ïÏÉÅ ÌôïÎ•†: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏòàÏãú Îç∞Ïù¥ÌÑ∞Î°ú ÌÖåÏä§Ìä∏\n",
        "test_image_path = \"/content/IMG_2757.jpg\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú\n",
        "test_text = \"\"\"\n",
        "Subject: üåü Join Late Night Study Group - SWU AI Security Department!\n",
        "\n",
        "Hello from Suwon University's AI Security Department Late Night Study Group!\n",
        "\n",
        "We are a dedicated study group that meets every Tuesday night for intensive learning sessions.\n",
        "(Photo attached: Last week's study session - Our passionate team at 2:06 AM)\n",
        "\n",
        "üìö Study Focus Areas:\n",
        "- AI Security Project Labs\n",
        "- Coding Test Preparation\n",
        "- Team Project Collaboration\n",
        "- Career Development Insights\n",
        "\n",
        "‚ú® Requirements:\n",
        "- Current student in SWU AI Security Department\n",
        "- Passionate and committed mindset\n",
        "- Available for late-night sessions (2-4 AM)\n",
        "- Strong team player attitude\n",
        "\n",
        "üíù Benefits:\n",
        "- Network with department peers\n",
        "- Hands-on project experience\n",
        "- Career opportunity sharing\n",
        "- Snacks and beverages provided\n",
        "\n",
        "Interested? Join our open KakaoTalk chat!\n",
        "[Link]\n",
        "\n",
        "* This semester's recruitment ends this week!\n",
        "* Limited to first 3 applicants - Don't miss out!\n",
        "\n",
        "Best regards,\n",
        "SWU AI Security Late Night Study Group\n",
        "\"\"\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥Î©îÏùº ÌÖçÏä§Ìä∏\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nÏòàÏ∏° Í≤∞Í≥º:\")\n",
        "    print(f\"ÌåêÏ†ï: {result['prediction']}\")\n",
        "    print(f\"Ïä§Ìå∏ ÌôïÎ•†: {result['spam_prob']:.4f}\")\n",
        "    print(f\"Ï†ïÏÉÅ ÌôïÎ•†: {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LY-BUyGNeHs",
        "outputId": "f2b32610-fac9-43ff-83ad-555b9c6bbf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ÏòàÏ∏° Í≤∞Í≥º:\n",
            "ÌåêÏ†ï: Ïä§Ìå∏\n",
            "Ïä§Ìå∏ ÌôïÎ•†: 0.9836\n",
            "Ï†ïÏÉÅ ÌôïÎ•†: 0.0164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏòàÏãú Îç∞Ïù¥ÌÑ∞Î°ú ÌÖåÏä§Ìä∏\n",
        "test_image_path = \"/content/IMG_2757.jpg\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú\n",
        "test_text = \"\"\"\n",
        "Subject: üéÑ CHRISTMAS SPECIAL OFFER - MEN'S POWER PACK! üéÅ\n",
        "\n",
        "HELLO!\n",
        "\n",
        "CHRISTMAS MEN'S POWER CHARGE!\n",
        "SPECIAL HOLIDAY COMBO PACK - CIALIS + VIAGRA\n",
        "\n",
        "INCREDIBLE HOLIDAY SAVINGS:\n",
        "‚ú® 10 + 10 = $129.95 (BEST VALUE!)\n",
        "‚ú® 20 + 20 = $249.95\n",
        "‚ú® 30 + 30 = $319.95\n",
        "\n",
        "üéÖ HOLIDAY BONUS: 20% EXTRA DISCOUNT! üéÑ\n",
        "\n",
        "Available Products:\n",
        "- Cialis Soft\n",
        "- Viagra Professional\n",
        "- Viagra Soft\n",
        "- Generic Viagra\n",
        "- Valium\n",
        "- Xanax\n",
        "- Soma\n",
        "- Ambien\n",
        "And many more!\n",
        "\n",
        "üíä 100% GENUINE PRODUCTS\n",
        "‚úàÔ∏è WORLDWIDE SHIPPING\n",
        "üîí SECURE PAYMENT\n",
        "\n",
        "DON'T MISS OUT ON THIS LIMITED TIME OFFER!\n",
        "\n",
        "CLICK HERE TO ORDER NOW!\n",
        "[suspicious_link_removed]\n",
        "\n",
        "To unsubscribe, reply with \"STOP\"\n",
        "\"\"\"  # ÌÖåÏä§Ìä∏Ìï† Ïù¥Î©îÏùº ÌÖçÏä§Ìä∏\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    result = predict_sample(best_model, test_image_path, test_text, device, transform)\n",
        "\n",
        "    print(\"\\nÏòàÏ∏° Í≤∞Í≥º:\")\n",
        "    print(f\"ÌåêÏ†ï: {result['prediction']}\")\n",
        "    print(f\"Ïä§Ìå∏ ÌôïÎ•†: {result['spam_prob']:.4f}\")\n",
        "    print(f\"Ï†ïÏÉÅ ÌôïÎ•†: {result['normal_prob']:.4f}\")\n",
        "else:\n",
        "    print(\"ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjb4DYdLPLHq",
        "outputId": "19a3f251-5ea9-4b08-a597-3b020a5906c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ÏòàÏ∏° Í≤∞Í≥º:\n",
            "ÌåêÏ†ï: Ïä§Ìå∏\n",
            "Ïä§Ìå∏ ÌôïÎ•†: 0.9922\n",
            "Ï†ïÏÉÅ ÌôïÎ•†: 0.0078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_only(model, text, device):\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # ÎçîÎØ∏ Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± (Í≤ÄÏùÄÏÉâ Ïù¥ÎØ∏ÏßÄ)\n",
        "    dummy_image = torch.zeros((1, 3, 224, 224)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(dummy_image, input_ids, attention_mask)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "    return {\n",
        "        'prediction': 'Ïä§Ìå∏' if prediction == 1 else 'Ï†ïÏÉÅ',\n",
        "        'spam_prob': probs[0][1].item(),\n",
        "        'normal_prob': probs[0][0].item()\n",
        "    }\n",
        "\n",
        "# ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú ÌÖåÏä§Ìä∏\n",
        "test_text = \"\"\"\n",
        "From ilug-admin@linux.ie  Tue Aug  6 11:51:02 2002\n",
        "Return-Path: <ilug-admin@linux.ie>\n",
        "Delivered-To: yyyy@localhost.netnoteinc.com\n",
        "Received: from localhost (localhost [127.0.0.1])\n",
        "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\n",
        "\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
        "Received: from phobos [127.0.0.1]\n",
        "\tby localhost with IMAP (fetchmail-5.9.0)\n",
        "\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
        "Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\n",
        "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for\n",
        "    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
        "Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\n",
        "    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
        "Received: from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net\n",
        "    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for\n",
        "    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
        "X-Authentication-Warning: lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net\n",
        "    [64.0.57.142] claimed to be bettyjagessar.com\n",
        "Received: from 64.0.57.142 [202.63.165.34] by bettyjagessar.com\n",
        "    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
        "Message-Id: <1028311679.886@0.57.142>\n",
        "Date: Fri, 02 Aug 2002 23:37:59 0530\n",
        "To: ilug@linux.ie\n",
        "From: \"Start Now\" <startnow2002@hotmail.com>\n",
        "MIME-Version: 1.0\n",
        "Content-Type: text/plain; charset=\"US-ASCII\"; format=flowed\n",
        "Subject: [ILUG] STOP THE MLM INSANITY\n",
        "Sender: ilug-admin@linux.ie\n",
        "Errors-To: ilug-admin@linux.ie\n",
        "X-Mailman-Version: 1.1\n",
        "Precedence: bulk\n",
        "List-Id: Irish Linux Users' Group <ilug.linux.ie>\n",
        "X-Beenthere: ilug@linux.ie\n",
        "\n",
        "Greetings!\n",
        "\n",
        "You are receiving this letter because you have expressed an interest in\n",
        "receiving information about online business opportunities. If this is\n",
        "erroneous then please accept my most sincere apology. This is a one-time\n",
        "mailing, so no removal is necessary.\n",
        "\n",
        "If you've been burned, betrayed, and back-stabbed by multi-level marketing,\n",
        "MLM, then please read this letter. It could be the most important one that\n",
        "has ever landed in your Inbox.\n",
        "\n",
        "MULTI-LEVEL MARKETING IS A HUGE MISTAKE FOR MOST PEOPLE\n",
        "\n",
        "MLM has failed to deliver on its promises for the past 50 years. The pursuit\n",
        "of the \"MLM Dream\" has cost hundreds of thousands of people their friends,\n",
        "their fortunes and their sacred honor. The fact is that MLM is fatally\n",
        "flawed, meaning that it CANNOT work for most people.\n",
        "\n",
        "The companies and the few who earn the big money in MLM are NOT going to\n",
        "tell you the real story. FINALLY, there is someone who has the courage to\n",
        "cut through the hype and lies and tell the TRUTH about MLM.\n",
        "\n",
        "HERE'S GOOD NEWS\n",
        "\n",
        "There IS an alternative to MLM that WORKS, and works BIG! If you haven't yet\n",
        "abandoned your dreams, then you need to see this. Earning the kind of income\n",
        "you've dreamed about is easier than you think!\n",
        "\n",
        "With your permission, I'd like to send you a brief letter that will tell you\n",
        "WHY MLM doesn't work for most people and will then introduce you to\n",
        "something so new and refreshing that you'll wonder why you haven't heard of\n",
        "this before.\n",
        "\n",
        "I promise that there will be NO unwanted follow up, NO sales pitch, no one\n",
        "will call you, and your email address will only be used to send you the\n",
        "information. Period.\n",
        "\n",
        "To receive this free, life-changing information, simply click Reply, type\n",
        "\"Send Info\" in the Subject box and hit Send. I'll get the information to you\n",
        "within 24 hours. Just look for the words MLM WALL OF SHAME in your Inbox.\n",
        "\n",
        "Cordially,\n",
        "\n",
        "Siddhi\n",
        "\n",
        "P.S. Someone recently sent the letter to me and it has been the most\n",
        "eye-opening, financially beneficial information I have ever received. I\n",
        "honestly believe that you will feel the same way once you've read it. And\n",
        "it's FREE!\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "This email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". You are receiving\n",
        "this email because you EXPLICITLY signed yourself up to our list with our\n",
        "online signup form or through use of our FFA Links Page and E-MailDOM\n",
        "systems, which have EXPLICIT terms of use which state that through its use\n",
        "you agree to receive our emailings.  You may also be a member of a Altra\n",
        "Computer Systems list or one of many numerous FREE Marketing Services and as\n",
        "such you agreed when you signed up for such list that you would also be\n",
        "receiving this emailing.\n",
        "Due to the above, this email message cannot be considered unsolicitated, or\n",
        "spam.\n",
        "-----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "--\n",
        "Irish Linux Users' Group: ilug@linux.ie\n",
        "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
        "List maintainer: listmaster@linux.ie\n",
        "\"\"\"\n",
        "\n",
        "result = predict_text_only(best_model, test_text, device)\n",
        "\n",
        "print(\"\\nÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÏòàÏ∏° Í≤∞Í≥º:\")\n",
        "print(f\"ÌåêÏ†ï: {result['prediction']}\")\n",
        "print(f\"Ïä§Ìå∏ ÌôïÎ•†: {result['spam_prob']:.4f}\")\n",
        "print(f\"Ï†ïÏÉÅ ÌôïÎ•†: {result['normal_prob']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PvdAWI3OraM",
        "outputId": "e00105f0-efee-445c-9fbe-51600875f4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÏòàÏ∏° Í≤∞Í≥º:\n",
            "ÌåêÏ†ï: Ï†ïÏÉÅ\n",
            "Ïä§Ìå∏ ÌôïÎ•†: 0.0263\n",
            "Ï†ïÏÉÅ ÌôïÎ•†: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_wxYUUb8Qmhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}